// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: server_status.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_server_5fstatus_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_server_5fstatus_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3019000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3019004 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata_lite.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/map.h>  // IWYU pragma: export
#include <google/protobuf/map_entry.h>
#include <google/protobuf/map_field_inl.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "model_config.pb.h"
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_server_5fstatus_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_server_5fstatus_2eproto {
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTableField entries[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::AuxiliaryParseTableField aux[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTable schema[11]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::FieldMetadata field_metadata[];
  static const ::PROTOBUF_NAMESPACE_ID::internal::SerializationTable serialization_table[];
  static const uint32_t offsets[];
};
extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_server_5fstatus_2eproto;
namespace nvidia {
namespace inferenceserver {
class HealthRequestStats;
struct HealthRequestStatsDefaultTypeInternal;
extern HealthRequestStatsDefaultTypeInternal _HealthRequestStats_default_instance_;
class InferRequestStats;
struct InferRequestStatsDefaultTypeInternal;
extern InferRequestStatsDefaultTypeInternal _InferRequestStats_default_instance_;
class ModelStatus;
struct ModelStatusDefaultTypeInternal;
extern ModelStatusDefaultTypeInternal _ModelStatus_default_instance_;
class ModelStatus_VersionStatusEntry_DoNotUse;
struct ModelStatus_VersionStatusEntry_DoNotUseDefaultTypeInternal;
extern ModelStatus_VersionStatusEntry_DoNotUseDefaultTypeInternal _ModelStatus_VersionStatusEntry_DoNotUse_default_instance_;
class ModelVersionStatus;
struct ModelVersionStatusDefaultTypeInternal;
extern ModelVersionStatusDefaultTypeInternal _ModelVersionStatus_default_instance_;
class ModelVersionStatus_InferStatsEntry_DoNotUse;
struct ModelVersionStatus_InferStatsEntry_DoNotUseDefaultTypeInternal;
extern ModelVersionStatus_InferStatsEntry_DoNotUseDefaultTypeInternal _ModelVersionStatus_InferStatsEntry_DoNotUse_default_instance_;
class ProfileRequestStats;
struct ProfileRequestStatsDefaultTypeInternal;
extern ProfileRequestStatsDefaultTypeInternal _ProfileRequestStats_default_instance_;
class ServerStatus;
struct ServerStatusDefaultTypeInternal;
extern ServerStatusDefaultTypeInternal _ServerStatus_default_instance_;
class ServerStatus_ModelStatusEntry_DoNotUse;
struct ServerStatus_ModelStatusEntry_DoNotUseDefaultTypeInternal;
extern ServerStatus_ModelStatusEntry_DoNotUseDefaultTypeInternal _ServerStatus_ModelStatusEntry_DoNotUse_default_instance_;
class StatDuration;
struct StatDurationDefaultTypeInternal;
extern StatDurationDefaultTypeInternal _StatDuration_default_instance_;
class StatusRequestStats;
struct StatusRequestStatsDefaultTypeInternal;
extern StatusRequestStatsDefaultTypeInternal _StatusRequestStats_default_instance_;
}  // namespace inferenceserver
}  // namespace nvidia
PROTOBUF_NAMESPACE_OPEN
template<> ::nvidia::inferenceserver::HealthRequestStats* Arena::CreateMaybeMessage<::nvidia::inferenceserver::HealthRequestStats>(Arena*);
template<> ::nvidia::inferenceserver::InferRequestStats* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestStats>(Arena*);
template<> ::nvidia::inferenceserver::ModelStatus* Arena::CreateMaybeMessage<::nvidia::inferenceserver::ModelStatus>(Arena*);
template<> ::nvidia::inferenceserver::ModelStatus_VersionStatusEntry_DoNotUse* Arena::CreateMaybeMessage<::nvidia::inferenceserver::ModelStatus_VersionStatusEntry_DoNotUse>(Arena*);
template<> ::nvidia::inferenceserver::ModelVersionStatus* Arena::CreateMaybeMessage<::nvidia::inferenceserver::ModelVersionStatus>(Arena*);
template<> ::nvidia::inferenceserver::ModelVersionStatus_InferStatsEntry_DoNotUse* Arena::CreateMaybeMessage<::nvidia::inferenceserver::ModelVersionStatus_InferStatsEntry_DoNotUse>(Arena*);
template<> ::nvidia::inferenceserver::ProfileRequestStats* Arena::CreateMaybeMessage<::nvidia::inferenceserver::ProfileRequestStats>(Arena*);
template<> ::nvidia::inferenceserver::ServerStatus* Arena::CreateMaybeMessage<::nvidia::inferenceserver::ServerStatus>(Arena*);
template<> ::nvidia::inferenceserver::ServerStatus_ModelStatusEntry_DoNotUse* Arena::CreateMaybeMessage<::nvidia::inferenceserver::ServerStatus_ModelStatusEntry_DoNotUse>(Arena*);
template<> ::nvidia::inferenceserver::StatDuration* Arena::CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(Arena*);
template<> ::nvidia::inferenceserver::StatusRequestStats* Arena::CreateMaybeMessage<::nvidia::inferenceserver::StatusRequestStats>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace nvidia {
namespace inferenceserver {

enum ModelReadyState : int {
  MODEL_UNKNOWN = 0,
  MODEL_READY = 1,
  MODEL_UNAVAILABLE = 2,
  MODEL_LOADING = 3,
  MODEL_UNLOADING = 4,
  ModelReadyState_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::min(),
  ModelReadyState_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::max()
};
bool ModelReadyState_IsValid(int value);
constexpr ModelReadyState ModelReadyState_MIN = MODEL_UNKNOWN;
constexpr ModelReadyState ModelReadyState_MAX = MODEL_UNLOADING;
constexpr int ModelReadyState_ARRAYSIZE = ModelReadyState_MAX + 1;

const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* ModelReadyState_descriptor();
template<typename T>
inline const std::string& ModelReadyState_Name(T enum_t_value) {
  static_assert(::std::is_same<T, ModelReadyState>::value ||
    ::std::is_integral<T>::value,
    "Incorrect type passed to function ModelReadyState_Name.");
  return ::PROTOBUF_NAMESPACE_ID::internal::NameOfEnum(
    ModelReadyState_descriptor(), enum_t_value);
}
inline bool ModelReadyState_Parse(
    ::PROTOBUF_NAMESPACE_ID::ConstStringParam name, ModelReadyState* value) {
  return ::PROTOBUF_NAMESPACE_ID::internal::ParseNamedEnum<ModelReadyState>(
    ModelReadyState_descriptor(), name, value);
}
enum ServerReadyState : int {
  SERVER_INVALID = 0,
  SERVER_INITIALIZING = 1,
  SERVER_READY = 2,
  SERVER_EXITING = 3,
  SERVER_FAILED_TO_INITIALIZE = 10,
  ServerReadyState_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::min(),
  ServerReadyState_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits<int32_t>::max()
};
bool ServerReadyState_IsValid(int value);
constexpr ServerReadyState ServerReadyState_MIN = SERVER_INVALID;
constexpr ServerReadyState ServerReadyState_MAX = SERVER_FAILED_TO_INITIALIZE;
constexpr int ServerReadyState_ARRAYSIZE = ServerReadyState_MAX + 1;

const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* ServerReadyState_descriptor();
template<typename T>
inline const std::string& ServerReadyState_Name(T enum_t_value) {
  static_assert(::std::is_same<T, ServerReadyState>::value ||
    ::std::is_integral<T>::value,
    "Incorrect type passed to function ServerReadyState_Name.");
  return ::PROTOBUF_NAMESPACE_ID::internal::NameOfEnum(
    ServerReadyState_descriptor(), enum_t_value);
}
inline bool ServerReadyState_Parse(
    ::PROTOBUF_NAMESPACE_ID::ConstStringParam name, ServerReadyState* value) {
  return ::PROTOBUF_NAMESPACE_ID::internal::ParseNamedEnum<ServerReadyState>(
    ServerReadyState_descriptor(), name, value);
}
// ===================================================================

class StatDuration final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.StatDuration) */ {
 public:
  inline StatDuration() : StatDuration(nullptr) {}
  ~StatDuration() override;
  explicit constexpr StatDuration(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  StatDuration(const StatDuration& from);
  StatDuration(StatDuration&& from) noexcept
    : StatDuration() {
    *this = ::std::move(from);
  }

  inline StatDuration& operator=(const StatDuration& from) {
    CopyFrom(from);
    return *this;
  }
  inline StatDuration& operator=(StatDuration&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const StatDuration& default_instance() {
    return *internal_default_instance();
  }
  static inline const StatDuration* internal_default_instance() {
    return reinterpret_cast<const StatDuration*>(
               &_StatDuration_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  friend void swap(StatDuration& a, StatDuration& b) {
    a.Swap(&b);
  }
  inline void Swap(StatDuration* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(StatDuration* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  StatDuration* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<StatDuration>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const StatDuration& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const StatDuration& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StatDuration* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.StatDuration";
  }
  protected:
  explicit StatDuration(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kCountFieldNumber = 1,
    kTotalTimeNsFieldNumber = 2,
  };
  // uint64 count = 1;
  void clear_count();
  uint64_t count() const;
  void set_count(uint64_t value);
  private:
  uint64_t _internal_count() const;
  void _internal_set_count(uint64_t value);
  public:

  // uint64 total_time_ns = 2;
  void clear_total_time_ns();
  uint64_t total_time_ns() const;
  void set_total_time_ns(uint64_t value);
  private:
  uint64_t _internal_total_time_ns() const;
  void _internal_set_total_time_ns(uint64_t value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.StatDuration)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  uint64_t count_;
  uint64_t total_time_ns_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// -------------------------------------------------------------------

class StatusRequestStats final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.StatusRequestStats) */ {
 public:
  inline StatusRequestStats() : StatusRequestStats(nullptr) {}
  ~StatusRequestStats() override;
  explicit constexpr StatusRequestStats(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  StatusRequestStats(const StatusRequestStats& from);
  StatusRequestStats(StatusRequestStats&& from) noexcept
    : StatusRequestStats() {
    *this = ::std::move(from);
  }

  inline StatusRequestStats& operator=(const StatusRequestStats& from) {
    CopyFrom(from);
    return *this;
  }
  inline StatusRequestStats& operator=(StatusRequestStats&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const StatusRequestStats& default_instance() {
    return *internal_default_instance();
  }
  static inline const StatusRequestStats* internal_default_instance() {
    return reinterpret_cast<const StatusRequestStats*>(
               &_StatusRequestStats_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  friend void swap(StatusRequestStats& a, StatusRequestStats& b) {
    a.Swap(&b);
  }
  inline void Swap(StatusRequestStats* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(StatusRequestStats* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  StatusRequestStats* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<StatusRequestStats>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const StatusRequestStats& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const StatusRequestStats& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StatusRequestStats* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.StatusRequestStats";
  }
  protected:
  explicit StatusRequestStats(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kSuccessFieldNumber = 1,
  };
  // .nvidia.inferenceserver.StatDuration success = 1;
  bool has_success() const;
  private:
  bool _internal_has_success() const;
  public:
  void clear_success();
  const ::nvidia::inferenceserver::StatDuration& success() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatDuration* release_success();
  ::nvidia::inferenceserver::StatDuration* mutable_success();
  void set_allocated_success(::nvidia::inferenceserver::StatDuration* success);
  private:
  const ::nvidia::inferenceserver::StatDuration& _internal_success() const;
  ::nvidia::inferenceserver::StatDuration* _internal_mutable_success();
  public:
  void unsafe_arena_set_allocated_success(
      ::nvidia::inferenceserver::StatDuration* success);
  ::nvidia::inferenceserver::StatDuration* unsafe_arena_release_success();

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.StatusRequestStats)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::nvidia::inferenceserver::StatDuration* success_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// -------------------------------------------------------------------

class ProfileRequestStats final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.ProfileRequestStats) */ {
 public:
  inline ProfileRequestStats() : ProfileRequestStats(nullptr) {}
  ~ProfileRequestStats() override;
  explicit constexpr ProfileRequestStats(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  ProfileRequestStats(const ProfileRequestStats& from);
  ProfileRequestStats(ProfileRequestStats&& from) noexcept
    : ProfileRequestStats() {
    *this = ::std::move(from);
  }

  inline ProfileRequestStats& operator=(const ProfileRequestStats& from) {
    CopyFrom(from);
    return *this;
  }
  inline ProfileRequestStats& operator=(ProfileRequestStats&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const ProfileRequestStats& default_instance() {
    return *internal_default_instance();
  }
  static inline const ProfileRequestStats* internal_default_instance() {
    return reinterpret_cast<const ProfileRequestStats*>(
               &_ProfileRequestStats_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  friend void swap(ProfileRequestStats& a, ProfileRequestStats& b) {
    a.Swap(&b);
  }
  inline void Swap(ProfileRequestStats* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(ProfileRequestStats* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  ProfileRequestStats* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<ProfileRequestStats>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const ProfileRequestStats& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const ProfileRequestStats& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ProfileRequestStats* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.ProfileRequestStats";
  }
  protected:
  explicit ProfileRequestStats(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kSuccessFieldNumber = 1,
  };
  // .nvidia.inferenceserver.StatDuration success = 1;
  bool has_success() const;
  private:
  bool _internal_has_success() const;
  public:
  void clear_success();
  const ::nvidia::inferenceserver::StatDuration& success() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatDuration* release_success();
  ::nvidia::inferenceserver::StatDuration* mutable_success();
  void set_allocated_success(::nvidia::inferenceserver::StatDuration* success);
  private:
  const ::nvidia::inferenceserver::StatDuration& _internal_success() const;
  ::nvidia::inferenceserver::StatDuration* _internal_mutable_success();
  public:
  void unsafe_arena_set_allocated_success(
      ::nvidia::inferenceserver::StatDuration* success);
  ::nvidia::inferenceserver::StatDuration* unsafe_arena_release_success();

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ProfileRequestStats)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::nvidia::inferenceserver::StatDuration* success_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// -------------------------------------------------------------------

class HealthRequestStats final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.HealthRequestStats) */ {
 public:
  inline HealthRequestStats() : HealthRequestStats(nullptr) {}
  ~HealthRequestStats() override;
  explicit constexpr HealthRequestStats(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  HealthRequestStats(const HealthRequestStats& from);
  HealthRequestStats(HealthRequestStats&& from) noexcept
    : HealthRequestStats() {
    *this = ::std::move(from);
  }

  inline HealthRequestStats& operator=(const HealthRequestStats& from) {
    CopyFrom(from);
    return *this;
  }
  inline HealthRequestStats& operator=(HealthRequestStats&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const HealthRequestStats& default_instance() {
    return *internal_default_instance();
  }
  static inline const HealthRequestStats* internal_default_instance() {
    return reinterpret_cast<const HealthRequestStats*>(
               &_HealthRequestStats_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  friend void swap(HealthRequestStats& a, HealthRequestStats& b) {
    a.Swap(&b);
  }
  inline void Swap(HealthRequestStats* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(HealthRequestStats* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  HealthRequestStats* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<HealthRequestStats>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const HealthRequestStats& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const HealthRequestStats& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(HealthRequestStats* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.HealthRequestStats";
  }
  protected:
  explicit HealthRequestStats(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kSuccessFieldNumber = 1,
  };
  // .nvidia.inferenceserver.StatDuration success = 1;
  bool has_success() const;
  private:
  bool _internal_has_success() const;
  public:
  void clear_success();
  const ::nvidia::inferenceserver::StatDuration& success() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatDuration* release_success();
  ::nvidia::inferenceserver::StatDuration* mutable_success();
  void set_allocated_success(::nvidia::inferenceserver::StatDuration* success);
  private:
  const ::nvidia::inferenceserver::StatDuration& _internal_success() const;
  ::nvidia::inferenceserver::StatDuration* _internal_mutable_success();
  public:
  void unsafe_arena_set_allocated_success(
      ::nvidia::inferenceserver::StatDuration* success);
  ::nvidia::inferenceserver::StatDuration* unsafe_arena_release_success();

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.HealthRequestStats)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::nvidia::inferenceserver::StatDuration* success_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// -------------------------------------------------------------------

class InferRequestStats final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestStats) */ {
 public:
  inline InferRequestStats() : InferRequestStats(nullptr) {}
  ~InferRequestStats() override;
  explicit constexpr InferRequestStats(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferRequestStats(const InferRequestStats& from);
  InferRequestStats(InferRequestStats&& from) noexcept
    : InferRequestStats() {
    *this = ::std::move(from);
  }

  inline InferRequestStats& operator=(const InferRequestStats& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferRequestStats& operator=(InferRequestStats&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferRequestStats& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferRequestStats* internal_default_instance() {
    return reinterpret_cast<const InferRequestStats*>(
               &_InferRequestStats_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  friend void swap(InferRequestStats& a, InferRequestStats& b) {
    a.Swap(&b);
  }
  inline void Swap(InferRequestStats* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferRequestStats* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferRequestStats* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferRequestStats>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferRequestStats& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferRequestStats& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestStats* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferRequestStats";
  }
  protected:
  explicit InferRequestStats(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kSuccessFieldNumber = 1,
    kFailedFieldNumber = 2,
    kComputeFieldNumber = 3,
    kQueueFieldNumber = 4,
  };
  // .nvidia.inferenceserver.StatDuration success = 1;
  bool has_success() const;
  private:
  bool _internal_has_success() const;
  public:
  void clear_success();
  const ::nvidia::inferenceserver::StatDuration& success() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatDuration* release_success();
  ::nvidia::inferenceserver::StatDuration* mutable_success();
  void set_allocated_success(::nvidia::inferenceserver::StatDuration* success);
  private:
  const ::nvidia::inferenceserver::StatDuration& _internal_success() const;
  ::nvidia::inferenceserver::StatDuration* _internal_mutable_success();
  public:
  void unsafe_arena_set_allocated_success(
      ::nvidia::inferenceserver::StatDuration* success);
  ::nvidia::inferenceserver::StatDuration* unsafe_arena_release_success();

  // .nvidia.inferenceserver.StatDuration failed = 2;
  bool has_failed() const;
  private:
  bool _internal_has_failed() const;
  public:
  void clear_failed();
  const ::nvidia::inferenceserver::StatDuration& failed() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatDuration* release_failed();
  ::nvidia::inferenceserver::StatDuration* mutable_failed();
  void set_allocated_failed(::nvidia::inferenceserver::StatDuration* failed);
  private:
  const ::nvidia::inferenceserver::StatDuration& _internal_failed() const;
  ::nvidia::inferenceserver::StatDuration* _internal_mutable_failed();
  public:
  void unsafe_arena_set_allocated_failed(
      ::nvidia::inferenceserver::StatDuration* failed);
  ::nvidia::inferenceserver::StatDuration* unsafe_arena_release_failed();

  // .nvidia.inferenceserver.StatDuration compute = 3;
  bool has_compute() const;
  private:
  bool _internal_has_compute() const;
  public:
  void clear_compute();
  const ::nvidia::inferenceserver::StatDuration& compute() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatDuration* release_compute();
  ::nvidia::inferenceserver::StatDuration* mutable_compute();
  void set_allocated_compute(::nvidia::inferenceserver::StatDuration* compute);
  private:
  const ::nvidia::inferenceserver::StatDuration& _internal_compute() const;
  ::nvidia::inferenceserver::StatDuration* _internal_mutable_compute();
  public:
  void unsafe_arena_set_allocated_compute(
      ::nvidia::inferenceserver::StatDuration* compute);
  ::nvidia::inferenceserver::StatDuration* unsafe_arena_release_compute();

  // .nvidia.inferenceserver.StatDuration queue = 4;
  bool has_queue() const;
  private:
  bool _internal_has_queue() const;
  public:
  void clear_queue();
  const ::nvidia::inferenceserver::StatDuration& queue() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatDuration* release_queue();
  ::nvidia::inferenceserver::StatDuration* mutable_queue();
  void set_allocated_queue(::nvidia::inferenceserver::StatDuration* queue);
  private:
  const ::nvidia::inferenceserver::StatDuration& _internal_queue() const;
  ::nvidia::inferenceserver::StatDuration* _internal_mutable_queue();
  public:
  void unsafe_arena_set_allocated_queue(
      ::nvidia::inferenceserver::StatDuration* queue);
  ::nvidia::inferenceserver::StatDuration* unsafe_arena_release_queue();

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestStats)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::nvidia::inferenceserver::StatDuration* success_;
  ::nvidia::inferenceserver::StatDuration* failed_;
  ::nvidia::inferenceserver::StatDuration* compute_;
  ::nvidia::inferenceserver::StatDuration* queue_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// -------------------------------------------------------------------

class ModelVersionStatus_InferStatsEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<ModelVersionStatus_InferStatsEntry_DoNotUse, 
    uint32_t, ::nvidia::inferenceserver::InferRequestStats,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_UINT32,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<ModelVersionStatus_InferStatsEntry_DoNotUse, 
    uint32_t, ::nvidia::inferenceserver::InferRequestStats,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_UINT32,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> SuperType;
  ModelVersionStatus_InferStatsEntry_DoNotUse();
  explicit constexpr ModelVersionStatus_InferStatsEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit ModelVersionStatus_InferStatsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const ModelVersionStatus_InferStatsEntry_DoNotUse& other);
  static const ModelVersionStatus_InferStatsEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const ModelVersionStatus_InferStatsEntry_DoNotUse*>(&_ModelVersionStatus_InferStatsEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(void*) { return true; }
  static bool ValidateValue(void*) { return true; }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
};

// -------------------------------------------------------------------

class ModelVersionStatus final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.ModelVersionStatus) */ {
 public:
  inline ModelVersionStatus() : ModelVersionStatus(nullptr) {}
  ~ModelVersionStatus() override;
  explicit constexpr ModelVersionStatus(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  ModelVersionStatus(const ModelVersionStatus& from);
  ModelVersionStatus(ModelVersionStatus&& from) noexcept
    : ModelVersionStatus() {
    *this = ::std::move(from);
  }

  inline ModelVersionStatus& operator=(const ModelVersionStatus& from) {
    CopyFrom(from);
    return *this;
  }
  inline ModelVersionStatus& operator=(ModelVersionStatus&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const ModelVersionStatus& default_instance() {
    return *internal_default_instance();
  }
  static inline const ModelVersionStatus* internal_default_instance() {
    return reinterpret_cast<const ModelVersionStatus*>(
               &_ModelVersionStatus_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  friend void swap(ModelVersionStatus& a, ModelVersionStatus& b) {
    a.Swap(&b);
  }
  inline void Swap(ModelVersionStatus* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(ModelVersionStatus* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  ModelVersionStatus* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<ModelVersionStatus>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const ModelVersionStatus& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const ModelVersionStatus& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ModelVersionStatus* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.ModelVersionStatus";
  }
  protected:
  explicit ModelVersionStatus(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  enum : int {
    kInferStatsFieldNumber = 2,
    kModelExecutionCountFieldNumber = 3,
    kModelInferenceCountFieldNumber = 4,
    kReadyStateFieldNumber = 1,
  };
  // map<uint32, .nvidia.inferenceserver.InferRequestStats> infer_stats = 2;
  int infer_stats_size() const;
  private:
  int _internal_infer_stats_size() const;
  public:
  void clear_infer_stats();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >&
      _internal_infer_stats() const;
  ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >*
      _internal_mutable_infer_stats();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >&
      infer_stats() const;
  ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >*
      mutable_infer_stats();

  // uint64 model_execution_count = 3;
  void clear_model_execution_count();
  uint64_t model_execution_count() const;
  void set_model_execution_count(uint64_t value);
  private:
  uint64_t _internal_model_execution_count() const;
  void _internal_set_model_execution_count(uint64_t value);
  public:

  // uint64 model_inference_count = 4;
  void clear_model_inference_count();
  uint64_t model_inference_count() const;
  void set_model_inference_count(uint64_t value);
  private:
  uint64_t _internal_model_inference_count() const;
  void _internal_set_model_inference_count(uint64_t value);
  public:

  // .nvidia.inferenceserver.ModelReadyState ready_state = 1;
  void clear_ready_state();
  ::nvidia::inferenceserver::ModelReadyState ready_state() const;
  void set_ready_state(::nvidia::inferenceserver::ModelReadyState value);
  private:
  ::nvidia::inferenceserver::ModelReadyState _internal_ready_state() const;
  void _internal_set_ready_state(::nvidia::inferenceserver::ModelReadyState value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelVersionStatus)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::MapField<
      ModelVersionStatus_InferStatsEntry_DoNotUse,
      uint32_t, ::nvidia::inferenceserver::InferRequestStats,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_UINT32,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> infer_stats_;
  uint64_t model_execution_count_;
  uint64_t model_inference_count_;
  int ready_state_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// -------------------------------------------------------------------

class ModelStatus_VersionStatusEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<ModelStatus_VersionStatusEntry_DoNotUse, 
    int64_t, ::nvidia::inferenceserver::ModelVersionStatus,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT64,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<ModelStatus_VersionStatusEntry_DoNotUse, 
    int64_t, ::nvidia::inferenceserver::ModelVersionStatus,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT64,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> SuperType;
  ModelStatus_VersionStatusEntry_DoNotUse();
  explicit constexpr ModelStatus_VersionStatusEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit ModelStatus_VersionStatusEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const ModelStatus_VersionStatusEntry_DoNotUse& other);
  static const ModelStatus_VersionStatusEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const ModelStatus_VersionStatusEntry_DoNotUse*>(&_ModelStatus_VersionStatusEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(void*) { return true; }
  static bool ValidateValue(void*) { return true; }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
};

// -------------------------------------------------------------------

class ModelStatus final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.ModelStatus) */ {
 public:
  inline ModelStatus() : ModelStatus(nullptr) {}
  ~ModelStatus() override;
  explicit constexpr ModelStatus(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  ModelStatus(const ModelStatus& from);
  ModelStatus(ModelStatus&& from) noexcept
    : ModelStatus() {
    *this = ::std::move(from);
  }

  inline ModelStatus& operator=(const ModelStatus& from) {
    CopyFrom(from);
    return *this;
  }
  inline ModelStatus& operator=(ModelStatus&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const ModelStatus& default_instance() {
    return *internal_default_instance();
  }
  static inline const ModelStatus* internal_default_instance() {
    return reinterpret_cast<const ModelStatus*>(
               &_ModelStatus_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    8;

  friend void swap(ModelStatus& a, ModelStatus& b) {
    a.Swap(&b);
  }
  inline void Swap(ModelStatus* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(ModelStatus* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  ModelStatus* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<ModelStatus>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const ModelStatus& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const ModelStatus& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ModelStatus* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.ModelStatus";
  }
  protected:
  explicit ModelStatus(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  enum : int {
    kVersionStatusFieldNumber = 2,
    kConfigFieldNumber = 1,
  };
  // map<int64, .nvidia.inferenceserver.ModelVersionStatus> version_status = 2;
  int version_status_size() const;
  private:
  int _internal_version_status_size() const;
  public:
  void clear_version_status();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >&
      _internal_version_status() const;
  ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >*
      _internal_mutable_version_status();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >&
      version_status() const;
  ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >*
      mutable_version_status();

  // .nvidia.inferenceserver.ModelConfig config = 1;
  bool has_config() const;
  private:
  bool _internal_has_config() const;
  public:
  void clear_config();
  const ::nvidia::inferenceserver::ModelConfig& config() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::ModelConfig* release_config();
  ::nvidia::inferenceserver::ModelConfig* mutable_config();
  void set_allocated_config(::nvidia::inferenceserver::ModelConfig* config);
  private:
  const ::nvidia::inferenceserver::ModelConfig& _internal_config() const;
  ::nvidia::inferenceserver::ModelConfig* _internal_mutable_config();
  public:
  void unsafe_arena_set_allocated_config(
      ::nvidia::inferenceserver::ModelConfig* config);
  ::nvidia::inferenceserver::ModelConfig* unsafe_arena_release_config();

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ModelStatus)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::MapField<
      ModelStatus_VersionStatusEntry_DoNotUse,
      int64_t, ::nvidia::inferenceserver::ModelVersionStatus,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT64,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> version_status_;
  ::nvidia::inferenceserver::ModelConfig* config_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// -------------------------------------------------------------------

class ServerStatus_ModelStatusEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<ServerStatus_ModelStatusEntry_DoNotUse, 
    std::string, ::nvidia::inferenceserver::ModelStatus,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> {
public:
  typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry<ServerStatus_ModelStatusEntry_DoNotUse, 
    std::string, ::nvidia::inferenceserver::ModelStatus,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> SuperType;
  ServerStatus_ModelStatusEntry_DoNotUse();
  explicit constexpr ServerStatus_ModelStatusEntry_DoNotUse(
      ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
  explicit ServerStatus_ModelStatusEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  void MergeFrom(const ServerStatus_ModelStatusEntry_DoNotUse& other);
  static const ServerStatus_ModelStatusEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const ServerStatus_ModelStatusEntry_DoNotUse*>(&_ServerStatus_ModelStatusEntry_DoNotUse_default_instance_); }
  static bool ValidateKey(std::string* s) {
    return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s->data(), static_cast<int>(s->size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, "nvidia.inferenceserver.ServerStatus.ModelStatusEntry.key");
 }
  static bool ValidateValue(void*) { return true; }
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
};

// -------------------------------------------------------------------

class ServerStatus final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.ServerStatus) */ {
 public:
  inline ServerStatus() : ServerStatus(nullptr) {}
  ~ServerStatus() override;
  explicit constexpr ServerStatus(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  ServerStatus(const ServerStatus& from);
  ServerStatus(ServerStatus&& from) noexcept
    : ServerStatus() {
    *this = ::std::move(from);
  }

  inline ServerStatus& operator=(const ServerStatus& from) {
    CopyFrom(from);
    return *this;
  }
  inline ServerStatus& operator=(ServerStatus&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const ServerStatus& default_instance() {
    return *internal_default_instance();
  }
  static inline const ServerStatus* internal_default_instance() {
    return reinterpret_cast<const ServerStatus*>(
               &_ServerStatus_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    10;

  friend void swap(ServerStatus& a, ServerStatus& b) {
    a.Swap(&b);
  }
  inline void Swap(ServerStatus* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(ServerStatus* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  ServerStatus* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<ServerStatus>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const ServerStatus& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const ServerStatus& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ServerStatus* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.ServerStatus";
  }
  protected:
  explicit ServerStatus(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  enum : int {
    kModelStatusFieldNumber = 4,
    kIdFieldNumber = 1,
    kVersionFieldNumber = 2,
    kStatusStatsFieldNumber = 5,
    kProfileStatsFieldNumber = 6,
    kHealthStatsFieldNumber = 8,
    kUptimeNsFieldNumber = 3,
    kReadyStateFieldNumber = 7,
  };
  // map<string, .nvidia.inferenceserver.ModelStatus> model_status = 4;
  int model_status_size() const;
  private:
  int _internal_model_status_size() const;
  public:
  void clear_model_status();
  private:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >&
      _internal_model_status() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >*
      _internal_mutable_model_status();
  public:
  const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >&
      model_status() const;
  ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >*
      mutable_model_status();

  // string id = 1;
  void clear_id();
  const std::string& id() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_id(ArgT0&& arg0, ArgT... args);
  std::string* mutable_id();
  PROTOBUF_NODISCARD std::string* release_id();
  void set_allocated_id(std::string* id);
  private:
  const std::string& _internal_id() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_id(const std::string& value);
  std::string* _internal_mutable_id();
  public:

  // string version = 2;
  void clear_version();
  const std::string& version() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_version(ArgT0&& arg0, ArgT... args);
  std::string* mutable_version();
  PROTOBUF_NODISCARD std::string* release_version();
  void set_allocated_version(std::string* version);
  private:
  const std::string& _internal_version() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_version(const std::string& value);
  std::string* _internal_mutable_version();
  public:

  // .nvidia.inferenceserver.StatusRequestStats status_stats = 5;
  bool has_status_stats() const;
  private:
  bool _internal_has_status_stats() const;
  public:
  void clear_status_stats();
  const ::nvidia::inferenceserver::StatusRequestStats& status_stats() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::StatusRequestStats* release_status_stats();
  ::nvidia::inferenceserver::StatusRequestStats* mutable_status_stats();
  void set_allocated_status_stats(::nvidia::inferenceserver::StatusRequestStats* status_stats);
  private:
  const ::nvidia::inferenceserver::StatusRequestStats& _internal_status_stats() const;
  ::nvidia::inferenceserver::StatusRequestStats* _internal_mutable_status_stats();
  public:
  void unsafe_arena_set_allocated_status_stats(
      ::nvidia::inferenceserver::StatusRequestStats* status_stats);
  ::nvidia::inferenceserver::StatusRequestStats* unsafe_arena_release_status_stats();

  // .nvidia.inferenceserver.ProfileRequestStats profile_stats = 6;
  bool has_profile_stats() const;
  private:
  bool _internal_has_profile_stats() const;
  public:
  void clear_profile_stats();
  const ::nvidia::inferenceserver::ProfileRequestStats& profile_stats() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::ProfileRequestStats* release_profile_stats();
  ::nvidia::inferenceserver::ProfileRequestStats* mutable_profile_stats();
  void set_allocated_profile_stats(::nvidia::inferenceserver::ProfileRequestStats* profile_stats);
  private:
  const ::nvidia::inferenceserver::ProfileRequestStats& _internal_profile_stats() const;
  ::nvidia::inferenceserver::ProfileRequestStats* _internal_mutable_profile_stats();
  public:
  void unsafe_arena_set_allocated_profile_stats(
      ::nvidia::inferenceserver::ProfileRequestStats* profile_stats);
  ::nvidia::inferenceserver::ProfileRequestStats* unsafe_arena_release_profile_stats();

  // .nvidia.inferenceserver.HealthRequestStats health_stats = 8;
  bool has_health_stats() const;
  private:
  bool _internal_has_health_stats() const;
  public:
  void clear_health_stats();
  const ::nvidia::inferenceserver::HealthRequestStats& health_stats() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::HealthRequestStats* release_health_stats();
  ::nvidia::inferenceserver::HealthRequestStats* mutable_health_stats();
  void set_allocated_health_stats(::nvidia::inferenceserver::HealthRequestStats* health_stats);
  private:
  const ::nvidia::inferenceserver::HealthRequestStats& _internal_health_stats() const;
  ::nvidia::inferenceserver::HealthRequestStats* _internal_mutable_health_stats();
  public:
  void unsafe_arena_set_allocated_health_stats(
      ::nvidia::inferenceserver::HealthRequestStats* health_stats);
  ::nvidia::inferenceserver::HealthRequestStats* unsafe_arena_release_health_stats();

  // uint64 uptime_ns = 3;
  void clear_uptime_ns();
  uint64_t uptime_ns() const;
  void set_uptime_ns(uint64_t value);
  private:
  uint64_t _internal_uptime_ns() const;
  void _internal_set_uptime_ns(uint64_t value);
  public:

  // .nvidia.inferenceserver.ServerReadyState ready_state = 7;
  void clear_ready_state();
  ::nvidia::inferenceserver::ServerReadyState ready_state() const;
  void set_ready_state(::nvidia::inferenceserver::ServerReadyState value);
  private:
  ::nvidia::inferenceserver::ServerReadyState _internal_ready_state() const;
  void _internal_set_ready_state(::nvidia::inferenceserver::ServerReadyState value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.ServerStatus)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::MapField<
      ServerStatus_ModelStatusEntry_DoNotUse,
      std::string, ::nvidia::inferenceserver::ModelStatus,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING,
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_MESSAGE> model_status_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr id_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr version_;
  ::nvidia::inferenceserver::StatusRequestStats* status_stats_;
  ::nvidia::inferenceserver::ProfileRequestStats* profile_stats_;
  ::nvidia::inferenceserver::HealthRequestStats* health_stats_;
  uint64_t uptime_ns_;
  int ready_state_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_server_5fstatus_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// StatDuration

// uint64 count = 1;
inline void StatDuration::clear_count() {
  count_ = uint64_t{0u};
}
inline uint64_t StatDuration::_internal_count() const {
  return count_;
}
inline uint64_t StatDuration::count() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.StatDuration.count)
  return _internal_count();
}
inline void StatDuration::_internal_set_count(uint64_t value) {
  
  count_ = value;
}
inline void StatDuration::set_count(uint64_t value) {
  _internal_set_count(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.StatDuration.count)
}

// uint64 total_time_ns = 2;
inline void StatDuration::clear_total_time_ns() {
  total_time_ns_ = uint64_t{0u};
}
inline uint64_t StatDuration::_internal_total_time_ns() const {
  return total_time_ns_;
}
inline uint64_t StatDuration::total_time_ns() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.StatDuration.total_time_ns)
  return _internal_total_time_ns();
}
inline void StatDuration::_internal_set_total_time_ns(uint64_t value) {
  
  total_time_ns_ = value;
}
inline void StatDuration::set_total_time_ns(uint64_t value) {
  _internal_set_total_time_ns(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.StatDuration.total_time_ns)
}

// -------------------------------------------------------------------

// StatusRequestStats

// .nvidia.inferenceserver.StatDuration success = 1;
inline bool StatusRequestStats::_internal_has_success() const {
  return this != internal_default_instance() && success_ != nullptr;
}
inline bool StatusRequestStats::has_success() const {
  return _internal_has_success();
}
inline void StatusRequestStats::clear_success() {
  if (GetArenaForAllocation() == nullptr && success_ != nullptr) {
    delete success_;
  }
  success_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatDuration& StatusRequestStats::_internal_success() const {
  const ::nvidia::inferenceserver::StatDuration* p = success_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatDuration&>(
      ::nvidia::inferenceserver::_StatDuration_default_instance_);
}
inline const ::nvidia::inferenceserver::StatDuration& StatusRequestStats::success() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.StatusRequestStats.success)
  return _internal_success();
}
inline void StatusRequestStats::unsafe_arena_set_allocated_success(
    ::nvidia::inferenceserver::StatDuration* success) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(success_);
  }
  success_ = success;
  if (success) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.StatusRequestStats.success)
}
inline ::nvidia::inferenceserver::StatDuration* StatusRequestStats::release_success() {
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* StatusRequestStats::unsafe_arena_release_success() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.StatusRequestStats.success)
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* StatusRequestStats::_internal_mutable_success() {
  
  if (success_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(GetArenaForAllocation());
    success_ = p;
  }
  return success_;
}
inline ::nvidia::inferenceserver::StatDuration* StatusRequestStats::mutable_success() {
  ::nvidia::inferenceserver::StatDuration* _msg = _internal_mutable_success();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.StatusRequestStats.success)
  return _msg;
}
inline void StatusRequestStats::set_allocated_success(::nvidia::inferenceserver::StatDuration* success) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete success_;
  }
  if (success) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatDuration>::GetOwningArena(success);
    if (message_arena != submessage_arena) {
      success = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, success, submessage_arena);
    }
    
  } else {
    
  }
  success_ = success;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.StatusRequestStats.success)
}

// -------------------------------------------------------------------

// ProfileRequestStats

// .nvidia.inferenceserver.StatDuration success = 1;
inline bool ProfileRequestStats::_internal_has_success() const {
  return this != internal_default_instance() && success_ != nullptr;
}
inline bool ProfileRequestStats::has_success() const {
  return _internal_has_success();
}
inline void ProfileRequestStats::clear_success() {
  if (GetArenaForAllocation() == nullptr && success_ != nullptr) {
    delete success_;
  }
  success_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatDuration& ProfileRequestStats::_internal_success() const {
  const ::nvidia::inferenceserver::StatDuration* p = success_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatDuration&>(
      ::nvidia::inferenceserver::_StatDuration_default_instance_);
}
inline const ::nvidia::inferenceserver::StatDuration& ProfileRequestStats::success() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ProfileRequestStats.success)
  return _internal_success();
}
inline void ProfileRequestStats::unsafe_arena_set_allocated_success(
    ::nvidia::inferenceserver::StatDuration* success) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(success_);
  }
  success_ = success;
  if (success) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.ProfileRequestStats.success)
}
inline ::nvidia::inferenceserver::StatDuration* ProfileRequestStats::release_success() {
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* ProfileRequestStats::unsafe_arena_release_success() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.ProfileRequestStats.success)
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* ProfileRequestStats::_internal_mutable_success() {
  
  if (success_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(GetArenaForAllocation());
    success_ = p;
  }
  return success_;
}
inline ::nvidia::inferenceserver::StatDuration* ProfileRequestStats::mutable_success() {
  ::nvidia::inferenceserver::StatDuration* _msg = _internal_mutable_success();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.ProfileRequestStats.success)
  return _msg;
}
inline void ProfileRequestStats::set_allocated_success(::nvidia::inferenceserver::StatDuration* success) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete success_;
  }
  if (success) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatDuration>::GetOwningArena(success);
    if (message_arena != submessage_arena) {
      success = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, success, submessage_arena);
    }
    
  } else {
    
  }
  success_ = success;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ProfileRequestStats.success)
}

// -------------------------------------------------------------------

// HealthRequestStats

// .nvidia.inferenceserver.StatDuration success = 1;
inline bool HealthRequestStats::_internal_has_success() const {
  return this != internal_default_instance() && success_ != nullptr;
}
inline bool HealthRequestStats::has_success() const {
  return _internal_has_success();
}
inline void HealthRequestStats::clear_success() {
  if (GetArenaForAllocation() == nullptr && success_ != nullptr) {
    delete success_;
  }
  success_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatDuration& HealthRequestStats::_internal_success() const {
  const ::nvidia::inferenceserver::StatDuration* p = success_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatDuration&>(
      ::nvidia::inferenceserver::_StatDuration_default_instance_);
}
inline const ::nvidia::inferenceserver::StatDuration& HealthRequestStats::success() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.HealthRequestStats.success)
  return _internal_success();
}
inline void HealthRequestStats::unsafe_arena_set_allocated_success(
    ::nvidia::inferenceserver::StatDuration* success) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(success_);
  }
  success_ = success;
  if (success) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.HealthRequestStats.success)
}
inline ::nvidia::inferenceserver::StatDuration* HealthRequestStats::release_success() {
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* HealthRequestStats::unsafe_arena_release_success() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.HealthRequestStats.success)
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* HealthRequestStats::_internal_mutable_success() {
  
  if (success_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(GetArenaForAllocation());
    success_ = p;
  }
  return success_;
}
inline ::nvidia::inferenceserver::StatDuration* HealthRequestStats::mutable_success() {
  ::nvidia::inferenceserver::StatDuration* _msg = _internal_mutable_success();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.HealthRequestStats.success)
  return _msg;
}
inline void HealthRequestStats::set_allocated_success(::nvidia::inferenceserver::StatDuration* success) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete success_;
  }
  if (success) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatDuration>::GetOwningArena(success);
    if (message_arena != submessage_arena) {
      success = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, success, submessage_arena);
    }
    
  } else {
    
  }
  success_ = success;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.HealthRequestStats.success)
}

// -------------------------------------------------------------------

// InferRequestStats

// .nvidia.inferenceserver.StatDuration success = 1;
inline bool InferRequestStats::_internal_has_success() const {
  return this != internal_default_instance() && success_ != nullptr;
}
inline bool InferRequestStats::has_success() const {
  return _internal_has_success();
}
inline void InferRequestStats::clear_success() {
  if (GetArenaForAllocation() == nullptr && success_ != nullptr) {
    delete success_;
  }
  success_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::_internal_success() const {
  const ::nvidia::inferenceserver::StatDuration* p = success_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatDuration&>(
      ::nvidia::inferenceserver::_StatDuration_default_instance_);
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::success() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestStats.success)
  return _internal_success();
}
inline void InferRequestStats::unsafe_arena_set_allocated_success(
    ::nvidia::inferenceserver::StatDuration* success) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(success_);
  }
  success_ = success;
  if (success) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.InferRequestStats.success)
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::release_success() {
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::unsafe_arena_release_success() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestStats.success)
  
  ::nvidia::inferenceserver::StatDuration* temp = success_;
  success_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::_internal_mutable_success() {
  
  if (success_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(GetArenaForAllocation());
    success_ = p;
  }
  return success_;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::mutable_success() {
  ::nvidia::inferenceserver::StatDuration* _msg = _internal_mutable_success();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestStats.success)
  return _msg;
}
inline void InferRequestStats::set_allocated_success(::nvidia::inferenceserver::StatDuration* success) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete success_;
  }
  if (success) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatDuration>::GetOwningArena(success);
    if (message_arena != submessage_arena) {
      success = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, success, submessage_arena);
    }
    
  } else {
    
  }
  success_ = success;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestStats.success)
}

// .nvidia.inferenceserver.StatDuration failed = 2;
inline bool InferRequestStats::_internal_has_failed() const {
  return this != internal_default_instance() && failed_ != nullptr;
}
inline bool InferRequestStats::has_failed() const {
  return _internal_has_failed();
}
inline void InferRequestStats::clear_failed() {
  if (GetArenaForAllocation() == nullptr && failed_ != nullptr) {
    delete failed_;
  }
  failed_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::_internal_failed() const {
  const ::nvidia::inferenceserver::StatDuration* p = failed_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatDuration&>(
      ::nvidia::inferenceserver::_StatDuration_default_instance_);
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::failed() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestStats.failed)
  return _internal_failed();
}
inline void InferRequestStats::unsafe_arena_set_allocated_failed(
    ::nvidia::inferenceserver::StatDuration* failed) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(failed_);
  }
  failed_ = failed;
  if (failed) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.InferRequestStats.failed)
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::release_failed() {
  
  ::nvidia::inferenceserver::StatDuration* temp = failed_;
  failed_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::unsafe_arena_release_failed() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestStats.failed)
  
  ::nvidia::inferenceserver::StatDuration* temp = failed_;
  failed_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::_internal_mutable_failed() {
  
  if (failed_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(GetArenaForAllocation());
    failed_ = p;
  }
  return failed_;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::mutable_failed() {
  ::nvidia::inferenceserver::StatDuration* _msg = _internal_mutable_failed();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestStats.failed)
  return _msg;
}
inline void InferRequestStats::set_allocated_failed(::nvidia::inferenceserver::StatDuration* failed) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete failed_;
  }
  if (failed) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatDuration>::GetOwningArena(failed);
    if (message_arena != submessage_arena) {
      failed = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, failed, submessage_arena);
    }
    
  } else {
    
  }
  failed_ = failed;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestStats.failed)
}

// .nvidia.inferenceserver.StatDuration compute = 3;
inline bool InferRequestStats::_internal_has_compute() const {
  return this != internal_default_instance() && compute_ != nullptr;
}
inline bool InferRequestStats::has_compute() const {
  return _internal_has_compute();
}
inline void InferRequestStats::clear_compute() {
  if (GetArenaForAllocation() == nullptr && compute_ != nullptr) {
    delete compute_;
  }
  compute_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::_internal_compute() const {
  const ::nvidia::inferenceserver::StatDuration* p = compute_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatDuration&>(
      ::nvidia::inferenceserver::_StatDuration_default_instance_);
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::compute() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestStats.compute)
  return _internal_compute();
}
inline void InferRequestStats::unsafe_arena_set_allocated_compute(
    ::nvidia::inferenceserver::StatDuration* compute) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(compute_);
  }
  compute_ = compute;
  if (compute) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.InferRequestStats.compute)
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::release_compute() {
  
  ::nvidia::inferenceserver::StatDuration* temp = compute_;
  compute_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::unsafe_arena_release_compute() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestStats.compute)
  
  ::nvidia::inferenceserver::StatDuration* temp = compute_;
  compute_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::_internal_mutable_compute() {
  
  if (compute_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(GetArenaForAllocation());
    compute_ = p;
  }
  return compute_;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::mutable_compute() {
  ::nvidia::inferenceserver::StatDuration* _msg = _internal_mutable_compute();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestStats.compute)
  return _msg;
}
inline void InferRequestStats::set_allocated_compute(::nvidia::inferenceserver::StatDuration* compute) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete compute_;
  }
  if (compute) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatDuration>::GetOwningArena(compute);
    if (message_arena != submessage_arena) {
      compute = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, compute, submessage_arena);
    }
    
  } else {
    
  }
  compute_ = compute;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestStats.compute)
}

// .nvidia.inferenceserver.StatDuration queue = 4;
inline bool InferRequestStats::_internal_has_queue() const {
  return this != internal_default_instance() && queue_ != nullptr;
}
inline bool InferRequestStats::has_queue() const {
  return _internal_has_queue();
}
inline void InferRequestStats::clear_queue() {
  if (GetArenaForAllocation() == nullptr && queue_ != nullptr) {
    delete queue_;
  }
  queue_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::_internal_queue() const {
  const ::nvidia::inferenceserver::StatDuration* p = queue_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatDuration&>(
      ::nvidia::inferenceserver::_StatDuration_default_instance_);
}
inline const ::nvidia::inferenceserver::StatDuration& InferRequestStats::queue() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestStats.queue)
  return _internal_queue();
}
inline void InferRequestStats::unsafe_arena_set_allocated_queue(
    ::nvidia::inferenceserver::StatDuration* queue) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(queue_);
  }
  queue_ = queue;
  if (queue) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.InferRequestStats.queue)
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::release_queue() {
  
  ::nvidia::inferenceserver::StatDuration* temp = queue_;
  queue_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::unsafe_arena_release_queue() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestStats.queue)
  
  ::nvidia::inferenceserver::StatDuration* temp = queue_;
  queue_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::_internal_mutable_queue() {
  
  if (queue_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatDuration>(GetArenaForAllocation());
    queue_ = p;
  }
  return queue_;
}
inline ::nvidia::inferenceserver::StatDuration* InferRequestStats::mutable_queue() {
  ::nvidia::inferenceserver::StatDuration* _msg = _internal_mutable_queue();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestStats.queue)
  return _msg;
}
inline void InferRequestStats::set_allocated_queue(::nvidia::inferenceserver::StatDuration* queue) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete queue_;
  }
  if (queue) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatDuration>::GetOwningArena(queue);
    if (message_arena != submessage_arena) {
      queue = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, queue, submessage_arena);
    }
    
  } else {
    
  }
  queue_ = queue;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestStats.queue)
}

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// ModelVersionStatus

// .nvidia.inferenceserver.ModelReadyState ready_state = 1;
inline void ModelVersionStatus::clear_ready_state() {
  ready_state_ = 0;
}
inline ::nvidia::inferenceserver::ModelReadyState ModelVersionStatus::_internal_ready_state() const {
  return static_cast< ::nvidia::inferenceserver::ModelReadyState >(ready_state_);
}
inline ::nvidia::inferenceserver::ModelReadyState ModelVersionStatus::ready_state() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ModelVersionStatus.ready_state)
  return _internal_ready_state();
}
inline void ModelVersionStatus::_internal_set_ready_state(::nvidia::inferenceserver::ModelReadyState value) {
  
  ready_state_ = value;
}
inline void ModelVersionStatus::set_ready_state(::nvidia::inferenceserver::ModelReadyState value) {
  _internal_set_ready_state(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.ModelVersionStatus.ready_state)
}

// map<uint32, .nvidia.inferenceserver.InferRequestStats> infer_stats = 2;
inline int ModelVersionStatus::_internal_infer_stats_size() const {
  return infer_stats_.size();
}
inline int ModelVersionStatus::infer_stats_size() const {
  return _internal_infer_stats_size();
}
inline void ModelVersionStatus::clear_infer_stats() {
  infer_stats_.Clear();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >&
ModelVersionStatus::_internal_infer_stats() const {
  return infer_stats_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >&
ModelVersionStatus::infer_stats() const {
  // @@protoc_insertion_point(field_map:nvidia.inferenceserver.ModelVersionStatus.infer_stats)
  return _internal_infer_stats();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >*
ModelVersionStatus::_internal_mutable_infer_stats() {
  return infer_stats_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< uint32_t, ::nvidia::inferenceserver::InferRequestStats >*
ModelVersionStatus::mutable_infer_stats() {
  // @@protoc_insertion_point(field_mutable_map:nvidia.inferenceserver.ModelVersionStatus.infer_stats)
  return _internal_mutable_infer_stats();
}

// uint64 model_execution_count = 3;
inline void ModelVersionStatus::clear_model_execution_count() {
  model_execution_count_ = uint64_t{0u};
}
inline uint64_t ModelVersionStatus::_internal_model_execution_count() const {
  return model_execution_count_;
}
inline uint64_t ModelVersionStatus::model_execution_count() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ModelVersionStatus.model_execution_count)
  return _internal_model_execution_count();
}
inline void ModelVersionStatus::_internal_set_model_execution_count(uint64_t value) {
  
  model_execution_count_ = value;
}
inline void ModelVersionStatus::set_model_execution_count(uint64_t value) {
  _internal_set_model_execution_count(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.ModelVersionStatus.model_execution_count)
}

// uint64 model_inference_count = 4;
inline void ModelVersionStatus::clear_model_inference_count() {
  model_inference_count_ = uint64_t{0u};
}
inline uint64_t ModelVersionStatus::_internal_model_inference_count() const {
  return model_inference_count_;
}
inline uint64_t ModelVersionStatus::model_inference_count() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ModelVersionStatus.model_inference_count)
  return _internal_model_inference_count();
}
inline void ModelVersionStatus::_internal_set_model_inference_count(uint64_t value) {
  
  model_inference_count_ = value;
}
inline void ModelVersionStatus::set_model_inference_count(uint64_t value) {
  _internal_set_model_inference_count(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.ModelVersionStatus.model_inference_count)
}

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// ModelStatus

// .nvidia.inferenceserver.ModelConfig config = 1;
inline bool ModelStatus::_internal_has_config() const {
  return this != internal_default_instance() && config_ != nullptr;
}
inline bool ModelStatus::has_config() const {
  return _internal_has_config();
}
inline const ::nvidia::inferenceserver::ModelConfig& ModelStatus::_internal_config() const {
  const ::nvidia::inferenceserver::ModelConfig* p = config_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::ModelConfig&>(
      ::nvidia::inferenceserver::_ModelConfig_default_instance_);
}
inline const ::nvidia::inferenceserver::ModelConfig& ModelStatus::config() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ModelStatus.config)
  return _internal_config();
}
inline void ModelStatus::unsafe_arena_set_allocated_config(
    ::nvidia::inferenceserver::ModelConfig* config) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(config_);
  }
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.ModelStatus.config)
}
inline ::nvidia::inferenceserver::ModelConfig* ModelStatus::release_config() {
  
  ::nvidia::inferenceserver::ModelConfig* temp = config_;
  config_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::ModelConfig* ModelStatus::unsafe_arena_release_config() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.ModelStatus.config)
  
  ::nvidia::inferenceserver::ModelConfig* temp = config_;
  config_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::ModelConfig* ModelStatus::_internal_mutable_config() {
  
  if (config_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::ModelConfig>(GetArenaForAllocation());
    config_ = p;
  }
  return config_;
}
inline ::nvidia::inferenceserver::ModelConfig* ModelStatus::mutable_config() {
  ::nvidia::inferenceserver::ModelConfig* _msg = _internal_mutable_config();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.ModelStatus.config)
  return _msg;
}
inline void ModelStatus::set_allocated_config(::nvidia::inferenceserver::ModelConfig* config) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::PROTOBUF_NAMESPACE_ID::MessageLite*>(config_);
  }
  if (config) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<
            ::PROTOBUF_NAMESPACE_ID::MessageLite>::GetOwningArena(
                reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(config));
    if (message_arena != submessage_arena) {
      config = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, config, submessage_arena);
    }
    
  } else {
    
  }
  config_ = config;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ModelStatus.config)
}

// map<int64, .nvidia.inferenceserver.ModelVersionStatus> version_status = 2;
inline int ModelStatus::_internal_version_status_size() const {
  return version_status_.size();
}
inline int ModelStatus::version_status_size() const {
  return _internal_version_status_size();
}
inline void ModelStatus::clear_version_status() {
  version_status_.Clear();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >&
ModelStatus::_internal_version_status() const {
  return version_status_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >&
ModelStatus::version_status() const {
  // @@protoc_insertion_point(field_map:nvidia.inferenceserver.ModelStatus.version_status)
  return _internal_version_status();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >*
ModelStatus::_internal_mutable_version_status() {
  return version_status_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< int64_t, ::nvidia::inferenceserver::ModelVersionStatus >*
ModelStatus::mutable_version_status() {
  // @@protoc_insertion_point(field_mutable_map:nvidia.inferenceserver.ModelStatus.version_status)
  return _internal_mutable_version_status();
}

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// ServerStatus

// string id = 1;
inline void ServerStatus::clear_id() {
  id_.ClearToEmpty();
}
inline const std::string& ServerStatus::id() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ServerStatus.id)
  return _internal_id();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void ServerStatus::set_id(ArgT0&& arg0, ArgT... args) {
 
 id_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.ServerStatus.id)
}
inline std::string* ServerStatus::mutable_id() {
  std::string* _s = _internal_mutable_id();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.ServerStatus.id)
  return _s;
}
inline const std::string& ServerStatus::_internal_id() const {
  return id_.Get();
}
inline void ServerStatus::_internal_set_id(const std::string& value) {
  
  id_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* ServerStatus::_internal_mutable_id() {
  
  return id_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* ServerStatus::release_id() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.ServerStatus.id)
  return id_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void ServerStatus::set_allocated_id(std::string* id) {
  if (id != nullptr) {
    
  } else {
    
  }
  id_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), id,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (id_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    id_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ServerStatus.id)
}

// string version = 2;
inline void ServerStatus::clear_version() {
  version_.ClearToEmpty();
}
inline const std::string& ServerStatus::version() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ServerStatus.version)
  return _internal_version();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void ServerStatus::set_version(ArgT0&& arg0, ArgT... args) {
 
 version_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.ServerStatus.version)
}
inline std::string* ServerStatus::mutable_version() {
  std::string* _s = _internal_mutable_version();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.ServerStatus.version)
  return _s;
}
inline const std::string& ServerStatus::_internal_version() const {
  return version_.Get();
}
inline void ServerStatus::_internal_set_version(const std::string& value) {
  
  version_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* ServerStatus::_internal_mutable_version() {
  
  return version_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* ServerStatus::release_version() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.ServerStatus.version)
  return version_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void ServerStatus::set_allocated_version(std::string* version) {
  if (version != nullptr) {
    
  } else {
    
  }
  version_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), version,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (version_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    version_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ServerStatus.version)
}

// .nvidia.inferenceserver.ServerReadyState ready_state = 7;
inline void ServerStatus::clear_ready_state() {
  ready_state_ = 0;
}
inline ::nvidia::inferenceserver::ServerReadyState ServerStatus::_internal_ready_state() const {
  return static_cast< ::nvidia::inferenceserver::ServerReadyState >(ready_state_);
}
inline ::nvidia::inferenceserver::ServerReadyState ServerStatus::ready_state() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ServerStatus.ready_state)
  return _internal_ready_state();
}
inline void ServerStatus::_internal_set_ready_state(::nvidia::inferenceserver::ServerReadyState value) {
  
  ready_state_ = value;
}
inline void ServerStatus::set_ready_state(::nvidia::inferenceserver::ServerReadyState value) {
  _internal_set_ready_state(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.ServerStatus.ready_state)
}

// uint64 uptime_ns = 3;
inline void ServerStatus::clear_uptime_ns() {
  uptime_ns_ = uint64_t{0u};
}
inline uint64_t ServerStatus::_internal_uptime_ns() const {
  return uptime_ns_;
}
inline uint64_t ServerStatus::uptime_ns() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ServerStatus.uptime_ns)
  return _internal_uptime_ns();
}
inline void ServerStatus::_internal_set_uptime_ns(uint64_t value) {
  
  uptime_ns_ = value;
}
inline void ServerStatus::set_uptime_ns(uint64_t value) {
  _internal_set_uptime_ns(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.ServerStatus.uptime_ns)
}

// map<string, .nvidia.inferenceserver.ModelStatus> model_status = 4;
inline int ServerStatus::_internal_model_status_size() const {
  return model_status_.size();
}
inline int ServerStatus::model_status_size() const {
  return _internal_model_status_size();
}
inline void ServerStatus::clear_model_status() {
  model_status_.Clear();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >&
ServerStatus::_internal_model_status() const {
  return model_status_.GetMap();
}
inline const ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >&
ServerStatus::model_status() const {
  // @@protoc_insertion_point(field_map:nvidia.inferenceserver.ServerStatus.model_status)
  return _internal_model_status();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >*
ServerStatus::_internal_mutable_model_status() {
  return model_status_.MutableMap();
}
inline ::PROTOBUF_NAMESPACE_ID::Map< std::string, ::nvidia::inferenceserver::ModelStatus >*
ServerStatus::mutable_model_status() {
  // @@protoc_insertion_point(field_mutable_map:nvidia.inferenceserver.ServerStatus.model_status)
  return _internal_mutable_model_status();
}

// .nvidia.inferenceserver.StatusRequestStats status_stats = 5;
inline bool ServerStatus::_internal_has_status_stats() const {
  return this != internal_default_instance() && status_stats_ != nullptr;
}
inline bool ServerStatus::has_status_stats() const {
  return _internal_has_status_stats();
}
inline void ServerStatus::clear_status_stats() {
  if (GetArenaForAllocation() == nullptr && status_stats_ != nullptr) {
    delete status_stats_;
  }
  status_stats_ = nullptr;
}
inline const ::nvidia::inferenceserver::StatusRequestStats& ServerStatus::_internal_status_stats() const {
  const ::nvidia::inferenceserver::StatusRequestStats* p = status_stats_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::StatusRequestStats&>(
      ::nvidia::inferenceserver::_StatusRequestStats_default_instance_);
}
inline const ::nvidia::inferenceserver::StatusRequestStats& ServerStatus::status_stats() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ServerStatus.status_stats)
  return _internal_status_stats();
}
inline void ServerStatus::unsafe_arena_set_allocated_status_stats(
    ::nvidia::inferenceserver::StatusRequestStats* status_stats) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(status_stats_);
  }
  status_stats_ = status_stats;
  if (status_stats) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.ServerStatus.status_stats)
}
inline ::nvidia::inferenceserver::StatusRequestStats* ServerStatus::release_status_stats() {
  
  ::nvidia::inferenceserver::StatusRequestStats* temp = status_stats_;
  status_stats_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::StatusRequestStats* ServerStatus::unsafe_arena_release_status_stats() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.ServerStatus.status_stats)
  
  ::nvidia::inferenceserver::StatusRequestStats* temp = status_stats_;
  status_stats_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::StatusRequestStats* ServerStatus::_internal_mutable_status_stats() {
  
  if (status_stats_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::StatusRequestStats>(GetArenaForAllocation());
    status_stats_ = p;
  }
  return status_stats_;
}
inline ::nvidia::inferenceserver::StatusRequestStats* ServerStatus::mutable_status_stats() {
  ::nvidia::inferenceserver::StatusRequestStats* _msg = _internal_mutable_status_stats();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.ServerStatus.status_stats)
  return _msg;
}
inline void ServerStatus::set_allocated_status_stats(::nvidia::inferenceserver::StatusRequestStats* status_stats) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete status_stats_;
  }
  if (status_stats) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::StatusRequestStats>::GetOwningArena(status_stats);
    if (message_arena != submessage_arena) {
      status_stats = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, status_stats, submessage_arena);
    }
    
  } else {
    
  }
  status_stats_ = status_stats;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ServerStatus.status_stats)
}

// .nvidia.inferenceserver.ProfileRequestStats profile_stats = 6;
inline bool ServerStatus::_internal_has_profile_stats() const {
  return this != internal_default_instance() && profile_stats_ != nullptr;
}
inline bool ServerStatus::has_profile_stats() const {
  return _internal_has_profile_stats();
}
inline void ServerStatus::clear_profile_stats() {
  if (GetArenaForAllocation() == nullptr && profile_stats_ != nullptr) {
    delete profile_stats_;
  }
  profile_stats_ = nullptr;
}
inline const ::nvidia::inferenceserver::ProfileRequestStats& ServerStatus::_internal_profile_stats() const {
  const ::nvidia::inferenceserver::ProfileRequestStats* p = profile_stats_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::ProfileRequestStats&>(
      ::nvidia::inferenceserver::_ProfileRequestStats_default_instance_);
}
inline const ::nvidia::inferenceserver::ProfileRequestStats& ServerStatus::profile_stats() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ServerStatus.profile_stats)
  return _internal_profile_stats();
}
inline void ServerStatus::unsafe_arena_set_allocated_profile_stats(
    ::nvidia::inferenceserver::ProfileRequestStats* profile_stats) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(profile_stats_);
  }
  profile_stats_ = profile_stats;
  if (profile_stats) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.ServerStatus.profile_stats)
}
inline ::nvidia::inferenceserver::ProfileRequestStats* ServerStatus::release_profile_stats() {
  
  ::nvidia::inferenceserver::ProfileRequestStats* temp = profile_stats_;
  profile_stats_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::ProfileRequestStats* ServerStatus::unsafe_arena_release_profile_stats() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.ServerStatus.profile_stats)
  
  ::nvidia::inferenceserver::ProfileRequestStats* temp = profile_stats_;
  profile_stats_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::ProfileRequestStats* ServerStatus::_internal_mutable_profile_stats() {
  
  if (profile_stats_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::ProfileRequestStats>(GetArenaForAllocation());
    profile_stats_ = p;
  }
  return profile_stats_;
}
inline ::nvidia::inferenceserver::ProfileRequestStats* ServerStatus::mutable_profile_stats() {
  ::nvidia::inferenceserver::ProfileRequestStats* _msg = _internal_mutable_profile_stats();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.ServerStatus.profile_stats)
  return _msg;
}
inline void ServerStatus::set_allocated_profile_stats(::nvidia::inferenceserver::ProfileRequestStats* profile_stats) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete profile_stats_;
  }
  if (profile_stats) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::ProfileRequestStats>::GetOwningArena(profile_stats);
    if (message_arena != submessage_arena) {
      profile_stats = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, profile_stats, submessage_arena);
    }
    
  } else {
    
  }
  profile_stats_ = profile_stats;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ServerStatus.profile_stats)
}

// .nvidia.inferenceserver.HealthRequestStats health_stats = 8;
inline bool ServerStatus::_internal_has_health_stats() const {
  return this != internal_default_instance() && health_stats_ != nullptr;
}
inline bool ServerStatus::has_health_stats() const {
  return _internal_has_health_stats();
}
inline void ServerStatus::clear_health_stats() {
  if (GetArenaForAllocation() == nullptr && health_stats_ != nullptr) {
    delete health_stats_;
  }
  health_stats_ = nullptr;
}
inline const ::nvidia::inferenceserver::HealthRequestStats& ServerStatus::_internal_health_stats() const {
  const ::nvidia::inferenceserver::HealthRequestStats* p = health_stats_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::HealthRequestStats&>(
      ::nvidia::inferenceserver::_HealthRequestStats_default_instance_);
}
inline const ::nvidia::inferenceserver::HealthRequestStats& ServerStatus::health_stats() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.ServerStatus.health_stats)
  return _internal_health_stats();
}
inline void ServerStatus::unsafe_arena_set_allocated_health_stats(
    ::nvidia::inferenceserver::HealthRequestStats* health_stats) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(health_stats_);
  }
  health_stats_ = health_stats;
  if (health_stats) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.ServerStatus.health_stats)
}
inline ::nvidia::inferenceserver::HealthRequestStats* ServerStatus::release_health_stats() {
  
  ::nvidia::inferenceserver::HealthRequestStats* temp = health_stats_;
  health_stats_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::HealthRequestStats* ServerStatus::unsafe_arena_release_health_stats() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.ServerStatus.health_stats)
  
  ::nvidia::inferenceserver::HealthRequestStats* temp = health_stats_;
  health_stats_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::HealthRequestStats* ServerStatus::_internal_mutable_health_stats() {
  
  if (health_stats_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::HealthRequestStats>(GetArenaForAllocation());
    health_stats_ = p;
  }
  return health_stats_;
}
inline ::nvidia::inferenceserver::HealthRequestStats* ServerStatus::mutable_health_stats() {
  ::nvidia::inferenceserver::HealthRequestStats* _msg = _internal_mutable_health_stats();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.ServerStatus.health_stats)
  return _msg;
}
inline void ServerStatus::set_allocated_health_stats(::nvidia::inferenceserver::HealthRequestStats* health_stats) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete health_stats_;
  }
  if (health_stats) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::HealthRequestStats>::GetOwningArena(health_stats);
    if (message_arena != submessage_arena) {
      health_stats = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, health_stats, submessage_arena);
    }
    
  } else {
    
  }
  health_stats_ = health_stats;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ServerStatus.health_stats)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace inferenceserver
}  // namespace nvidia

PROTOBUF_NAMESPACE_OPEN

template <> struct is_proto_enum< ::nvidia::inferenceserver::ModelReadyState> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::nvidia::inferenceserver::ModelReadyState>() {
  return ::nvidia::inferenceserver::ModelReadyState_descriptor();
}
template <> struct is_proto_enum< ::nvidia::inferenceserver::ServerReadyState> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::nvidia::inferenceserver::ServerReadyState>() {
  return ::nvidia::inferenceserver::ServerReadyState_descriptor();
}

PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_server_5fstatus_2eproto
