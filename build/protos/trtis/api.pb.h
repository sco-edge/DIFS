// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: api.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_api_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_api_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3019000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3019004 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata_lite.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_api_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_api_2eproto {
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTableField entries[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::AuxiliaryParseTableField aux[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::ParseTable schema[9]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::PROTOBUF_NAMESPACE_ID::internal::FieldMetadata field_metadata[];
  static const ::PROTOBUF_NAMESPACE_ID::internal::SerializationTable serialization_table[];
  static const uint32_t offsets[];
};
extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_api_2eproto;
namespace nvidia {
namespace inferenceserver {
class InferRequestHeader;
struct InferRequestHeaderDefaultTypeInternal;
extern InferRequestHeaderDefaultTypeInternal _InferRequestHeader_default_instance_;
class InferRequestHeader_Input;
struct InferRequestHeader_InputDefaultTypeInternal;
extern InferRequestHeader_InputDefaultTypeInternal _InferRequestHeader_Input_default_instance_;
class InferRequestHeader_Output;
struct InferRequestHeader_OutputDefaultTypeInternal;
extern InferRequestHeader_OutputDefaultTypeInternal _InferRequestHeader_Output_default_instance_;
class InferRequestHeader_Output_Class;
struct InferRequestHeader_Output_ClassDefaultTypeInternal;
extern InferRequestHeader_Output_ClassDefaultTypeInternal _InferRequestHeader_Output_Class_default_instance_;
class InferResponseHeader;
struct InferResponseHeaderDefaultTypeInternal;
extern InferResponseHeaderDefaultTypeInternal _InferResponseHeader_default_instance_;
class InferResponseHeader_Output;
struct InferResponseHeader_OutputDefaultTypeInternal;
extern InferResponseHeader_OutputDefaultTypeInternal _InferResponseHeader_Output_default_instance_;
class InferResponseHeader_Output_Class;
struct InferResponseHeader_Output_ClassDefaultTypeInternal;
extern InferResponseHeader_Output_ClassDefaultTypeInternal _InferResponseHeader_Output_Class_default_instance_;
class InferResponseHeader_Output_Classes;
struct InferResponseHeader_Output_ClassesDefaultTypeInternal;
extern InferResponseHeader_Output_ClassesDefaultTypeInternal _InferResponseHeader_Output_Classes_default_instance_;
class InferResponseHeader_Output_Raw;
struct InferResponseHeader_Output_RawDefaultTypeInternal;
extern InferResponseHeader_Output_RawDefaultTypeInternal _InferResponseHeader_Output_Raw_default_instance_;
}  // namespace inferenceserver
}  // namespace nvidia
PROTOBUF_NAMESPACE_OPEN
template<> ::nvidia::inferenceserver::InferRequestHeader* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader>(Arena*);
template<> ::nvidia::inferenceserver::InferRequestHeader_Input* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Input>(Arena*);
template<> ::nvidia::inferenceserver::InferRequestHeader_Output* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Output>(Arena*);
template<> ::nvidia::inferenceserver::InferRequestHeader_Output_Class* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Output_Class>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output_Class* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Class>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Classes>(Arena*);
template<> ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* Arena::CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Raw>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace nvidia {
namespace inferenceserver {

// ===================================================================

class InferRequestHeader_Input final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader.Input) */ {
 public:
  inline InferRequestHeader_Input() : InferRequestHeader_Input(nullptr) {}
  ~InferRequestHeader_Input() override;
  explicit constexpr InferRequestHeader_Input(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferRequestHeader_Input(const InferRequestHeader_Input& from);
  InferRequestHeader_Input(InferRequestHeader_Input&& from) noexcept
    : InferRequestHeader_Input() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader_Input& operator=(const InferRequestHeader_Input& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferRequestHeader_Input& operator=(InferRequestHeader_Input&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferRequestHeader_Input& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferRequestHeader_Input* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader_Input*>(
               &_InferRequestHeader_Input_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  friend void swap(InferRequestHeader_Input& a, InferRequestHeader_Input& b) {
    a.Swap(&b);
  }
  inline void Swap(InferRequestHeader_Input* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferRequestHeader_Input* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferRequestHeader_Input* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferRequestHeader_Input>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferRequestHeader_Input& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferRequestHeader_Input& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader_Input* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferRequestHeader.Input";
  }
  protected:
  explicit InferRequestHeader_Input(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kDimsFieldNumber = 2,
    kNameFieldNumber = 1,
    kBatchByteSizeFieldNumber = 3,
  };
  // repeated int64 dims = 2;
  int dims_size() const;
  private:
  int _internal_dims_size() const;
  public:
  void clear_dims();
  private:
  int64_t _internal_dims(int index) const;
  const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
      _internal_dims() const;
  void _internal_add_dims(int64_t value);
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
      _internal_mutable_dims();
  public:
  int64_t dims(int index) const;
  void set_dims(int index, int64_t value);
  void add_dims(int64_t value);
  const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
      dims() const;
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
      mutable_dims();

  // string name = 1;
  void clear_name();
  const std::string& name() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_name(ArgT0&& arg0, ArgT... args);
  std::string* mutable_name();
  PROTOBUF_NODISCARD std::string* release_name();
  void set_allocated_name(std::string* name);
  private:
  const std::string& _internal_name() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_name(const std::string& value);
  std::string* _internal_mutable_name();
  public:

  // uint64 batch_byte_size = 3;
  void clear_batch_byte_size();
  uint64_t batch_byte_size() const;
  void set_batch_byte_size(uint64_t value);
  private:
  uint64_t _internal_batch_byte_size() const;
  void _internal_set_batch_byte_size(uint64_t value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader.Input)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t > dims_;
  mutable std::atomic<int> _dims_cached_byte_size_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr name_;
  uint64_t batch_byte_size_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferRequestHeader_Output_Class final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader.Output.Class) */ {
 public:
  inline InferRequestHeader_Output_Class() : InferRequestHeader_Output_Class(nullptr) {}
  ~InferRequestHeader_Output_Class() override;
  explicit constexpr InferRequestHeader_Output_Class(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferRequestHeader_Output_Class(const InferRequestHeader_Output_Class& from);
  InferRequestHeader_Output_Class(InferRequestHeader_Output_Class&& from) noexcept
    : InferRequestHeader_Output_Class() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader_Output_Class& operator=(const InferRequestHeader_Output_Class& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferRequestHeader_Output_Class& operator=(InferRequestHeader_Output_Class&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferRequestHeader_Output_Class& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferRequestHeader_Output_Class* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader_Output_Class*>(
               &_InferRequestHeader_Output_Class_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  friend void swap(InferRequestHeader_Output_Class& a, InferRequestHeader_Output_Class& b) {
    a.Swap(&b);
  }
  inline void Swap(InferRequestHeader_Output_Class* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferRequestHeader_Output_Class* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferRequestHeader_Output_Class* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferRequestHeader_Output_Class>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferRequestHeader_Output_Class& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferRequestHeader_Output_Class& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader_Output_Class* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferRequestHeader.Output.Class";
  }
  protected:
  explicit InferRequestHeader_Output_Class(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kCountFieldNumber = 1,
  };
  // uint32 count = 1;
  void clear_count();
  uint32_t count() const;
  void set_count(uint32_t value);
  private:
  uint32_t _internal_count() const;
  void _internal_set_count(uint32_t value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader.Output.Class)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  uint32_t count_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferRequestHeader_Output final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader.Output) */ {
 public:
  inline InferRequestHeader_Output() : InferRequestHeader_Output(nullptr) {}
  ~InferRequestHeader_Output() override;
  explicit constexpr InferRequestHeader_Output(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferRequestHeader_Output(const InferRequestHeader_Output& from);
  InferRequestHeader_Output(InferRequestHeader_Output&& from) noexcept
    : InferRequestHeader_Output() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader_Output& operator=(const InferRequestHeader_Output& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferRequestHeader_Output& operator=(InferRequestHeader_Output&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferRequestHeader_Output& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferRequestHeader_Output* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader_Output*>(
               &_InferRequestHeader_Output_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  friend void swap(InferRequestHeader_Output& a, InferRequestHeader_Output& b) {
    a.Swap(&b);
  }
  inline void Swap(InferRequestHeader_Output* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferRequestHeader_Output* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferRequestHeader_Output* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferRequestHeader_Output>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferRequestHeader_Output& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferRequestHeader_Output& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader_Output* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferRequestHeader.Output";
  }
  protected:
  explicit InferRequestHeader_Output(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferRequestHeader_Output_Class Class;

  // accessors -------------------------------------------------------

  enum : int {
    kNameFieldNumber = 1,
    kClsFieldNumber = 3,
  };
  // string name = 1;
  void clear_name();
  const std::string& name() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_name(ArgT0&& arg0, ArgT... args);
  std::string* mutable_name();
  PROTOBUF_NODISCARD std::string* release_name();
  void set_allocated_name(std::string* name);
  private:
  const std::string& _internal_name() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_name(const std::string& value);
  std::string* _internal_mutable_name();
  public:

  // .nvidia.inferenceserver.InferRequestHeader.Output.Class cls = 3;
  bool has_cls() const;
  private:
  bool _internal_has_cls() const;
  public:
  void clear_cls();
  const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& cls() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::InferRequestHeader_Output_Class* release_cls();
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* mutable_cls();
  void set_allocated_cls(::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls);
  private:
  const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& _internal_cls() const;
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* _internal_mutable_cls();
  public:
  void unsafe_arena_set_allocated_cls(
      ::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls);
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* unsafe_arena_release_cls();

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader.Output)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr name_;
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferRequestHeader final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferRequestHeader) */ {
 public:
  inline InferRequestHeader() : InferRequestHeader(nullptr) {}
  ~InferRequestHeader() override;
  explicit constexpr InferRequestHeader(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferRequestHeader(const InferRequestHeader& from);
  InferRequestHeader(InferRequestHeader&& from) noexcept
    : InferRequestHeader() {
    *this = ::std::move(from);
  }

  inline InferRequestHeader& operator=(const InferRequestHeader& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferRequestHeader& operator=(InferRequestHeader&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferRequestHeader& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferRequestHeader* internal_default_instance() {
    return reinterpret_cast<const InferRequestHeader*>(
               &_InferRequestHeader_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  friend void swap(InferRequestHeader& a, InferRequestHeader& b) {
    a.Swap(&b);
  }
  inline void Swap(InferRequestHeader* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferRequestHeader* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferRequestHeader* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferRequestHeader>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferRequestHeader& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferRequestHeader& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferRequestHeader* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferRequestHeader";
  }
  protected:
  explicit InferRequestHeader(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferRequestHeader_Input Input;
  typedef InferRequestHeader_Output Output;

  // accessors -------------------------------------------------------

  enum : int {
    kInputFieldNumber = 2,
    kOutputFieldNumber = 3,
    kCorrelationIdFieldNumber = 4,
    kBatchSizeFieldNumber = 1,
  };
  // repeated .nvidia.inferenceserver.InferRequestHeader.Input input = 2;
  int input_size() const;
  private:
  int _internal_input_size() const;
  public:
  void clear_input();
  ::nvidia::inferenceserver::InferRequestHeader_Input* mutable_input(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >*
      mutable_input();
  private:
  const ::nvidia::inferenceserver::InferRequestHeader_Input& _internal_input(int index) const;
  ::nvidia::inferenceserver::InferRequestHeader_Input* _internal_add_input();
  public:
  const ::nvidia::inferenceserver::InferRequestHeader_Input& input(int index) const;
  ::nvidia::inferenceserver::InferRequestHeader_Input* add_input();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >&
      input() const;

  // repeated .nvidia.inferenceserver.InferRequestHeader.Output output = 3;
  int output_size() const;
  private:
  int _internal_output_size() const;
  public:
  void clear_output();
  ::nvidia::inferenceserver::InferRequestHeader_Output* mutable_output(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >*
      mutable_output();
  private:
  const ::nvidia::inferenceserver::InferRequestHeader_Output& _internal_output(int index) const;
  ::nvidia::inferenceserver::InferRequestHeader_Output* _internal_add_output();
  public:
  const ::nvidia::inferenceserver::InferRequestHeader_Output& output(int index) const;
  ::nvidia::inferenceserver::InferRequestHeader_Output* add_output();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >&
      output() const;

  // uint64 correlation_id = 4;
  void clear_correlation_id();
  uint64_t correlation_id() const;
  void set_correlation_id(uint64_t value);
  private:
  uint64_t _internal_correlation_id() const;
  void _internal_set_correlation_id(uint64_t value);
  public:

  // uint32 batch_size = 1;
  void clear_batch_size();
  uint32_t batch_size() const;
  void set_batch_size(uint32_t value);
  private:
  uint32_t _internal_batch_size() const;
  void _internal_set_batch_size(uint32_t value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferRequestHeader)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input > input_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output > output_;
  uint64_t correlation_id_;
  uint32_t batch_size_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output_Raw final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output.Raw) */ {
 public:
  inline InferResponseHeader_Output_Raw() : InferResponseHeader_Output_Raw(nullptr) {}
  ~InferResponseHeader_Output_Raw() override;
  explicit constexpr InferResponseHeader_Output_Raw(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferResponseHeader_Output_Raw(const InferResponseHeader_Output_Raw& from);
  InferResponseHeader_Output_Raw(InferResponseHeader_Output_Raw&& from) noexcept
    : InferResponseHeader_Output_Raw() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output_Raw& operator=(const InferResponseHeader_Output_Raw& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferResponseHeader_Output_Raw& operator=(InferResponseHeader_Output_Raw&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferResponseHeader_Output_Raw& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferResponseHeader_Output_Raw* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output_Raw*>(
               &_InferResponseHeader_Output_Raw_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  friend void swap(InferResponseHeader_Output_Raw& a, InferResponseHeader_Output_Raw& b) {
    a.Swap(&b);
  }
  inline void Swap(InferResponseHeader_Output_Raw* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferResponseHeader_Output_Raw* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferResponseHeader_Output_Raw* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Raw>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferResponseHeader_Output_Raw& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferResponseHeader_Output_Raw& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output_Raw* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferResponseHeader.Output.Raw";
  }
  protected:
  explicit InferResponseHeader_Output_Raw(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kDimsFieldNumber = 1,
    kBatchByteSizeFieldNumber = 2,
  };
  // repeated int64 dims = 1;
  int dims_size() const;
  private:
  int _internal_dims_size() const;
  public:
  void clear_dims();
  private:
  int64_t _internal_dims(int index) const;
  const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
      _internal_dims() const;
  void _internal_add_dims(int64_t value);
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
      _internal_mutable_dims();
  public:
  int64_t dims(int index) const;
  void set_dims(int index, int64_t value);
  void add_dims(int64_t value);
  const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
      dims() const;
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
      mutable_dims();

  // uint64 batch_byte_size = 2;
  void clear_batch_byte_size();
  uint64_t batch_byte_size() const;
  void set_batch_byte_size(uint64_t value);
  private:
  uint64_t _internal_batch_byte_size() const;
  void _internal_set_batch_byte_size(uint64_t value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t > dims_;
  mutable std::atomic<int> _dims_cached_byte_size_;
  uint64_t batch_byte_size_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output_Class final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output.Class) */ {
 public:
  inline InferResponseHeader_Output_Class() : InferResponseHeader_Output_Class(nullptr) {}
  ~InferResponseHeader_Output_Class() override;
  explicit constexpr InferResponseHeader_Output_Class(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferResponseHeader_Output_Class(const InferResponseHeader_Output_Class& from);
  InferResponseHeader_Output_Class(InferResponseHeader_Output_Class&& from) noexcept
    : InferResponseHeader_Output_Class() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output_Class& operator=(const InferResponseHeader_Output_Class& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferResponseHeader_Output_Class& operator=(InferResponseHeader_Output_Class&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferResponseHeader_Output_Class& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferResponseHeader_Output_Class* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output_Class*>(
               &_InferResponseHeader_Output_Class_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    5;

  friend void swap(InferResponseHeader_Output_Class& a, InferResponseHeader_Output_Class& b) {
    a.Swap(&b);
  }
  inline void Swap(InferResponseHeader_Output_Class* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferResponseHeader_Output_Class* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferResponseHeader_Output_Class* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Class>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferResponseHeader_Output_Class& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferResponseHeader_Output_Class& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output_Class* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferResponseHeader.Output.Class";
  }
  protected:
  explicit InferResponseHeader_Output_Class(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kLabelFieldNumber = 3,
    kIdxFieldNumber = 1,
    kValueFieldNumber = 2,
  };
  // string label = 3;
  void clear_label();
  const std::string& label() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_label(ArgT0&& arg0, ArgT... args);
  std::string* mutable_label();
  PROTOBUF_NODISCARD std::string* release_label();
  void set_allocated_label(std::string* label);
  private:
  const std::string& _internal_label() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_label(const std::string& value);
  std::string* _internal_mutable_label();
  public:

  // int32 idx = 1;
  void clear_idx();
  int32_t idx() const;
  void set_idx(int32_t value);
  private:
  int32_t _internal_idx() const;
  void _internal_set_idx(int32_t value);
  public:

  // float value = 2;
  void clear_value();
  float value() const;
  void set_value(float value);
  private:
  float _internal_value() const;
  void _internal_set_value(float value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output.Class)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr label_;
  int32_t idx_;
  float value_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output_Classes final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output.Classes) */ {
 public:
  inline InferResponseHeader_Output_Classes() : InferResponseHeader_Output_Classes(nullptr) {}
  ~InferResponseHeader_Output_Classes() override;
  explicit constexpr InferResponseHeader_Output_Classes(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferResponseHeader_Output_Classes(const InferResponseHeader_Output_Classes& from);
  InferResponseHeader_Output_Classes(InferResponseHeader_Output_Classes&& from) noexcept
    : InferResponseHeader_Output_Classes() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output_Classes& operator=(const InferResponseHeader_Output_Classes& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferResponseHeader_Output_Classes& operator=(InferResponseHeader_Output_Classes&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferResponseHeader_Output_Classes& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferResponseHeader_Output_Classes* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output_Classes*>(
               &_InferResponseHeader_Output_Classes_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  friend void swap(InferResponseHeader_Output_Classes& a, InferResponseHeader_Output_Classes& b) {
    a.Swap(&b);
  }
  inline void Swap(InferResponseHeader_Output_Classes* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferResponseHeader_Output_Classes* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferResponseHeader_Output_Classes* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferResponseHeader_Output_Classes>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferResponseHeader_Output_Classes& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferResponseHeader_Output_Classes& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output_Classes* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferResponseHeader.Output.Classes";
  }
  protected:
  explicit InferResponseHeader_Output_Classes(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kClsFieldNumber = 1,
  };
  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Class cls = 1;
  int cls_size() const;
  private:
  int _internal_cls_size() const;
  public:
  void clear_cls();
  ::nvidia::inferenceserver::InferResponseHeader_Output_Class* mutable_cls(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >*
      mutable_cls();
  private:
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Class& _internal_cls(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Class* _internal_add_cls();
  public:
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Class& cls(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Class* add_cls();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >&
      cls() const;

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class > cls_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferResponseHeader_Output final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader.Output) */ {
 public:
  inline InferResponseHeader_Output() : InferResponseHeader_Output(nullptr) {}
  ~InferResponseHeader_Output() override;
  explicit constexpr InferResponseHeader_Output(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferResponseHeader_Output(const InferResponseHeader_Output& from);
  InferResponseHeader_Output(InferResponseHeader_Output&& from) noexcept
    : InferResponseHeader_Output() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader_Output& operator=(const InferResponseHeader_Output& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferResponseHeader_Output& operator=(InferResponseHeader_Output&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferResponseHeader_Output& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferResponseHeader_Output* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader_Output*>(
               &_InferResponseHeader_Output_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    7;

  friend void swap(InferResponseHeader_Output& a, InferResponseHeader_Output& b) {
    a.Swap(&b);
  }
  inline void Swap(InferResponseHeader_Output* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferResponseHeader_Output* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferResponseHeader_Output* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferResponseHeader_Output>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferResponseHeader_Output& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferResponseHeader_Output& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader_Output* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferResponseHeader.Output";
  }
  protected:
  explicit InferResponseHeader_Output(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferResponseHeader_Output_Raw Raw;
  typedef InferResponseHeader_Output_Class Class;
  typedef InferResponseHeader_Output_Classes Classes;

  // accessors -------------------------------------------------------

  enum : int {
    kBatchClassesFieldNumber = 3,
    kNameFieldNumber = 1,
    kRawFieldNumber = 2,
  };
  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Classes batch_classes = 3;
  int batch_classes_size() const;
  private:
  int _internal_batch_classes_size() const;
  public:
  void clear_batch_classes();
  ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* mutable_batch_classes(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >*
      mutable_batch_classes();
  private:
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Classes& _internal_batch_classes(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* _internal_add_batch_classes();
  public:
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Classes& batch_classes(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* add_batch_classes();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >&
      batch_classes() const;

  // string name = 1;
  void clear_name();
  const std::string& name() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_name(ArgT0&& arg0, ArgT... args);
  std::string* mutable_name();
  PROTOBUF_NODISCARD std::string* release_name();
  void set_allocated_name(std::string* name);
  private:
  const std::string& _internal_name() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_name(const std::string& value);
  std::string* _internal_mutable_name();
  public:

  // .nvidia.inferenceserver.InferResponseHeader.Output.Raw raw = 2;
  bool has_raw() const;
  private:
  bool _internal_has_raw() const;
  public:
  void clear_raw();
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& raw() const;
  PROTOBUF_NODISCARD ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* release_raw();
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* mutable_raw();
  void set_allocated_raw(::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw);
  private:
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& _internal_raw() const;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* _internal_mutable_raw();
  public:
  void unsafe_arena_set_allocated_raw(
      ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw);
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* unsafe_arena_release_raw();

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader.Output)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes > batch_classes_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr name_;
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// -------------------------------------------------------------------

class InferResponseHeader final :
    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:nvidia.inferenceserver.InferResponseHeader) */ {
 public:
  inline InferResponseHeader() : InferResponseHeader(nullptr) {}
  ~InferResponseHeader() override;
  explicit constexpr InferResponseHeader(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  InferResponseHeader(const InferResponseHeader& from);
  InferResponseHeader(InferResponseHeader&& from) noexcept
    : InferResponseHeader() {
    *this = ::std::move(from);
  }

  inline InferResponseHeader& operator=(const InferResponseHeader& from) {
    CopyFrom(from);
    return *this;
  }
  inline InferResponseHeader& operator=(InferResponseHeader&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const InferResponseHeader& default_instance() {
    return *internal_default_instance();
  }
  static inline const InferResponseHeader* internal_default_instance() {
    return reinterpret_cast<const InferResponseHeader*>(
               &_InferResponseHeader_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    8;

  friend void swap(InferResponseHeader& a, InferResponseHeader& b) {
    a.Swap(&b);
  }
  inline void Swap(InferResponseHeader* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(InferResponseHeader* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  InferResponseHeader* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<InferResponseHeader>(arena);
  }
  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
  void CopyFrom(const InferResponseHeader& from);
  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
  void MergeFrom(const InferResponseHeader& from);
  private:
  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to, const ::PROTOBUF_NAMESPACE_ID::Message& from);
  public:
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(InferResponseHeader* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "nvidia.inferenceserver.InferResponseHeader";
  }
  protected:
  explicit InferResponseHeader(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  private:
  static void ArenaDtor(void* object);
  inline void RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena);
  public:

  static const ClassData _class_data_;
  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;

  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef InferResponseHeader_Output Output;

  // accessors -------------------------------------------------------

  enum : int {
    kOutputFieldNumber = 4,
    kModelNameFieldNumber = 1,
    kModelVersionFieldNumber = 2,
    kBatchSizeFieldNumber = 3,
  };
  // repeated .nvidia.inferenceserver.InferResponseHeader.Output output = 4;
  int output_size() const;
  private:
  int _internal_output_size() const;
  public:
  void clear_output();
  ::nvidia::inferenceserver::InferResponseHeader_Output* mutable_output(int index);
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >*
      mutable_output();
  private:
  const ::nvidia::inferenceserver::InferResponseHeader_Output& _internal_output(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output* _internal_add_output();
  public:
  const ::nvidia::inferenceserver::InferResponseHeader_Output& output(int index) const;
  ::nvidia::inferenceserver::InferResponseHeader_Output* add_output();
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >&
      output() const;

  // string model_name = 1;
  void clear_model_name();
  const std::string& model_name() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_model_name(ArgT0&& arg0, ArgT... args);
  std::string* mutable_model_name();
  PROTOBUF_NODISCARD std::string* release_model_name();
  void set_allocated_model_name(std::string* model_name);
  private:
  const std::string& _internal_model_name() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_model_name(const std::string& value);
  std::string* _internal_mutable_model_name();
  public:

  // int64 model_version = 2;
  void clear_model_version();
  int64_t model_version() const;
  void set_model_version(int64_t value);
  private:
  int64_t _internal_model_version() const;
  void _internal_set_model_version(int64_t value);
  public:

  // uint32 batch_size = 3;
  void clear_batch_size();
  uint32_t batch_size() const;
  void set_batch_size(uint32_t value);
  private:
  uint32_t _internal_batch_size() const;
  void _internal_set_batch_size(uint32_t value);
  public:

  // @@protoc_insertion_point(class_scope:nvidia.inferenceserver.InferResponseHeader)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output > output_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr model_name_;
  int64_t model_version_;
  uint32_t batch_size_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_api_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// InferRequestHeader_Input

// string name = 1;
inline void InferRequestHeader_Input::clear_name() {
  name_.ClearToEmpty();
}
inline const std::string& InferRequestHeader_Input::name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Input.name)
  return _internal_name();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void InferRequestHeader_Input::set_name(ArgT0&& arg0, ArgT... args) {
 
 name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Input.name)
}
inline std::string* InferRequestHeader_Input::mutable_name() {
  std::string* _s = _internal_mutable_name();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Input.name)
  return _s;
}
inline const std::string& InferRequestHeader_Input::_internal_name() const {
  return name_.Get();
}
inline void InferRequestHeader_Input::_internal_set_name(const std::string& value) {
  
  name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* InferRequestHeader_Input::_internal_mutable_name() {
  
  return name_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* InferRequestHeader_Input::release_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Input.name)
  return name_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void InferRequestHeader_Input::set_allocated_name(std::string* name) {
  if (name != nullptr) {
    
  } else {
    
  }
  name_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), name,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (name_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Input.name)
}

// repeated int64 dims = 2;
inline int InferRequestHeader_Input::_internal_dims_size() const {
  return dims_.size();
}
inline int InferRequestHeader_Input::dims_size() const {
  return _internal_dims_size();
}
inline void InferRequestHeader_Input::clear_dims() {
  dims_.Clear();
}
inline int64_t InferRequestHeader_Input::_internal_dims(int index) const {
  return dims_.Get(index);
}
inline int64_t InferRequestHeader_Input::dims(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Input.dims)
  return _internal_dims(index);
}
inline void InferRequestHeader_Input::set_dims(int index, int64_t value) {
  dims_.Set(index, value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Input.dims)
}
inline void InferRequestHeader_Input::_internal_add_dims(int64_t value) {
  dims_.Add(value);
}
inline void InferRequestHeader_Input::add_dims(int64_t value) {
  _internal_add_dims(value);
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferRequestHeader.Input.dims)
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
InferRequestHeader_Input::_internal_dims() const {
  return dims_;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
InferRequestHeader_Input::dims() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferRequestHeader.Input.dims)
  return _internal_dims();
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
InferRequestHeader_Input::_internal_mutable_dims() {
  return &dims_;
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
InferRequestHeader_Input::mutable_dims() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferRequestHeader.Input.dims)
  return _internal_mutable_dims();
}

// uint64 batch_byte_size = 3;
inline void InferRequestHeader_Input::clear_batch_byte_size() {
  batch_byte_size_ = uint64_t{0u};
}
inline uint64_t InferRequestHeader_Input::_internal_batch_byte_size() const {
  return batch_byte_size_;
}
inline uint64_t InferRequestHeader_Input::batch_byte_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Input.batch_byte_size)
  return _internal_batch_byte_size();
}
inline void InferRequestHeader_Input::_internal_set_batch_byte_size(uint64_t value) {
  
  batch_byte_size_ = value;
}
inline void InferRequestHeader_Input::set_batch_byte_size(uint64_t value) {
  _internal_set_batch_byte_size(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Input.batch_byte_size)
}

// -------------------------------------------------------------------

// InferRequestHeader_Output_Class

// uint32 count = 1;
inline void InferRequestHeader_Output_Class::clear_count() {
  count_ = 0u;
}
inline uint32_t InferRequestHeader_Output_Class::_internal_count() const {
  return count_;
}
inline uint32_t InferRequestHeader_Output_Class::count() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Output.Class.count)
  return _internal_count();
}
inline void InferRequestHeader_Output_Class::_internal_set_count(uint32_t value) {
  
  count_ = value;
}
inline void InferRequestHeader_Output_Class::set_count(uint32_t value) {
  _internal_set_count(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Output.Class.count)
}

// -------------------------------------------------------------------

// InferRequestHeader_Output

// string name = 1;
inline void InferRequestHeader_Output::clear_name() {
  name_.ClearToEmpty();
}
inline const std::string& InferRequestHeader_Output::name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Output.name)
  return _internal_name();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void InferRequestHeader_Output::set_name(ArgT0&& arg0, ArgT... args) {
 
 name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.Output.name)
}
inline std::string* InferRequestHeader_Output::mutable_name() {
  std::string* _s = _internal_mutable_name();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Output.name)
  return _s;
}
inline const std::string& InferRequestHeader_Output::_internal_name() const {
  return name_.Get();
}
inline void InferRequestHeader_Output::_internal_set_name(const std::string& value) {
  
  name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* InferRequestHeader_Output::_internal_mutable_name() {
  
  return name_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* InferRequestHeader_Output::release_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Output.name)
  return name_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void InferRequestHeader_Output::set_allocated_name(std::string* name) {
  if (name != nullptr) {
    
  } else {
    
  }
  name_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), name,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (name_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Output.name)
}

// .nvidia.inferenceserver.InferRequestHeader.Output.Class cls = 3;
inline bool InferRequestHeader_Output::_internal_has_cls() const {
  return this != internal_default_instance() && cls_ != nullptr;
}
inline bool InferRequestHeader_Output::has_cls() const {
  return _internal_has_cls();
}
inline void InferRequestHeader_Output::clear_cls() {
  if (GetArenaForAllocation() == nullptr && cls_ != nullptr) {
    delete cls_;
  }
  cls_ = nullptr;
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& InferRequestHeader_Output::_internal_cls() const {
  const ::nvidia::inferenceserver::InferRequestHeader_Output_Class* p = cls_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::InferRequestHeader_Output_Class&>(
      ::nvidia::inferenceserver::_InferRequestHeader_Output_Class_default_instance_);
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& InferRequestHeader_Output::cls() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.Output.cls)
  return _internal_cls();
}
inline void InferRequestHeader_Output::unsafe_arena_set_allocated_cls(
    ::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(cls_);
  }
  cls_ = cls;
  if (cls) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.InferRequestHeader.Output.cls)
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output_Class* InferRequestHeader_Output::release_cls() {
  
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* temp = cls_;
  cls_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output_Class* InferRequestHeader_Output::unsafe_arena_release_cls() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferRequestHeader.Output.cls)
  
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* temp = cls_;
  cls_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output_Class* InferRequestHeader_Output::_internal_mutable_cls() {
  
  if (cls_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::InferRequestHeader_Output_Class>(GetArenaForAllocation());
    cls_ = p;
  }
  return cls_;
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output_Class* InferRequestHeader_Output::mutable_cls() {
  ::nvidia::inferenceserver::InferRequestHeader_Output_Class* _msg = _internal_mutable_cls();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.Output.cls)
  return _msg;
}
inline void InferRequestHeader_Output::set_allocated_cls(::nvidia::inferenceserver::InferRequestHeader_Output_Class* cls) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete cls_;
  }
  if (cls) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::InferRequestHeader_Output_Class>::GetOwningArena(cls);
    if (message_arena != submessage_arena) {
      cls = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, cls, submessage_arena);
    }
    
  } else {
    
  }
  cls_ = cls;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferRequestHeader.Output.cls)
}

// -------------------------------------------------------------------

// InferRequestHeader

// uint64 correlation_id = 4;
inline void InferRequestHeader::clear_correlation_id() {
  correlation_id_ = uint64_t{0u};
}
inline uint64_t InferRequestHeader::_internal_correlation_id() const {
  return correlation_id_;
}
inline uint64_t InferRequestHeader::correlation_id() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.correlation_id)
  return _internal_correlation_id();
}
inline void InferRequestHeader::_internal_set_correlation_id(uint64_t value) {
  
  correlation_id_ = value;
}
inline void InferRequestHeader::set_correlation_id(uint64_t value) {
  _internal_set_correlation_id(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.correlation_id)
}

// uint32 batch_size = 1;
inline void InferRequestHeader::clear_batch_size() {
  batch_size_ = 0u;
}
inline uint32_t InferRequestHeader::_internal_batch_size() const {
  return batch_size_;
}
inline uint32_t InferRequestHeader::batch_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.batch_size)
  return _internal_batch_size();
}
inline void InferRequestHeader::_internal_set_batch_size(uint32_t value) {
  
  batch_size_ = value;
}
inline void InferRequestHeader::set_batch_size(uint32_t value) {
  _internal_set_batch_size(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferRequestHeader.batch_size)
}

// repeated .nvidia.inferenceserver.InferRequestHeader.Input input = 2;
inline int InferRequestHeader::_internal_input_size() const {
  return input_.size();
}
inline int InferRequestHeader::input_size() const {
  return _internal_input_size();
}
inline void InferRequestHeader::clear_input() {
  input_.Clear();
}
inline ::nvidia::inferenceserver::InferRequestHeader_Input* InferRequestHeader::mutable_input(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.input)
  return input_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >*
InferRequestHeader::mutable_input() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferRequestHeader.input)
  return &input_;
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Input& InferRequestHeader::_internal_input(int index) const {
  return input_.Get(index);
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Input& InferRequestHeader::input(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.input)
  return _internal_input(index);
}
inline ::nvidia::inferenceserver::InferRequestHeader_Input* InferRequestHeader::_internal_add_input() {
  return input_.Add();
}
inline ::nvidia::inferenceserver::InferRequestHeader_Input* InferRequestHeader::add_input() {
  ::nvidia::inferenceserver::InferRequestHeader_Input* _add = _internal_add_input();
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferRequestHeader.input)
  return _add;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Input >&
InferRequestHeader::input() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferRequestHeader.input)
  return input_;
}

// repeated .nvidia.inferenceserver.InferRequestHeader.Output output = 3;
inline int InferRequestHeader::_internal_output_size() const {
  return output_.size();
}
inline int InferRequestHeader::output_size() const {
  return _internal_output_size();
}
inline void InferRequestHeader::clear_output() {
  output_.Clear();
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output* InferRequestHeader::mutable_output(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferRequestHeader.output)
  return output_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >*
InferRequestHeader::mutable_output() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferRequestHeader.output)
  return &output_;
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Output& InferRequestHeader::_internal_output(int index) const {
  return output_.Get(index);
}
inline const ::nvidia::inferenceserver::InferRequestHeader_Output& InferRequestHeader::output(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferRequestHeader.output)
  return _internal_output(index);
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output* InferRequestHeader::_internal_add_output() {
  return output_.Add();
}
inline ::nvidia::inferenceserver::InferRequestHeader_Output* InferRequestHeader::add_output() {
  ::nvidia::inferenceserver::InferRequestHeader_Output* _add = _internal_add_output();
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferRequestHeader.output)
  return _add;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferRequestHeader_Output >&
InferRequestHeader::output() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferRequestHeader.output)
  return output_;
}

// -------------------------------------------------------------------

// InferResponseHeader_Output_Raw

// repeated int64 dims = 1;
inline int InferResponseHeader_Output_Raw::_internal_dims_size() const {
  return dims_.size();
}
inline int InferResponseHeader_Output_Raw::dims_size() const {
  return _internal_dims_size();
}
inline void InferResponseHeader_Output_Raw::clear_dims() {
  dims_.Clear();
}
inline int64_t InferResponseHeader_Output_Raw::_internal_dims(int index) const {
  return dims_.Get(index);
}
inline int64_t InferResponseHeader_Output_Raw::dims(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
  return _internal_dims(index);
}
inline void InferResponseHeader_Output_Raw::set_dims(int index, int64_t value) {
  dims_.Set(index, value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
}
inline void InferResponseHeader_Output_Raw::_internal_add_dims(int64_t value) {
  dims_.Add(value);
}
inline void InferResponseHeader_Output_Raw::add_dims(int64_t value) {
  _internal_add_dims(value);
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
InferResponseHeader_Output_Raw::_internal_dims() const {
  return dims_;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >&
InferResponseHeader_Output_Raw::dims() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
  return _internal_dims();
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
InferResponseHeader_Output_Raw::_internal_mutable_dims() {
  return &dims_;
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedField< int64_t >*
InferResponseHeader_Output_Raw::mutable_dims() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.Output.Raw.dims)
  return _internal_mutable_dims();
}

// uint64 batch_byte_size = 2;
inline void InferResponseHeader_Output_Raw::clear_batch_byte_size() {
  batch_byte_size_ = uint64_t{0u};
}
inline uint64_t InferResponseHeader_Output_Raw::_internal_batch_byte_size() const {
  return batch_byte_size_;
}
inline uint64_t InferResponseHeader_Output_Raw::batch_byte_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Raw.batch_byte_size)
  return _internal_batch_byte_size();
}
inline void InferResponseHeader_Output_Raw::_internal_set_batch_byte_size(uint64_t value) {
  
  batch_byte_size_ = value;
}
inline void InferResponseHeader_Output_Raw::set_batch_byte_size(uint64_t value) {
  _internal_set_batch_byte_size(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Raw.batch_byte_size)
}

// -------------------------------------------------------------------

// InferResponseHeader_Output_Class

// int32 idx = 1;
inline void InferResponseHeader_Output_Class::clear_idx() {
  idx_ = 0;
}
inline int32_t InferResponseHeader_Output_Class::_internal_idx() const {
  return idx_;
}
inline int32_t InferResponseHeader_Output_Class::idx() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Class.idx)
  return _internal_idx();
}
inline void InferResponseHeader_Output_Class::_internal_set_idx(int32_t value) {
  
  idx_ = value;
}
inline void InferResponseHeader_Output_Class::set_idx(int32_t value) {
  _internal_set_idx(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Class.idx)
}

// float value = 2;
inline void InferResponseHeader_Output_Class::clear_value() {
  value_ = 0;
}
inline float InferResponseHeader_Output_Class::_internal_value() const {
  return value_;
}
inline float InferResponseHeader_Output_Class::value() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Class.value)
  return _internal_value();
}
inline void InferResponseHeader_Output_Class::_internal_set_value(float value) {
  
  value_ = value;
}
inline void InferResponseHeader_Output_Class::set_value(float value) {
  _internal_set_value(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Class.value)
}

// string label = 3;
inline void InferResponseHeader_Output_Class::clear_label() {
  label_.ClearToEmpty();
}
inline const std::string& InferResponseHeader_Output_Class::label() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
  return _internal_label();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void InferResponseHeader_Output_Class::set_label(ArgT0&& arg0, ArgT... args) {
 
 label_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
}
inline std::string* InferResponseHeader_Output_Class::mutable_label() {
  std::string* _s = _internal_mutable_label();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
  return _s;
}
inline const std::string& InferResponseHeader_Output_Class::_internal_label() const {
  return label_.Get();
}
inline void InferResponseHeader_Output_Class::_internal_set_label(const std::string& value) {
  
  label_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* InferResponseHeader_Output_Class::_internal_mutable_label() {
  
  return label_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* InferResponseHeader_Output_Class::release_label() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
  return label_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void InferResponseHeader_Output_Class::set_allocated_label(std::string* label) {
  if (label != nullptr) {
    
  } else {
    
  }
  label_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), label,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (label_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    label_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.Output.Class.label)
}

// -------------------------------------------------------------------

// InferResponseHeader_Output_Classes

// repeated .nvidia.inferenceserver.InferResponseHeader.Output.Class cls = 1;
inline int InferResponseHeader_Output_Classes::_internal_cls_size() const {
  return cls_.size();
}
inline int InferResponseHeader_Output_Classes::cls_size() const {
  return _internal_cls_size();
}
inline void InferResponseHeader_Output_Classes::clear_cls() {
  cls_.Clear();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Class* InferResponseHeader_Output_Classes::mutable_cls(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return cls_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >*
InferResponseHeader_Output_Classes::mutable_cls() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return &cls_;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Class& InferResponseHeader_Output_Classes::_internal_cls(int index) const {
  return cls_.Get(index);
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Class& InferResponseHeader_Output_Classes::cls(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return _internal_cls(index);
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Class* InferResponseHeader_Output_Classes::_internal_add_cls() {
  return cls_.Add();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Class* InferResponseHeader_Output_Classes::add_cls() {
  ::nvidia::inferenceserver::InferResponseHeader_Output_Class* _add = _internal_add_cls();
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return _add;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >&
InferResponseHeader_Output_Classes::cls() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.Output.Classes.cls)
  return cls_;
}

// -------------------------------------------------------------------

// InferResponseHeader_Output

// string name = 1;
inline void InferResponseHeader_Output::clear_name() {
  name_.ClearToEmpty();
}
inline const std::string& InferResponseHeader_Output::name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.name)
  return _internal_name();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void InferResponseHeader_Output::set_name(ArgT0&& arg0, ArgT... args) {
 
 name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.Output.name)
}
inline std::string* InferResponseHeader_Output::mutable_name() {
  std::string* _s = _internal_mutable_name();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.name)
  return _s;
}
inline const std::string& InferResponseHeader_Output::_internal_name() const {
  return name_.Get();
}
inline void InferResponseHeader_Output::_internal_set_name(const std::string& value) {
  
  name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* InferResponseHeader_Output::_internal_mutable_name() {
  
  return name_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* InferResponseHeader_Output::release_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.Output.name)
  return name_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void InferResponseHeader_Output::set_allocated_name(std::string* name) {
  if (name != nullptr) {
    
  } else {
    
  }
  name_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), name,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (name_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.Output.name)
}

// .nvidia.inferenceserver.InferResponseHeader.Output.Raw raw = 2;
inline bool InferResponseHeader_Output::_internal_has_raw() const {
  return this != internal_default_instance() && raw_ != nullptr;
}
inline bool InferResponseHeader_Output::has_raw() const {
  return _internal_has_raw();
}
inline void InferResponseHeader_Output::clear_raw() {
  if (GetArenaForAllocation() == nullptr && raw_ != nullptr) {
    delete raw_;
  }
  raw_ = nullptr;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& InferResponseHeader_Output::_internal_raw() const {
  const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* p = raw_;
  return p != nullptr ? *p : reinterpret_cast<const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw&>(
      ::nvidia::inferenceserver::_InferResponseHeader_Output_Raw_default_instance_);
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& InferResponseHeader_Output::raw() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.raw)
  return _internal_raw();
}
inline void InferResponseHeader_Output::unsafe_arena_set_allocated_raw(
    ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(raw_);
  }
  raw_ = raw;
  if (raw) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:nvidia.inferenceserver.InferResponseHeader.Output.raw)
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* InferResponseHeader_Output::release_raw() {
  
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* temp = raw_;
  raw_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* InferResponseHeader_Output::unsafe_arena_release_raw() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.Output.raw)
  
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* temp = raw_;
  raw_ = nullptr;
  return temp;
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* InferResponseHeader_Output::_internal_mutable_raw() {
  
  if (raw_ == nullptr) {
    auto* p = CreateMaybeMessage<::nvidia::inferenceserver::InferResponseHeader_Output_Raw>(GetArenaForAllocation());
    raw_ = p;
  }
  return raw_;
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* InferResponseHeader_Output::mutable_raw() {
  ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* _msg = _internal_mutable_raw();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.raw)
  return _msg;
}
inline void InferResponseHeader_Output::set_allocated_raw(::nvidia::inferenceserver::InferResponseHeader_Output_Raw* raw) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete raw_;
  }
  if (raw) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::InferResponseHeader_Output_Raw>::GetOwningArena(raw);
    if (message_arena != submessage_arena) {
      raw = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, raw, submessage_arena);
    }
    
  } else {
    
  }
  raw_ = raw;
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.Output.raw)
}

// repeated .nvidia.inferenceserver.InferResponseHeader.Output.Classes batch_classes = 3;
inline int InferResponseHeader_Output::_internal_batch_classes_size() const {
  return batch_classes_.size();
}
inline int InferResponseHeader_Output::batch_classes_size() const {
  return _internal_batch_classes_size();
}
inline void InferResponseHeader_Output::clear_batch_classes() {
  batch_classes_.Clear();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* InferResponseHeader_Output::mutable_batch_classes(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return batch_classes_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >*
InferResponseHeader_Output::mutable_batch_classes() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return &batch_classes_;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Classes& InferResponseHeader_Output::_internal_batch_classes(int index) const {
  return batch_classes_.Get(index);
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output_Classes& InferResponseHeader_Output::batch_classes(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return _internal_batch_classes(index);
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* InferResponseHeader_Output::_internal_add_batch_classes() {
  return batch_classes_.Add();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* InferResponseHeader_Output::add_batch_classes() {
  ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* _add = _internal_add_batch_classes();
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return _add;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >&
InferResponseHeader_Output::batch_classes() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.Output.batch_classes)
  return batch_classes_;
}

// -------------------------------------------------------------------

// InferResponseHeader

// string model_name = 1;
inline void InferResponseHeader::clear_model_name() {
  model_name_.ClearToEmpty();
}
inline const std::string& InferResponseHeader::model_name() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.model_name)
  return _internal_model_name();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void InferResponseHeader::set_model_name(ArgT0&& arg0, ArgT... args) {
 
 model_name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.model_name)
}
inline std::string* InferResponseHeader::mutable_model_name() {
  std::string* _s = _internal_mutable_model_name();
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.model_name)
  return _s;
}
inline const std::string& InferResponseHeader::_internal_model_name() const {
  return model_name_.Get();
}
inline void InferResponseHeader::_internal_set_model_name(const std::string& value) {
  
  model_name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, value, GetArenaForAllocation());
}
inline std::string* InferResponseHeader::_internal_mutable_model_name() {
  
  return model_name_.Mutable(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, GetArenaForAllocation());
}
inline std::string* InferResponseHeader::release_model_name() {
  // @@protoc_insertion_point(field_release:nvidia.inferenceserver.InferResponseHeader.model_name)
  return model_name_.Release(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArenaForAllocation());
}
inline void InferResponseHeader::set_allocated_model_name(std::string* model_name) {
  if (model_name != nullptr) {
    
  } else {
    
  }
  model_name_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), model_name,
      GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (model_name_.IsDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited())) {
    model_name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.InferResponseHeader.model_name)
}

// int64 model_version = 2;
inline void InferResponseHeader::clear_model_version() {
  model_version_ = int64_t{0};
}
inline int64_t InferResponseHeader::_internal_model_version() const {
  return model_version_;
}
inline int64_t InferResponseHeader::model_version() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.model_version)
  return _internal_model_version();
}
inline void InferResponseHeader::_internal_set_model_version(int64_t value) {
  
  model_version_ = value;
}
inline void InferResponseHeader::set_model_version(int64_t value) {
  _internal_set_model_version(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.model_version)
}

// uint32 batch_size = 3;
inline void InferResponseHeader::clear_batch_size() {
  batch_size_ = 0u;
}
inline uint32_t InferResponseHeader::_internal_batch_size() const {
  return batch_size_;
}
inline uint32_t InferResponseHeader::batch_size() const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.batch_size)
  return _internal_batch_size();
}
inline void InferResponseHeader::_internal_set_batch_size(uint32_t value) {
  
  batch_size_ = value;
}
inline void InferResponseHeader::set_batch_size(uint32_t value) {
  _internal_set_batch_size(value);
  // @@protoc_insertion_point(field_set:nvidia.inferenceserver.InferResponseHeader.batch_size)
}

// repeated .nvidia.inferenceserver.InferResponseHeader.Output output = 4;
inline int InferResponseHeader::_internal_output_size() const {
  return output_.size();
}
inline int InferResponseHeader::output_size() const {
  return _internal_output_size();
}
inline void InferResponseHeader::clear_output() {
  output_.Clear();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output* InferResponseHeader::mutable_output(int index) {
  // @@protoc_insertion_point(field_mutable:nvidia.inferenceserver.InferResponseHeader.output)
  return output_.Mutable(index);
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >*
InferResponseHeader::mutable_output() {
  // @@protoc_insertion_point(field_mutable_list:nvidia.inferenceserver.InferResponseHeader.output)
  return &output_;
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output& InferResponseHeader::_internal_output(int index) const {
  return output_.Get(index);
}
inline const ::nvidia::inferenceserver::InferResponseHeader_Output& InferResponseHeader::output(int index) const {
  // @@protoc_insertion_point(field_get:nvidia.inferenceserver.InferResponseHeader.output)
  return _internal_output(index);
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output* InferResponseHeader::_internal_add_output() {
  return output_.Add();
}
inline ::nvidia::inferenceserver::InferResponseHeader_Output* InferResponseHeader::add_output() {
  ::nvidia::inferenceserver::InferResponseHeader_Output* _add = _internal_add_output();
  // @@protoc_insertion_point(field_add:nvidia.inferenceserver.InferResponseHeader.output)
  return _add;
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField< ::nvidia::inferenceserver::InferResponseHeader_Output >&
InferResponseHeader::output() const {
  // @@protoc_insertion_point(field_list:nvidia.inferenceserver.InferResponseHeader.output)
  return output_;
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace inferenceserver
}  // namespace nvidia

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_api_2eproto
