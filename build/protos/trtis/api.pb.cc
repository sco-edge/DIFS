// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: api.proto

#include "api.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG
namespace nvidia {
namespace inferenceserver {
constexpr InferRequestHeader_Input::InferRequestHeader_Input(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : dims_()
  , _dims_cached_byte_size_(0)
  , name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , batch_byte_size_(uint64_t{0u}){}
struct InferRequestHeader_InputDefaultTypeInternal {
  constexpr InferRequestHeader_InputDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferRequestHeader_InputDefaultTypeInternal() {}
  union {
    InferRequestHeader_Input _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferRequestHeader_InputDefaultTypeInternal _InferRequestHeader_Input_default_instance_;
constexpr InferRequestHeader_Output_Class::InferRequestHeader_Output_Class(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : count_(0u){}
struct InferRequestHeader_Output_ClassDefaultTypeInternal {
  constexpr InferRequestHeader_Output_ClassDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferRequestHeader_Output_ClassDefaultTypeInternal() {}
  union {
    InferRequestHeader_Output_Class _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferRequestHeader_Output_ClassDefaultTypeInternal _InferRequestHeader_Output_Class_default_instance_;
constexpr InferRequestHeader_Output::InferRequestHeader_Output(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , cls_(nullptr){}
struct InferRequestHeader_OutputDefaultTypeInternal {
  constexpr InferRequestHeader_OutputDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferRequestHeader_OutputDefaultTypeInternal() {}
  union {
    InferRequestHeader_Output _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferRequestHeader_OutputDefaultTypeInternal _InferRequestHeader_Output_default_instance_;
constexpr InferRequestHeader::InferRequestHeader(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : input_()
  , output_()
  , correlation_id_(uint64_t{0u})
  , batch_size_(0u){}
struct InferRequestHeaderDefaultTypeInternal {
  constexpr InferRequestHeaderDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferRequestHeaderDefaultTypeInternal() {}
  union {
    InferRequestHeader _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferRequestHeaderDefaultTypeInternal _InferRequestHeader_default_instance_;
constexpr InferResponseHeader_Output_Raw::InferResponseHeader_Output_Raw(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : dims_()
  , _dims_cached_byte_size_(0)
  , batch_byte_size_(uint64_t{0u}){}
struct InferResponseHeader_Output_RawDefaultTypeInternal {
  constexpr InferResponseHeader_Output_RawDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferResponseHeader_Output_RawDefaultTypeInternal() {}
  union {
    InferResponseHeader_Output_Raw _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferResponseHeader_Output_RawDefaultTypeInternal _InferResponseHeader_Output_Raw_default_instance_;
constexpr InferResponseHeader_Output_Class::InferResponseHeader_Output_Class(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : label_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , idx_(0)
  , value_(0){}
struct InferResponseHeader_Output_ClassDefaultTypeInternal {
  constexpr InferResponseHeader_Output_ClassDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferResponseHeader_Output_ClassDefaultTypeInternal() {}
  union {
    InferResponseHeader_Output_Class _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferResponseHeader_Output_ClassDefaultTypeInternal _InferResponseHeader_Output_Class_default_instance_;
constexpr InferResponseHeader_Output_Classes::InferResponseHeader_Output_Classes(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : cls_(){}
struct InferResponseHeader_Output_ClassesDefaultTypeInternal {
  constexpr InferResponseHeader_Output_ClassesDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferResponseHeader_Output_ClassesDefaultTypeInternal() {}
  union {
    InferResponseHeader_Output_Classes _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferResponseHeader_Output_ClassesDefaultTypeInternal _InferResponseHeader_Output_Classes_default_instance_;
constexpr InferResponseHeader_Output::InferResponseHeader_Output(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : batch_classes_()
  , name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , raw_(nullptr){}
struct InferResponseHeader_OutputDefaultTypeInternal {
  constexpr InferResponseHeader_OutputDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferResponseHeader_OutputDefaultTypeInternal() {}
  union {
    InferResponseHeader_Output _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferResponseHeader_OutputDefaultTypeInternal _InferResponseHeader_Output_default_instance_;
constexpr InferResponseHeader::InferResponseHeader(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : output_()
  , model_name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , model_version_(int64_t{0})
  , batch_size_(0u){}
struct InferResponseHeaderDefaultTypeInternal {
  constexpr InferResponseHeaderDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferResponseHeaderDefaultTypeInternal() {}
  union {
    InferResponseHeader _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferResponseHeaderDefaultTypeInternal _InferResponseHeader_default_instance_;
}  // namespace inferenceserver
}  // namespace nvidia
static ::PROTOBUF_NAMESPACE_ID::Metadata file_level_metadata_api_2eproto[9];
static constexpr ::PROTOBUF_NAMESPACE_ID::EnumDescriptor const** file_level_enum_descriptors_api_2eproto = nullptr;
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_api_2eproto = nullptr;

const uint32_t TableStruct_api_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Input, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Input, name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Input, dims_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Input, batch_byte_size_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Output_Class, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Output_Class, count_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Output, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Output, name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader_Output, cls_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader, correlation_id_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader, batch_size_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader, input_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferRequestHeader, output_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Raw, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Raw, dims_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Raw, batch_byte_size_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Class, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Class, idx_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Class, value_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Class, label_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Classes, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output_Classes, cls_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output, name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output, raw_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader_Output, batch_classes_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader, model_name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader, model_version_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader, batch_size_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::InferResponseHeader, output_),
};
static const ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::nvidia::inferenceserver::InferRequestHeader_Input)},
  { 9, -1, -1, sizeof(::nvidia::inferenceserver::InferRequestHeader_Output_Class)},
  { 16, -1, -1, sizeof(::nvidia::inferenceserver::InferRequestHeader_Output)},
  { 24, -1, -1, sizeof(::nvidia::inferenceserver::InferRequestHeader)},
  { 34, -1, -1, sizeof(::nvidia::inferenceserver::InferResponseHeader_Output_Raw)},
  { 42, -1, -1, sizeof(::nvidia::inferenceserver::InferResponseHeader_Output_Class)},
  { 51, -1, -1, sizeof(::nvidia::inferenceserver::InferResponseHeader_Output_Classes)},
  { 58, -1, -1, sizeof(::nvidia::inferenceserver::InferResponseHeader_Output)},
  { 67, -1, -1, sizeof(::nvidia::inferenceserver::InferResponseHeader)},
};

static ::PROTOBUF_NAMESPACE_ID::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferRequestHeader_Input_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferRequestHeader_Output_Class_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferRequestHeader_Output_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferRequestHeader_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferResponseHeader_Output_Raw_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferResponseHeader_Output_Class_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferResponseHeader_Output_Classes_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferResponseHeader_Output_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_InferResponseHeader_default_instance_),
};

const char descriptor_table_protodef_api_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n\tapi.proto\022\026nvidia.inferenceserver\"\370\002\n\022"
  "InferRequestHeader\022\026\n\016correlation_id\030\004 \001"
  "(\004\022\022\n\nbatch_size\030\001 \001(\r\022\?\n\005input\030\002 \003(\01320."
  "nvidia.inferenceserver.InferRequestHeade"
  "r.Input\022A\n\006output\030\003 \003(\01321.nvidia.inferen"
  "ceserver.InferRequestHeader.Output\032<\n\005In"
  "put\022\014\n\004name\030\001 \001(\t\022\014\n\004dims\030\002 \003(\003\022\027\n\017batch"
  "_byte_size\030\003 \001(\004\032t\n\006Output\022\014\n\004name\030\001 \001(\t"
  "\022D\n\003cls\030\003 \001(\01327.nvidia.inferenceserver.I"
  "nferRequestHeader.Output.Class\032\026\n\005Class\022"
  "\r\n\005count\030\001 \001(\r\"\375\003\n\023InferResponseHeader\022\022"
  "\n\nmodel_name\030\001 \001(\t\022\025\n\rmodel_version\030\002 \001("
  "\003\022\022\n\nbatch_size\030\003 \001(\r\022B\n\006output\030\004 \003(\01322."
  "nvidia.inferenceserver.InferResponseHead"
  "er.Output\032\342\002\n\006Output\022\014\n\004name\030\001 \001(\t\022C\n\003ra"
  "w\030\002 \001(\01326.nvidia.inferenceserver.InferRe"
  "sponseHeader.Output.Raw\022Q\n\rbatch_classes"
  "\030\003 \003(\0132:.nvidia.inferenceserver.InferRes"
  "ponseHeader.Output.Classes\032,\n\003Raw\022\014\n\004dim"
  "s\030\001 \003(\003\022\027\n\017batch_byte_size\030\002 \001(\004\0322\n\005Clas"
  "s\022\013\n\003idx\030\001 \001(\005\022\r\n\005value\030\002 \001(\002\022\r\n\005label\030\003"
  " \001(\t\032P\n\007Classes\022E\n\003cls\030\001 \003(\01328.nvidia.in"
  "ferenceserver.InferResponseHeader.Output"
  ".Classb\006proto3"
  ;
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_api_2eproto_once;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_api_2eproto = {
  false, false, 934, descriptor_table_protodef_api_2eproto, "api.proto", 
  &descriptor_table_api_2eproto_once, nullptr, 0, 9,
  schemas, file_default_instances, TableStruct_api_2eproto::offsets,
  file_level_metadata_api_2eproto, file_level_enum_descriptors_api_2eproto, file_level_service_descriptors_api_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable* descriptor_table_api_2eproto_getter() {
  return &descriptor_table_api_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY static ::PROTOBUF_NAMESPACE_ID::internal::AddDescriptorsRunner dynamic_init_dummy_api_2eproto(&descriptor_table_api_2eproto);
namespace nvidia {
namespace inferenceserver {

// ===================================================================

class InferRequestHeader_Input::_Internal {
 public:
};

InferRequestHeader_Input::InferRequestHeader_Input(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  dims_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferRequestHeader.Input)
}
InferRequestHeader_Input::InferRequestHeader_Input(const InferRequestHeader_Input& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      dims_(from.dims_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_name(), 
      GetArenaForAllocation());
  }
  batch_byte_size_ = from.batch_byte_size_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferRequestHeader.Input)
}

inline void InferRequestHeader_Input::SharedCtor() {
name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
batch_byte_size_ = uint64_t{0u};
}

InferRequestHeader_Input::~InferRequestHeader_Input() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferRequestHeader.Input)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferRequestHeader_Input::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void InferRequestHeader_Input::ArenaDtor(void* object) {
  InferRequestHeader_Input* _this = reinterpret_cast< InferRequestHeader_Input* >(object);
  (void)_this;
}
void InferRequestHeader_Input::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferRequestHeader_Input::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferRequestHeader_Input::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferRequestHeader.Input)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  dims_.Clear();
  name_.ClearToEmpty();
  batch_byte_size_ = uint64_t{0u};
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferRequestHeader_Input::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.InferRequestHeader.Input.name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated int64 dims = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt64Parser(_internal_mutable_dims(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 16) {
          _internal_add_dims(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 batch_byte_size = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          batch_byte_size_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferRequestHeader_Input::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferRequestHeader.Input)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.InferRequestHeader.Input.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // repeated int64 dims = 2;
  {
    int byte_size = _dims_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt64Packed(
          2, _internal_dims(), byte_size, target);
    }
  }

  // uint64 batch_byte_size = 3;
  if (this->_internal_batch_byte_size() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt64ToArray(3, this->_internal_batch_byte_size(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferRequestHeader.Input)
  return target;
}

size_t InferRequestHeader_Input::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferRequestHeader.Input)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int64 dims = 2;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int64Size(this->dims_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<int32_t>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _dims_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  // uint64 batch_byte_size = 3;
  if (this->_internal_batch_byte_size() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt64SizePlusOne(this->_internal_batch_byte_size());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferRequestHeader_Input::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferRequestHeader_Input::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferRequestHeader_Input::GetClassData() const { return &_class_data_; }

void InferRequestHeader_Input::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferRequestHeader_Input *>(to)->MergeFrom(
      static_cast<const InferRequestHeader_Input &>(from));
}


void InferRequestHeader_Input::MergeFrom(const InferRequestHeader_Input& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferRequestHeader.Input)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  dims_.MergeFrom(from.dims_);
  if (!from._internal_name().empty()) {
    _internal_set_name(from._internal_name());
  }
  if (from._internal_batch_byte_size() != 0) {
    _internal_set_batch_byte_size(from._internal_batch_byte_size());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferRequestHeader_Input::CopyFrom(const InferRequestHeader_Input& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferRequestHeader.Input)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferRequestHeader_Input::IsInitialized() const {
  return true;
}

void InferRequestHeader_Input::InternalSwap(InferRequestHeader_Input* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  dims_.InternalSwap(&other->dims_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &name_, lhs_arena,
      &other->name_, rhs_arena
  );
  swap(batch_byte_size_, other->batch_byte_size_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferRequestHeader_Input::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[0]);
}

// ===================================================================

class InferRequestHeader_Output_Class::_Internal {
 public:
};

InferRequestHeader_Output_Class::InferRequestHeader_Output_Class(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferRequestHeader.Output.Class)
}
InferRequestHeader_Output_Class::InferRequestHeader_Output_Class(const InferRequestHeader_Output_Class& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  count_ = from.count_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferRequestHeader.Output.Class)
}

inline void InferRequestHeader_Output_Class::SharedCtor() {
count_ = 0u;
}

InferRequestHeader_Output_Class::~InferRequestHeader_Output_Class() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferRequestHeader.Output.Class)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferRequestHeader_Output_Class::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void InferRequestHeader_Output_Class::ArenaDtor(void* object) {
  InferRequestHeader_Output_Class* _this = reinterpret_cast< InferRequestHeader_Output_Class* >(object);
  (void)_this;
}
void InferRequestHeader_Output_Class::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferRequestHeader_Output_Class::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferRequestHeader_Output_Class::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferRequestHeader.Output.Class)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  count_ = 0u;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferRequestHeader_Output_Class::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint32 count = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          count_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferRequestHeader_Output_Class::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferRequestHeader.Output.Class)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint32 count = 1;
  if (this->_internal_count() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt32ToArray(1, this->_internal_count(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferRequestHeader.Output.Class)
  return target;
}

size_t InferRequestHeader_Output_Class::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferRequestHeader.Output.Class)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint32 count = 1;
  if (this->_internal_count() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt32SizePlusOne(this->_internal_count());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferRequestHeader_Output_Class::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferRequestHeader_Output_Class::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferRequestHeader_Output_Class::GetClassData() const { return &_class_data_; }

void InferRequestHeader_Output_Class::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferRequestHeader_Output_Class *>(to)->MergeFrom(
      static_cast<const InferRequestHeader_Output_Class &>(from));
}


void InferRequestHeader_Output_Class::MergeFrom(const InferRequestHeader_Output_Class& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferRequestHeader.Output.Class)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_count() != 0) {
    _internal_set_count(from._internal_count());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferRequestHeader_Output_Class::CopyFrom(const InferRequestHeader_Output_Class& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferRequestHeader.Output.Class)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferRequestHeader_Output_Class::IsInitialized() const {
  return true;
}

void InferRequestHeader_Output_Class::InternalSwap(InferRequestHeader_Output_Class* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(count_, other->count_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferRequestHeader_Output_Class::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[1]);
}

// ===================================================================

class InferRequestHeader_Output::_Internal {
 public:
  static const ::nvidia::inferenceserver::InferRequestHeader_Output_Class& cls(const InferRequestHeader_Output* msg);
};

const ::nvidia::inferenceserver::InferRequestHeader_Output_Class&
InferRequestHeader_Output::_Internal::cls(const InferRequestHeader_Output* msg) {
  return *msg->cls_;
}
InferRequestHeader_Output::InferRequestHeader_Output(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferRequestHeader.Output)
}
InferRequestHeader_Output::InferRequestHeader_Output(const InferRequestHeader_Output& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_name(), 
      GetArenaForAllocation());
  }
  if (from._internal_has_cls()) {
    cls_ = new ::nvidia::inferenceserver::InferRequestHeader_Output_Class(*from.cls_);
  } else {
    cls_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferRequestHeader.Output)
}

inline void InferRequestHeader_Output::SharedCtor() {
name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
cls_ = nullptr;
}

InferRequestHeader_Output::~InferRequestHeader_Output() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferRequestHeader.Output)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferRequestHeader_Output::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete cls_;
}

void InferRequestHeader_Output::ArenaDtor(void* object) {
  InferRequestHeader_Output* _this = reinterpret_cast< InferRequestHeader_Output* >(object);
  (void)_this;
}
void InferRequestHeader_Output::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferRequestHeader_Output::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferRequestHeader_Output::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferRequestHeader.Output)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  name_.ClearToEmpty();
  if (GetArenaForAllocation() == nullptr && cls_ != nullptr) {
    delete cls_;
  }
  cls_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferRequestHeader_Output::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.InferRequestHeader.Output.name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.InferRequestHeader.Output.Class cls = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_cls(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferRequestHeader_Output::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferRequestHeader.Output)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.InferRequestHeader.Output.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // .nvidia.inferenceserver.InferRequestHeader.Output.Class cls = 3;
  if (this->_internal_has_cls()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        3, _Internal::cls(this), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferRequestHeader.Output)
  return target;
}

size_t InferRequestHeader_Output::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferRequestHeader.Output)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  // .nvidia.inferenceserver.InferRequestHeader.Output.Class cls = 3;
  if (this->_internal_has_cls()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *cls_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferRequestHeader_Output::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferRequestHeader_Output::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferRequestHeader_Output::GetClassData() const { return &_class_data_; }

void InferRequestHeader_Output::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferRequestHeader_Output *>(to)->MergeFrom(
      static_cast<const InferRequestHeader_Output &>(from));
}


void InferRequestHeader_Output::MergeFrom(const InferRequestHeader_Output& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferRequestHeader.Output)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_name().empty()) {
    _internal_set_name(from._internal_name());
  }
  if (from._internal_has_cls()) {
    _internal_mutable_cls()->::nvidia::inferenceserver::InferRequestHeader_Output_Class::MergeFrom(from._internal_cls());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferRequestHeader_Output::CopyFrom(const InferRequestHeader_Output& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferRequestHeader.Output)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferRequestHeader_Output::IsInitialized() const {
  return true;
}

void InferRequestHeader_Output::InternalSwap(InferRequestHeader_Output* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &name_, lhs_arena,
      &other->name_, rhs_arena
  );
  swap(cls_, other->cls_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferRequestHeader_Output::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[2]);
}

// ===================================================================

class InferRequestHeader::_Internal {
 public:
};

InferRequestHeader::InferRequestHeader(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  input_(arena),
  output_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferRequestHeader)
}
InferRequestHeader::InferRequestHeader(const InferRequestHeader& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      input_(from.input_),
      output_(from.output_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&correlation_id_, &from.correlation_id_,
    static_cast<size_t>(reinterpret_cast<char*>(&batch_size_) -
    reinterpret_cast<char*>(&correlation_id_)) + sizeof(batch_size_));
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferRequestHeader)
}

inline void InferRequestHeader::SharedCtor() {
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&correlation_id_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&batch_size_) -
    reinterpret_cast<char*>(&correlation_id_)) + sizeof(batch_size_));
}

InferRequestHeader::~InferRequestHeader() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferRequestHeader)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferRequestHeader::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void InferRequestHeader::ArenaDtor(void* object) {
  InferRequestHeader* _this = reinterpret_cast< InferRequestHeader* >(object);
  (void)_this;
}
void InferRequestHeader::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferRequestHeader::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferRequestHeader::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferRequestHeader)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  input_.Clear();
  output_.Clear();
  ::memset(&correlation_id_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&batch_size_) -
      reinterpret_cast<char*>(&correlation_id_)) + sizeof(batch_size_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferRequestHeader::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint32 batch_size = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          batch_size_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .nvidia.inferenceserver.InferRequestHeader.Input input = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_input(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .nvidia.inferenceserver.InferRequestHeader.Output output = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_output(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<26>(ptr));
        } else
          goto handle_unusual;
        continue;
      // uint64 correlation_id = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          correlation_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferRequestHeader::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferRequestHeader)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint32 batch_size = 1;
  if (this->_internal_batch_size() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt32ToArray(1, this->_internal_batch_size(), target);
  }

  // repeated .nvidia.inferenceserver.InferRequestHeader.Input input = 2;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_input_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, this->_internal_input(i), target, stream);
  }

  // repeated .nvidia.inferenceserver.InferRequestHeader.Output output = 3;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_output_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(3, this->_internal_output(i), target, stream);
  }

  // uint64 correlation_id = 4;
  if (this->_internal_correlation_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt64ToArray(4, this->_internal_correlation_id(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferRequestHeader)
  return target;
}

size_t InferRequestHeader::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferRequestHeader)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.inferenceserver.InferRequestHeader.Input input = 2;
  total_size += 1UL * this->_internal_input_size();
  for (const auto& msg : this->input_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .nvidia.inferenceserver.InferRequestHeader.Output output = 3;
  total_size += 1UL * this->_internal_output_size();
  for (const auto& msg : this->output_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // uint64 correlation_id = 4;
  if (this->_internal_correlation_id() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt64SizePlusOne(this->_internal_correlation_id());
  }

  // uint32 batch_size = 1;
  if (this->_internal_batch_size() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt32SizePlusOne(this->_internal_batch_size());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferRequestHeader::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferRequestHeader::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferRequestHeader::GetClassData() const { return &_class_data_; }

void InferRequestHeader::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferRequestHeader *>(to)->MergeFrom(
      static_cast<const InferRequestHeader &>(from));
}


void InferRequestHeader::MergeFrom(const InferRequestHeader& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferRequestHeader)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  input_.MergeFrom(from.input_);
  output_.MergeFrom(from.output_);
  if (from._internal_correlation_id() != 0) {
    _internal_set_correlation_id(from._internal_correlation_id());
  }
  if (from._internal_batch_size() != 0) {
    _internal_set_batch_size(from._internal_batch_size());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferRequestHeader::CopyFrom(const InferRequestHeader& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferRequestHeader)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferRequestHeader::IsInitialized() const {
  return true;
}

void InferRequestHeader::InternalSwap(InferRequestHeader* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  input_.InternalSwap(&other->input_);
  output_.InternalSwap(&other->output_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(InferRequestHeader, batch_size_)
      + sizeof(InferRequestHeader::batch_size_)
      - PROTOBUF_FIELD_OFFSET(InferRequestHeader, correlation_id_)>(
          reinterpret_cast<char*>(&correlation_id_),
          reinterpret_cast<char*>(&other->correlation_id_));
}

::PROTOBUF_NAMESPACE_ID::Metadata InferRequestHeader::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[3]);
}

// ===================================================================

class InferResponseHeader_Output_Raw::_Internal {
 public:
};

InferResponseHeader_Output_Raw::InferResponseHeader_Output_Raw(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  dims_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
}
InferResponseHeader_Output_Raw::InferResponseHeader_Output_Raw(const InferResponseHeader_Output_Raw& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      dims_(from.dims_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  batch_byte_size_ = from.batch_byte_size_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
}

inline void InferResponseHeader_Output_Raw::SharedCtor() {
batch_byte_size_ = uint64_t{0u};
}

InferResponseHeader_Output_Raw::~InferResponseHeader_Output_Raw() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferResponseHeader_Output_Raw::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void InferResponseHeader_Output_Raw::ArenaDtor(void* object) {
  InferResponseHeader_Output_Raw* _this = reinterpret_cast< InferResponseHeader_Output_Raw* >(object);
  (void)_this;
}
void InferResponseHeader_Output_Raw::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferResponseHeader_Output_Raw::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferResponseHeader_Output_Raw::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  dims_.Clear();
  batch_byte_size_ = uint64_t{0u};
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferResponseHeader_Output_Raw::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated int64 dims = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt64Parser(_internal_mutable_dims(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 8) {
          _internal_add_dims(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 batch_byte_size = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          batch_byte_size_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferResponseHeader_Output_Raw::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated int64 dims = 1;
  {
    int byte_size = _dims_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt64Packed(
          1, _internal_dims(), byte_size, target);
    }
  }

  // uint64 batch_byte_size = 2;
  if (this->_internal_batch_byte_size() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt64ToArray(2, this->_internal_batch_byte_size(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
  return target;
}

size_t InferResponseHeader_Output_Raw::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int64 dims = 1;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int64Size(this->dims_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<int32_t>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _dims_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // uint64 batch_byte_size = 2;
  if (this->_internal_batch_byte_size() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt64SizePlusOne(this->_internal_batch_byte_size());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferResponseHeader_Output_Raw::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferResponseHeader_Output_Raw::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferResponseHeader_Output_Raw::GetClassData() const { return &_class_data_; }

void InferResponseHeader_Output_Raw::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferResponseHeader_Output_Raw *>(to)->MergeFrom(
      static_cast<const InferResponseHeader_Output_Raw &>(from));
}


void InferResponseHeader_Output_Raw::MergeFrom(const InferResponseHeader_Output_Raw& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  dims_.MergeFrom(from.dims_);
  if (from._internal_batch_byte_size() != 0) {
    _internal_set_batch_byte_size(from._internal_batch_byte_size());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferResponseHeader_Output_Raw::CopyFrom(const InferResponseHeader_Output_Raw& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferResponseHeader.Output.Raw)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferResponseHeader_Output_Raw::IsInitialized() const {
  return true;
}

void InferResponseHeader_Output_Raw::InternalSwap(InferResponseHeader_Output_Raw* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  dims_.InternalSwap(&other->dims_);
  swap(batch_byte_size_, other->batch_byte_size_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferResponseHeader_Output_Raw::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[4]);
}

// ===================================================================

class InferResponseHeader_Output_Class::_Internal {
 public:
};

InferResponseHeader_Output_Class::InferResponseHeader_Output_Class(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferResponseHeader.Output.Class)
}
InferResponseHeader_Output_Class::InferResponseHeader_Output_Class(const InferResponseHeader_Output_Class& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  label_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    label_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_label().empty()) {
    label_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_label(), 
      GetArenaForAllocation());
  }
  ::memcpy(&idx_, &from.idx_,
    static_cast<size_t>(reinterpret_cast<char*>(&value_) -
    reinterpret_cast<char*>(&idx_)) + sizeof(value_));
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferResponseHeader.Output.Class)
}

inline void InferResponseHeader_Output_Class::SharedCtor() {
label_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  label_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&idx_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&value_) -
    reinterpret_cast<char*>(&idx_)) + sizeof(value_));
}

InferResponseHeader_Output_Class::~InferResponseHeader_Output_Class() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferResponseHeader.Output.Class)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferResponseHeader_Output_Class::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  label_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void InferResponseHeader_Output_Class::ArenaDtor(void* object) {
  InferResponseHeader_Output_Class* _this = reinterpret_cast< InferResponseHeader_Output_Class* >(object);
  (void)_this;
}
void InferResponseHeader_Output_Class::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferResponseHeader_Output_Class::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferResponseHeader_Output_Class::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferResponseHeader.Output.Class)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  label_.ClearToEmpty();
  ::memset(&idx_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&value_) -
      reinterpret_cast<char*>(&idx_)) + sizeof(value_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferResponseHeader_Output_Class::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 idx = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          idx_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // float value = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 21)) {
          value_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // string label = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          auto str = _internal_mutable_label();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.InferResponseHeader.Output.Class.label"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferResponseHeader_Output_Class::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferResponseHeader.Output.Class)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 idx = 1;
  if (this->_internal_idx() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(1, this->_internal_idx(), target);
  }

  // float value = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_value = this->_internal_value();
  uint32_t raw_value;
  memcpy(&raw_value, &tmp_value, sizeof(tmp_value));
  if (raw_value != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteFloatToArray(2, this->_internal_value(), target);
  }

  // string label = 3;
  if (!this->_internal_label().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_label().data(), static_cast<int>(this->_internal_label().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.InferResponseHeader.Output.Class.label");
    target = stream->WriteStringMaybeAliased(
        3, this->_internal_label(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferResponseHeader.Output.Class)
  return target;
}

size_t InferResponseHeader_Output_Class::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferResponseHeader.Output.Class)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // string label = 3;
  if (!this->_internal_label().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_label());
  }

  // int32 idx = 1;
  if (this->_internal_idx() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_idx());
  }

  // float value = 2;
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_value = this->_internal_value();
  uint32_t raw_value;
  memcpy(&raw_value, &tmp_value, sizeof(tmp_value));
  if (raw_value != 0) {
    total_size += 1 + 4;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferResponseHeader_Output_Class::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferResponseHeader_Output_Class::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferResponseHeader_Output_Class::GetClassData() const { return &_class_data_; }

void InferResponseHeader_Output_Class::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferResponseHeader_Output_Class *>(to)->MergeFrom(
      static_cast<const InferResponseHeader_Output_Class &>(from));
}


void InferResponseHeader_Output_Class::MergeFrom(const InferResponseHeader_Output_Class& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferResponseHeader.Output.Class)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_label().empty()) {
    _internal_set_label(from._internal_label());
  }
  if (from._internal_idx() != 0) {
    _internal_set_idx(from._internal_idx());
  }
  static_assert(sizeof(uint32_t) == sizeof(float), "Code assumes uint32_t and float are the same size.");
  float tmp_value = from._internal_value();
  uint32_t raw_value;
  memcpy(&raw_value, &tmp_value, sizeof(tmp_value));
  if (raw_value != 0) {
    _internal_set_value(from._internal_value());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferResponseHeader_Output_Class::CopyFrom(const InferResponseHeader_Output_Class& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferResponseHeader.Output.Class)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferResponseHeader_Output_Class::IsInitialized() const {
  return true;
}

void InferResponseHeader_Output_Class::InternalSwap(InferResponseHeader_Output_Class* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &label_, lhs_arena,
      &other->label_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(InferResponseHeader_Output_Class, value_)
      + sizeof(InferResponseHeader_Output_Class::value_)
      - PROTOBUF_FIELD_OFFSET(InferResponseHeader_Output_Class, idx_)>(
          reinterpret_cast<char*>(&idx_),
          reinterpret_cast<char*>(&other->idx_));
}

::PROTOBUF_NAMESPACE_ID::Metadata InferResponseHeader_Output_Class::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[5]);
}

// ===================================================================

class InferResponseHeader_Output_Classes::_Internal {
 public:
};

InferResponseHeader_Output_Classes::InferResponseHeader_Output_Classes(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  cls_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
}
InferResponseHeader_Output_Classes::InferResponseHeader_Output_Classes(const InferResponseHeader_Output_Classes& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      cls_(from.cls_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
}

inline void InferResponseHeader_Output_Classes::SharedCtor() {
}

InferResponseHeader_Output_Classes::~InferResponseHeader_Output_Classes() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferResponseHeader_Output_Classes::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void InferResponseHeader_Output_Classes::ArenaDtor(void* object) {
  InferResponseHeader_Output_Classes* _this = reinterpret_cast< InferResponseHeader_Output_Classes* >(object);
  (void)_this;
}
void InferResponseHeader_Output_Classes::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferResponseHeader_Output_Classes::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferResponseHeader_Output_Classes::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cls_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferResponseHeader_Output_Classes::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Class cls = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_cls(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferResponseHeader_Output_Classes::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Class cls = 1;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_cls_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, this->_internal_cls(i), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
  return target;
}

size_t InferResponseHeader_Output_Classes::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Class cls = 1;
  total_size += 1UL * this->_internal_cls_size();
  for (const auto& msg : this->cls_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferResponseHeader_Output_Classes::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferResponseHeader_Output_Classes::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferResponseHeader_Output_Classes::GetClassData() const { return &_class_data_; }

void InferResponseHeader_Output_Classes::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferResponseHeader_Output_Classes *>(to)->MergeFrom(
      static_cast<const InferResponseHeader_Output_Classes &>(from));
}


void InferResponseHeader_Output_Classes::MergeFrom(const InferResponseHeader_Output_Classes& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cls_.MergeFrom(from.cls_);
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferResponseHeader_Output_Classes::CopyFrom(const InferResponseHeader_Output_Classes& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferResponseHeader.Output.Classes)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferResponseHeader_Output_Classes::IsInitialized() const {
  return true;
}

void InferResponseHeader_Output_Classes::InternalSwap(InferResponseHeader_Output_Classes* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  cls_.InternalSwap(&other->cls_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferResponseHeader_Output_Classes::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[6]);
}

// ===================================================================

class InferResponseHeader_Output::_Internal {
 public:
  static const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw& raw(const InferResponseHeader_Output* msg);
};

const ::nvidia::inferenceserver::InferResponseHeader_Output_Raw&
InferResponseHeader_Output::_Internal::raw(const InferResponseHeader_Output* msg) {
  return *msg->raw_;
}
InferResponseHeader_Output::InferResponseHeader_Output(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  batch_classes_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferResponseHeader.Output)
}
InferResponseHeader_Output::InferResponseHeader_Output(const InferResponseHeader_Output& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      batch_classes_(from.batch_classes_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_name(), 
      GetArenaForAllocation());
  }
  if (from._internal_has_raw()) {
    raw_ = new ::nvidia::inferenceserver::InferResponseHeader_Output_Raw(*from.raw_);
  } else {
    raw_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferResponseHeader.Output)
}

inline void InferResponseHeader_Output::SharedCtor() {
name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
raw_ = nullptr;
}

InferResponseHeader_Output::~InferResponseHeader_Output() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferResponseHeader.Output)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferResponseHeader_Output::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete raw_;
}

void InferResponseHeader_Output::ArenaDtor(void* object) {
  InferResponseHeader_Output* _this = reinterpret_cast< InferResponseHeader_Output* >(object);
  (void)_this;
}
void InferResponseHeader_Output::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferResponseHeader_Output::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferResponseHeader_Output::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferResponseHeader.Output)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  batch_classes_.Clear();
  name_.ClearToEmpty();
  if (GetArenaForAllocation() == nullptr && raw_ != nullptr) {
    delete raw_;
  }
  raw_ = nullptr;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferResponseHeader_Output::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.InferResponseHeader.Output.name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.InferResponseHeader.Output.Raw raw = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_raw(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Classes batch_classes = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_batch_classes(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<26>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferResponseHeader_Output::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferResponseHeader.Output)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.InferResponseHeader.Output.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // .nvidia.inferenceserver.InferResponseHeader.Output.Raw raw = 2;
  if (this->_internal_has_raw()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        2, _Internal::raw(this), target, stream);
  }

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Classes batch_classes = 3;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_batch_classes_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(3, this->_internal_batch_classes(i), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferResponseHeader.Output)
  return target;
}

size_t InferResponseHeader_Output::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferResponseHeader.Output)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output.Classes batch_classes = 3;
  total_size += 1UL * this->_internal_batch_classes_size();
  for (const auto& msg : this->batch_classes_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  // .nvidia.inferenceserver.InferResponseHeader.Output.Raw raw = 2;
  if (this->_internal_has_raw()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *raw_);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferResponseHeader_Output::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferResponseHeader_Output::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferResponseHeader_Output::GetClassData() const { return &_class_data_; }

void InferResponseHeader_Output::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferResponseHeader_Output *>(to)->MergeFrom(
      static_cast<const InferResponseHeader_Output &>(from));
}


void InferResponseHeader_Output::MergeFrom(const InferResponseHeader_Output& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferResponseHeader.Output)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  batch_classes_.MergeFrom(from.batch_classes_);
  if (!from._internal_name().empty()) {
    _internal_set_name(from._internal_name());
  }
  if (from._internal_has_raw()) {
    _internal_mutable_raw()->::nvidia::inferenceserver::InferResponseHeader_Output_Raw::MergeFrom(from._internal_raw());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferResponseHeader_Output::CopyFrom(const InferResponseHeader_Output& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferResponseHeader.Output)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferResponseHeader_Output::IsInitialized() const {
  return true;
}

void InferResponseHeader_Output::InternalSwap(InferResponseHeader_Output* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  batch_classes_.InternalSwap(&other->batch_classes_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &name_, lhs_arena,
      &other->name_, rhs_arena
  );
  swap(raw_, other->raw_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferResponseHeader_Output::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[7]);
}

// ===================================================================

class InferResponseHeader::_Internal {
 public:
};

InferResponseHeader::InferResponseHeader(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  output_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.InferResponseHeader)
}
InferResponseHeader::InferResponseHeader(const InferResponseHeader& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      output_(from.output_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  model_name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    model_name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_model_name().empty()) {
    model_name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_model_name(), 
      GetArenaForAllocation());
  }
  ::memcpy(&model_version_, &from.model_version_,
    static_cast<size_t>(reinterpret_cast<char*>(&batch_size_) -
    reinterpret_cast<char*>(&model_version_)) + sizeof(batch_size_));
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.InferResponseHeader)
}

inline void InferResponseHeader::SharedCtor() {
model_name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  model_name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&model_version_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&batch_size_) -
    reinterpret_cast<char*>(&model_version_)) + sizeof(batch_size_));
}

InferResponseHeader::~InferResponseHeader() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.InferResponseHeader)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferResponseHeader::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  model_name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void InferResponseHeader::ArenaDtor(void* object) {
  InferResponseHeader* _this = reinterpret_cast< InferResponseHeader* >(object);
  (void)_this;
}
void InferResponseHeader::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferResponseHeader::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferResponseHeader::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.InferResponseHeader)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  output_.Clear();
  model_name_.ClearToEmpty();
  ::memset(&model_version_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&batch_size_) -
      reinterpret_cast<char*>(&model_version_)) + sizeof(batch_size_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferResponseHeader::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string model_name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_model_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.InferResponseHeader.model_name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int64 model_version = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          model_version_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint32 batch_size = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          batch_size_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .nvidia.inferenceserver.InferResponseHeader.Output output = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_output(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<34>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferResponseHeader::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.InferResponseHeader)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string model_name = 1;
  if (!this->_internal_model_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_model_name().data(), static_cast<int>(this->_internal_model_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.InferResponseHeader.model_name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_model_name(), target);
  }

  // int64 model_version = 2;
  if (this->_internal_model_version() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt64ToArray(2, this->_internal_model_version(), target);
  }

  // uint32 batch_size = 3;
  if (this->_internal_batch_size() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt32ToArray(3, this->_internal_batch_size(), target);
  }

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output output = 4;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_output_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(4, this->_internal_output(i), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.InferResponseHeader)
  return target;
}

size_t InferResponseHeader::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.InferResponseHeader)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.inferenceserver.InferResponseHeader.Output output = 4;
  total_size += 1UL * this->_internal_output_size();
  for (const auto& msg : this->output_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // string model_name = 1;
  if (!this->_internal_model_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_model_name());
  }

  // int64 model_version = 2;
  if (this->_internal_model_version() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int64SizePlusOne(this->_internal_model_version());
  }

  // uint32 batch_size = 3;
  if (this->_internal_batch_size() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt32SizePlusOne(this->_internal_batch_size());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferResponseHeader::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferResponseHeader::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferResponseHeader::GetClassData() const { return &_class_data_; }

void InferResponseHeader::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferResponseHeader *>(to)->MergeFrom(
      static_cast<const InferResponseHeader &>(from));
}


void InferResponseHeader::MergeFrom(const InferResponseHeader& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.InferResponseHeader)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  output_.MergeFrom(from.output_);
  if (!from._internal_model_name().empty()) {
    _internal_set_model_name(from._internal_model_name());
  }
  if (from._internal_model_version() != 0) {
    _internal_set_model_version(from._internal_model_version());
  }
  if (from._internal_batch_size() != 0) {
    _internal_set_batch_size(from._internal_batch_size());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferResponseHeader::CopyFrom(const InferResponseHeader& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.InferResponseHeader)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferResponseHeader::IsInitialized() const {
  return true;
}

void InferResponseHeader::InternalSwap(InferResponseHeader* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  output_.InternalSwap(&other->output_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &model_name_, lhs_arena,
      &other->model_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(InferResponseHeader, batch_size_)
      + sizeof(InferResponseHeader::batch_size_)
      - PROTOBUF_FIELD_OFFSET(InferResponseHeader, model_version_)>(
          reinterpret_cast<char*>(&model_version_),
          reinterpret_cast<char*>(&other->model_version_));
}

::PROTOBUF_NAMESPACE_ID::Metadata InferResponseHeader::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_api_2eproto_getter, &descriptor_table_api_2eproto_once,
      file_level_metadata_api_2eproto[8]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace inferenceserver
}  // namespace nvidia
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferRequestHeader_Input* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferRequestHeader_Input >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferRequestHeader_Input >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferRequestHeader_Output_Class* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferRequestHeader_Output_Class >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferRequestHeader_Output_Class >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferRequestHeader_Output* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferRequestHeader_Output >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferRequestHeader_Output >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferRequestHeader* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferRequestHeader >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferRequestHeader >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferResponseHeader_Output_Raw* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferResponseHeader_Output_Raw >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferResponseHeader_Output_Raw >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferResponseHeader_Output_Class* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferResponseHeader_Output_Class >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferResponseHeader_Output_Classes* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferResponseHeader_Output_Classes >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferResponseHeader_Output* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferResponseHeader_Output >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferResponseHeader_Output >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::InferResponseHeader* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::InferResponseHeader >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::InferResponseHeader >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
