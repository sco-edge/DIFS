// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: model_config.proto

#include "model_config.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG
namespace nvidia {
namespace inferenceserver {
constexpr ModelInstanceGroup::ModelInstanceGroup(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : gpus_()
  , _gpus_cached_byte_size_(0)
  , name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , count_(0)
  , kind_(0)
{}
struct ModelInstanceGroupDefaultTypeInternal {
  constexpr ModelInstanceGroupDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelInstanceGroupDefaultTypeInternal() {}
  union {
    ModelInstanceGroup _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelInstanceGroupDefaultTypeInternal _ModelInstanceGroup_default_instance_;
constexpr ModelInput::ModelInput(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : dims_()
  , _dims_cached_byte_size_(0)
  , name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , data_type_(0)

  , format_(0)
{}
struct ModelInputDefaultTypeInternal {
  constexpr ModelInputDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelInputDefaultTypeInternal() {}
  union {
    ModelInput _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelInputDefaultTypeInternal _ModelInput_default_instance_;
constexpr ModelOutput::ModelOutput(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : dims_()
  , _dims_cached_byte_size_(0)
  , name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , label_filename_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , data_type_(0)
{}
struct ModelOutputDefaultTypeInternal {
  constexpr ModelOutputDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelOutputDefaultTypeInternal() {}
  union {
    ModelOutput _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelOutputDefaultTypeInternal _ModelOutput_default_instance_;
constexpr ModelVersionPolicy_Latest::ModelVersionPolicy_Latest(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : num_versions_(0u){}
struct ModelVersionPolicy_LatestDefaultTypeInternal {
  constexpr ModelVersionPolicy_LatestDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelVersionPolicy_LatestDefaultTypeInternal() {}
  union {
    ModelVersionPolicy_Latest _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelVersionPolicy_LatestDefaultTypeInternal _ModelVersionPolicy_Latest_default_instance_;
constexpr ModelVersionPolicy_All::ModelVersionPolicy_All(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized){}
struct ModelVersionPolicy_AllDefaultTypeInternal {
  constexpr ModelVersionPolicy_AllDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelVersionPolicy_AllDefaultTypeInternal() {}
  union {
    ModelVersionPolicy_All _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelVersionPolicy_AllDefaultTypeInternal _ModelVersionPolicy_All_default_instance_;
constexpr ModelVersionPolicy_Specific::ModelVersionPolicy_Specific(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : versions_()
  , _versions_cached_byte_size_(0){}
struct ModelVersionPolicy_SpecificDefaultTypeInternal {
  constexpr ModelVersionPolicy_SpecificDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelVersionPolicy_SpecificDefaultTypeInternal() {}
  union {
    ModelVersionPolicy_Specific _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelVersionPolicy_SpecificDefaultTypeInternal _ModelVersionPolicy_Specific_default_instance_;
constexpr ModelVersionPolicy::ModelVersionPolicy(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : _oneof_case_{}{}
struct ModelVersionPolicyDefaultTypeInternal {
  constexpr ModelVersionPolicyDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelVersionPolicyDefaultTypeInternal() {}
  union {
    ModelVersionPolicy _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelVersionPolicyDefaultTypeInternal _ModelVersionPolicy_default_instance_;
constexpr ModelOptimizationPolicy_Graph::ModelOptimizationPolicy_Graph(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : level_(0){}
struct ModelOptimizationPolicy_GraphDefaultTypeInternal {
  constexpr ModelOptimizationPolicy_GraphDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelOptimizationPolicy_GraphDefaultTypeInternal() {}
  union {
    ModelOptimizationPolicy_Graph _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelOptimizationPolicy_GraphDefaultTypeInternal _ModelOptimizationPolicy_Graph_default_instance_;
constexpr ModelOptimizationPolicy::ModelOptimizationPolicy(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : graph_(nullptr)
  , priority_(0)
{}
struct ModelOptimizationPolicyDefaultTypeInternal {
  constexpr ModelOptimizationPolicyDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelOptimizationPolicyDefaultTypeInternal() {}
  union {
    ModelOptimizationPolicy _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelOptimizationPolicyDefaultTypeInternal _ModelOptimizationPolicy_default_instance_;
constexpr ModelDynamicBatching::ModelDynamicBatching(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : preferred_batch_size_()
  , _preferred_batch_size_cached_byte_size_(0)
  , max_queue_delay_microseconds_(0){}
struct ModelDynamicBatchingDefaultTypeInternal {
  constexpr ModelDynamicBatchingDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelDynamicBatchingDefaultTypeInternal() {}
  union {
    ModelDynamicBatching _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelDynamicBatchingDefaultTypeInternal _ModelDynamicBatching_default_instance_;
constexpr ModelSequenceBatching::ModelSequenceBatching(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : max_queue_delay_microseconds_(0){}
struct ModelSequenceBatchingDefaultTypeInternal {
  constexpr ModelSequenceBatchingDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelSequenceBatchingDefaultTypeInternal() {}
  union {
    ModelSequenceBatching _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelSequenceBatchingDefaultTypeInternal _ModelSequenceBatching_default_instance_;
constexpr ModelConfig_CcModelFilenamesEntry_DoNotUse::ModelConfig_CcModelFilenamesEntry_DoNotUse(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized){}
struct ModelConfig_CcModelFilenamesEntry_DoNotUseDefaultTypeInternal {
  constexpr ModelConfig_CcModelFilenamesEntry_DoNotUseDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelConfig_CcModelFilenamesEntry_DoNotUseDefaultTypeInternal() {}
  union {
    ModelConfig_CcModelFilenamesEntry_DoNotUse _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelConfig_CcModelFilenamesEntry_DoNotUseDefaultTypeInternal _ModelConfig_CcModelFilenamesEntry_DoNotUse_default_instance_;
constexpr ModelConfig_TagsEntry_DoNotUse::ModelConfig_TagsEntry_DoNotUse(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized){}
struct ModelConfig_TagsEntry_DoNotUseDefaultTypeInternal {
  constexpr ModelConfig_TagsEntry_DoNotUseDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelConfig_TagsEntry_DoNotUseDefaultTypeInternal() {}
  union {
    ModelConfig_TagsEntry_DoNotUse _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelConfig_TagsEntry_DoNotUseDefaultTypeInternal _ModelConfig_TagsEntry_DoNotUse_default_instance_;
constexpr ModelConfig::ModelConfig(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : input_()
  , output_()
  , instance_group_()
  , cc_model_filenames_(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{})
  , tags_(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{})
  , name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , platform_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , default_model_filename_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , version_policy_(nullptr)
  , optimization_(nullptr)
  , max_batch_size_(0)
  , _oneof_case_{}{}
struct ModelConfigDefaultTypeInternal {
  constexpr ModelConfigDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~ModelConfigDefaultTypeInternal() {}
  union {
    ModelConfig _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT ModelConfigDefaultTypeInternal _ModelConfig_default_instance_;
}  // namespace inferenceserver
}  // namespace nvidia
static ::PROTOBUF_NAMESPACE_ID::Metadata file_level_metadata_model_5fconfig_2eproto[14];
static const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* file_level_enum_descriptors_model_5fconfig_2eproto[4];
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_model_5fconfig_2eproto = nullptr;

const uint32_t TableStruct_model_5fconfig_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInstanceGroup, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInstanceGroup, name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInstanceGroup, kind_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInstanceGroup, count_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInstanceGroup, gpus_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInput, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInput, name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInput, data_type_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInput, format_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelInput, dims_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOutput, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOutput, name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOutput, data_type_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOutput, dims_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOutput, label_filename_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy_Latest, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy_Latest, num_versions_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy_All, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy_Specific, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy_Specific, versions_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy, _oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelVersionPolicy, policy_choice_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOptimizationPolicy_Graph, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOptimizationPolicy_Graph, level_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOptimizationPolicy, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOptimizationPolicy, graph_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelOptimizationPolicy, priority_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelDynamicBatching, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelDynamicBatching, preferred_batch_size_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelDynamicBatching, max_queue_delay_microseconds_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelSequenceBatching, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelSequenceBatching, max_queue_delay_microseconds_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse, key_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse, value_),
  0,
  1,
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse, key_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse, value_),
  0,
  1,
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, _oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, name_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, platform_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, version_policy_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, max_batch_size_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, input_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, output_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, optimization_),
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, instance_group_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, default_model_filename_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, cc_model_filenames_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, tags_),
  PROTOBUF_FIELD_OFFSET(::nvidia::inferenceserver::ModelConfig, scheduling_choice_),
};
static const ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::nvidia::inferenceserver::ModelInstanceGroup)},
  { 10, -1, -1, sizeof(::nvidia::inferenceserver::ModelInput)},
  { 20, -1, -1, sizeof(::nvidia::inferenceserver::ModelOutput)},
  { 30, -1, -1, sizeof(::nvidia::inferenceserver::ModelVersionPolicy_Latest)},
  { 37, -1, -1, sizeof(::nvidia::inferenceserver::ModelVersionPolicy_All)},
  { 43, -1, -1, sizeof(::nvidia::inferenceserver::ModelVersionPolicy_Specific)},
  { 50, -1, -1, sizeof(::nvidia::inferenceserver::ModelVersionPolicy)},
  { 60, -1, -1, sizeof(::nvidia::inferenceserver::ModelOptimizationPolicy_Graph)},
  { 67, -1, -1, sizeof(::nvidia::inferenceserver::ModelOptimizationPolicy)},
  { 75, -1, -1, sizeof(::nvidia::inferenceserver::ModelDynamicBatching)},
  { 83, -1, -1, sizeof(::nvidia::inferenceserver::ModelSequenceBatching)},
  { 90, 98, -1, sizeof(::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse)},
  { 100, 108, -1, sizeof(::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse)},
  { 110, -1, -1, sizeof(::nvidia::inferenceserver::ModelConfig)},
};

static ::PROTOBUF_NAMESPACE_ID::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelInstanceGroup_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelInput_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelOutput_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelVersionPolicy_Latest_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelVersionPolicy_All_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelVersionPolicy_Specific_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelVersionPolicy_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelOptimizationPolicy_Graph_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelOptimizationPolicy_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelDynamicBatching_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelSequenceBatching_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelConfig_CcModelFilenamesEntry_DoNotUse_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelConfig_TagsEntry_DoNotUse_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::nvidia::inferenceserver::_ModelConfig_default_instance_),
};

const char descriptor_table_protodef_model_5fconfig_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n\022model_config.proto\022\026nvidia.inferencese"
  "rver\"\261\001\n\022ModelInstanceGroup\022\014\n\004name\030\001 \001("
  "\t\022=\n\004kind\030\004 \001(\0162/.nvidia.inferenceserver"
  ".ModelInstanceGroup.Kind\022\r\n\005count\030\002 \001(\005\022"
  "\014\n\004gpus\030\003 \003(\005\"1\n\004Kind\022\r\n\tKIND_AUTO\020\000\022\014\n\010"
  "KIND_GPU\020\001\022\014\n\010KIND_CPU\020\002\"\325\001\n\nModelInput\022"
  "\014\n\004name\030\001 \001(\t\0223\n\tdata_type\030\002 \001(\0162 .nvidi"
  "a.inferenceserver.DataType\0229\n\006format\030\003 \001"
  "(\0162).nvidia.inferenceserver.ModelInput.F"
  "ormat\022\014\n\004dims\030\004 \003(\003\";\n\006Format\022\017\n\013FORMAT_"
  "NONE\020\000\022\017\n\013FORMAT_NHWC\020\001\022\017\n\013FORMAT_NCHW\020\002"
  "\"v\n\013ModelOutput\022\014\n\004name\030\001 \001(\t\0223\n\tdata_ty"
  "pe\030\002 \001(\0162 .nvidia.inferenceserver.DataTy"
  "pe\022\014\n\004dims\030\003 \003(\003\022\026\n\016label_filename\030\004 \001(\t"
  "\"\267\002\n\022ModelVersionPolicy\022C\n\006latest\030\001 \001(\0132"
  "1.nvidia.inferenceserver.ModelVersionPol"
  "icy.LatestH\000\022=\n\003all\030\002 \001(\0132..nvidia.infer"
  "enceserver.ModelVersionPolicy.AllH\000\022G\n\010s"
  "pecific\030\003 \001(\01323.nvidia.inferenceserver.M"
  "odelVersionPolicy.SpecificH\000\032\036\n\006Latest\022\024"
  "\n\014num_versions\030\001 \001(\r\032\005\n\003All\032\034\n\010Specific\022"
  "\020\n\010versions\030\001 \003(\003B\017\n\rpolicy_choice\"\223\002\n\027M"
  "odelOptimizationPolicy\022D\n\005graph\030\001 \001(\01325."
  "nvidia.inferenceserver.ModelOptimization"
  "Policy.Graph\022O\n\010priority\030\002 \001(\0162=.nvidia."
  "inferenceserver.ModelOptimizationPolicy."
  "ModelPriority\032\026\n\005Graph\022\r\n\005level\030\001 \001(\005\"I\n"
  "\rModelPriority\022\024\n\020PRIORITY_DEFAULT\020\000\022\020\n\014"
  "PRIORITY_MAX\020\001\022\020\n\014PRIORITY_MIN\020\002\"Z\n\024Mode"
  "lDynamicBatching\022\034\n\024preferred_batch_size"
  "\030\001 \003(\005\022$\n\034max_queue_delay_microseconds\030\002"
  " \001(\005\"=\n\025ModelSequenceBatching\022$\n\034max_que"
  "ue_delay_microseconds\030\001 \001(\005\"\301\006\n\013ModelCon"
  "fig\022\014\n\004name\030\001 \001(\t\022\020\n\010platform\030\002 \001(\t\022B\n\016v"
  "ersion_policy\030\003 \001(\0132*.nvidia.inferencese"
  "rver.ModelVersionPolicy\022\026\n\016max_batch_siz"
  "e\030\004 \001(\005\0221\n\005input\030\005 \003(\0132\".nvidia.inferenc"
  "eserver.ModelInput\0223\n\006output\030\006 \003(\0132#.nvi"
  "dia.inferenceserver.ModelOutput\022E\n\014optim"
  "ization\030\014 \001(\0132/.nvidia.inferenceserver.M"
  "odelOptimizationPolicy\022H\n\020dynamic_batchi"
  "ng\030\013 \001(\0132,.nvidia.inferenceserver.ModelD"
  "ynamicBatchingH\000\022J\n\021sequence_batching\030\r "
  "\001(\0132-.nvidia.inferenceserver.ModelSequen"
  "ceBatchingH\000\022B\n\016instance_group\030\007 \003(\0132*.n"
  "vidia.inferenceserver.ModelInstanceGroup"
  "\022\036\n\026default_model_filename\030\010 \001(\t\022U\n\022cc_m"
  "odel_filenames\030\t \003(\01329.nvidia.inferences"
  "erver.ModelConfig.CcModelFilenamesEntry\022"
  ";\n\004tags\030\n \003(\0132-.nvidia.inferenceserver.M"
  "odelConfig.TagsEntry\0327\n\025CcModelFilenames"
  "Entry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\032+\n"
  "\tTagsEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\002"
  "8\001B\023\n\021scheduling_choice*\353\001\n\010DataType\022\020\n\014"
  "TYPE_INVALID\020\000\022\r\n\tTYPE_BOOL\020\001\022\016\n\nTYPE_UI"
  "NT8\020\002\022\017\n\013TYPE_UINT16\020\003\022\017\n\013TYPE_UINT32\020\004\022"
  "\017\n\013TYPE_UINT64\020\005\022\r\n\tTYPE_INT8\020\006\022\016\n\nTYPE_"
  "INT16\020\007\022\016\n\nTYPE_INT32\020\010\022\016\n\nTYPE_INT64\020\t\022"
  "\r\n\tTYPE_FP16\020\n\022\r\n\tTYPE_FP32\020\013\022\r\n\tTYPE_FP"
  "64\020\014\022\017\n\013TYPE_STRING\020\rb\006proto3"
  ;
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_model_5fconfig_2eproto_once;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_model_5fconfig_2eproto = {
  false, false, 2389, descriptor_table_protodef_model_5fconfig_2eproto, "model_config.proto", 
  &descriptor_table_model_5fconfig_2eproto_once, nullptr, 0, 14,
  schemas, file_default_instances, TableStruct_model_5fconfig_2eproto::offsets,
  file_level_metadata_model_5fconfig_2eproto, file_level_enum_descriptors_model_5fconfig_2eproto, file_level_service_descriptors_model_5fconfig_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable* descriptor_table_model_5fconfig_2eproto_getter() {
  return &descriptor_table_model_5fconfig_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY static ::PROTOBUF_NAMESPACE_ID::internal::AddDescriptorsRunner dynamic_init_dummy_model_5fconfig_2eproto(&descriptor_table_model_5fconfig_2eproto);
namespace nvidia {
namespace inferenceserver {
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* ModelInstanceGroup_Kind_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_model_5fconfig_2eproto);
  return file_level_enum_descriptors_model_5fconfig_2eproto[0];
}
bool ModelInstanceGroup_Kind_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr ModelInstanceGroup_Kind ModelInstanceGroup::KIND_AUTO;
constexpr ModelInstanceGroup_Kind ModelInstanceGroup::KIND_GPU;
constexpr ModelInstanceGroup_Kind ModelInstanceGroup::KIND_CPU;
constexpr ModelInstanceGroup_Kind ModelInstanceGroup::Kind_MIN;
constexpr ModelInstanceGroup_Kind ModelInstanceGroup::Kind_MAX;
constexpr int ModelInstanceGroup::Kind_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* ModelInput_Format_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_model_5fconfig_2eproto);
  return file_level_enum_descriptors_model_5fconfig_2eproto[1];
}
bool ModelInput_Format_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr ModelInput_Format ModelInput::FORMAT_NONE;
constexpr ModelInput_Format ModelInput::FORMAT_NHWC;
constexpr ModelInput_Format ModelInput::FORMAT_NCHW;
constexpr ModelInput_Format ModelInput::Format_MIN;
constexpr ModelInput_Format ModelInput::Format_MAX;
constexpr int ModelInput::Format_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* ModelOptimizationPolicy_ModelPriority_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_model_5fconfig_2eproto);
  return file_level_enum_descriptors_model_5fconfig_2eproto[2];
}
bool ModelOptimizationPolicy_ModelPriority_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr ModelOptimizationPolicy_ModelPriority ModelOptimizationPolicy::PRIORITY_DEFAULT;
constexpr ModelOptimizationPolicy_ModelPriority ModelOptimizationPolicy::PRIORITY_MAX;
constexpr ModelOptimizationPolicy_ModelPriority ModelOptimizationPolicy::PRIORITY_MIN;
constexpr ModelOptimizationPolicy_ModelPriority ModelOptimizationPolicy::ModelPriority_MIN;
constexpr ModelOptimizationPolicy_ModelPriority ModelOptimizationPolicy::ModelPriority_MAX;
constexpr int ModelOptimizationPolicy::ModelPriority_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* DataType_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_model_5fconfig_2eproto);
  return file_level_enum_descriptors_model_5fconfig_2eproto[3];
}
bool DataType_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
    case 4:
    case 5:
    case 6:
    case 7:
    case 8:
    case 9:
    case 10:
    case 11:
    case 12:
    case 13:
      return true;
    default:
      return false;
  }
}


// ===================================================================

class ModelInstanceGroup::_Internal {
 public:
};

ModelInstanceGroup::ModelInstanceGroup(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  gpus_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelInstanceGroup)
}
ModelInstanceGroup::ModelInstanceGroup(const ModelInstanceGroup& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      gpus_(from.gpus_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_name(), 
      GetArenaForAllocation());
  }
  ::memcpy(&count_, &from.count_,
    static_cast<size_t>(reinterpret_cast<char*>(&kind_) -
    reinterpret_cast<char*>(&count_)) + sizeof(kind_));
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelInstanceGroup)
}

inline void ModelInstanceGroup::SharedCtor() {
name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&count_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&kind_) -
    reinterpret_cast<char*>(&count_)) + sizeof(kind_));
}

ModelInstanceGroup::~ModelInstanceGroup() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelInstanceGroup)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelInstanceGroup::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void ModelInstanceGroup::ArenaDtor(void* object) {
  ModelInstanceGroup* _this = reinterpret_cast< ModelInstanceGroup* >(object);
  (void)_this;
}
void ModelInstanceGroup::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelInstanceGroup::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelInstanceGroup::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelInstanceGroup)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  gpus_.Clear();
  name_.ClearToEmpty();
  ::memset(&count_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&kind_) -
      reinterpret_cast<char*>(&count_)) + sizeof(kind_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelInstanceGroup::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.ModelInstanceGroup.name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 count = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          count_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated int32 gpus = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_gpus(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 24) {
          _internal_add_gpus(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelInstanceGroup.Kind kind = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_kind(static_cast<::nvidia::inferenceserver::ModelInstanceGroup_Kind>(val));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelInstanceGroup::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelInstanceGroup)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.ModelInstanceGroup.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // int32 count = 2;
  if (this->_internal_count() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(2, this->_internal_count(), target);
  }

  // repeated int32 gpus = 3;
  {
    int byte_size = _gpus_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          3, _internal_gpus(), byte_size, target);
    }
  }

  // .nvidia.inferenceserver.ModelInstanceGroup.Kind kind = 4;
  if (this->_internal_kind() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteEnumToArray(
      4, this->_internal_kind(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelInstanceGroup)
  return target;
}

size_t ModelInstanceGroup::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelInstanceGroup)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int32 gpus = 3;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int32Size(this->gpus_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<int32_t>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _gpus_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  // int32 count = 2;
  if (this->_internal_count() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_count());
  }

  // .nvidia.inferenceserver.ModelInstanceGroup.Kind kind = 4;
  if (this->_internal_kind() != 0) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::EnumSize(this->_internal_kind());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelInstanceGroup::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelInstanceGroup::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelInstanceGroup::GetClassData() const { return &_class_data_; }

void ModelInstanceGroup::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelInstanceGroup *>(to)->MergeFrom(
      static_cast<const ModelInstanceGroup &>(from));
}


void ModelInstanceGroup::MergeFrom(const ModelInstanceGroup& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelInstanceGroup)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  gpus_.MergeFrom(from.gpus_);
  if (!from._internal_name().empty()) {
    _internal_set_name(from._internal_name());
  }
  if (from._internal_count() != 0) {
    _internal_set_count(from._internal_count());
  }
  if (from._internal_kind() != 0) {
    _internal_set_kind(from._internal_kind());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelInstanceGroup::CopyFrom(const ModelInstanceGroup& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelInstanceGroup)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelInstanceGroup::IsInitialized() const {
  return true;
}

void ModelInstanceGroup::InternalSwap(ModelInstanceGroup* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  gpus_.InternalSwap(&other->gpus_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &name_, lhs_arena,
      &other->name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ModelInstanceGroup, kind_)
      + sizeof(ModelInstanceGroup::kind_)
      - PROTOBUF_FIELD_OFFSET(ModelInstanceGroup, count_)>(
          reinterpret_cast<char*>(&count_),
          reinterpret_cast<char*>(&other->count_));
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelInstanceGroup::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[0]);
}

// ===================================================================

class ModelInput::_Internal {
 public:
};

ModelInput::ModelInput(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  dims_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelInput)
}
ModelInput::ModelInput(const ModelInput& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      dims_(from.dims_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_name(), 
      GetArenaForAllocation());
  }
  ::memcpy(&data_type_, &from.data_type_,
    static_cast<size_t>(reinterpret_cast<char*>(&format_) -
    reinterpret_cast<char*>(&data_type_)) + sizeof(format_));
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelInput)
}

inline void ModelInput::SharedCtor() {
name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&data_type_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&format_) -
    reinterpret_cast<char*>(&data_type_)) + sizeof(format_));
}

ModelInput::~ModelInput() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelInput)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelInput::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void ModelInput::ArenaDtor(void* object) {
  ModelInput* _this = reinterpret_cast< ModelInput* >(object);
  (void)_this;
}
void ModelInput::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelInput::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelInput::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelInput)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  dims_.Clear();
  name_.ClearToEmpty();
  ::memset(&data_type_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&format_) -
      reinterpret_cast<char*>(&data_type_)) + sizeof(format_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelInput::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.ModelInput.name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.DataType data_type = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_data_type(static_cast<::nvidia::inferenceserver::DataType>(val));
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelInput.Format format = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_format(static_cast<::nvidia::inferenceserver::ModelInput_Format>(val));
        } else
          goto handle_unusual;
        continue;
      // repeated int64 dims = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt64Parser(_internal_mutable_dims(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 32) {
          _internal_add_dims(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelInput::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelInput)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.ModelInput.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // .nvidia.inferenceserver.DataType data_type = 2;
  if (this->_internal_data_type() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteEnumToArray(
      2, this->_internal_data_type(), target);
  }

  // .nvidia.inferenceserver.ModelInput.Format format = 3;
  if (this->_internal_format() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteEnumToArray(
      3, this->_internal_format(), target);
  }

  // repeated int64 dims = 4;
  {
    int byte_size = _dims_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt64Packed(
          4, _internal_dims(), byte_size, target);
    }
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelInput)
  return target;
}

size_t ModelInput::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelInput)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int64 dims = 4;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int64Size(this->dims_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<int32_t>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _dims_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  // .nvidia.inferenceserver.DataType data_type = 2;
  if (this->_internal_data_type() != 0) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::EnumSize(this->_internal_data_type());
  }

  // .nvidia.inferenceserver.ModelInput.Format format = 3;
  if (this->_internal_format() != 0) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::EnumSize(this->_internal_format());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelInput::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelInput::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelInput::GetClassData() const { return &_class_data_; }

void ModelInput::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelInput *>(to)->MergeFrom(
      static_cast<const ModelInput &>(from));
}


void ModelInput::MergeFrom(const ModelInput& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelInput)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  dims_.MergeFrom(from.dims_);
  if (!from._internal_name().empty()) {
    _internal_set_name(from._internal_name());
  }
  if (from._internal_data_type() != 0) {
    _internal_set_data_type(from._internal_data_type());
  }
  if (from._internal_format() != 0) {
    _internal_set_format(from._internal_format());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelInput::CopyFrom(const ModelInput& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelInput)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelInput::IsInitialized() const {
  return true;
}

void ModelInput::InternalSwap(ModelInput* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  dims_.InternalSwap(&other->dims_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &name_, lhs_arena,
      &other->name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ModelInput, format_)
      + sizeof(ModelInput::format_)
      - PROTOBUF_FIELD_OFFSET(ModelInput, data_type_)>(
          reinterpret_cast<char*>(&data_type_),
          reinterpret_cast<char*>(&other->data_type_));
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelInput::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[1]);
}

// ===================================================================

class ModelOutput::_Internal {
 public:
};

ModelOutput::ModelOutput(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  dims_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelOutput)
}
ModelOutput::ModelOutput(const ModelOutput& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      dims_(from.dims_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_name(), 
      GetArenaForAllocation());
  }
  label_filename_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    label_filename_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_label_filename().empty()) {
    label_filename_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_label_filename(), 
      GetArenaForAllocation());
  }
  data_type_ = from.data_type_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelOutput)
}

inline void ModelOutput::SharedCtor() {
name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
label_filename_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  label_filename_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
data_type_ = 0;
}

ModelOutput::~ModelOutput() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelOutput)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelOutput::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  label_filename_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void ModelOutput::ArenaDtor(void* object) {
  ModelOutput* _this = reinterpret_cast< ModelOutput* >(object);
  (void)_this;
}
void ModelOutput::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelOutput::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelOutput::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelOutput)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  dims_.Clear();
  name_.ClearToEmpty();
  label_filename_.ClearToEmpty();
  data_type_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelOutput::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.ModelOutput.name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.DataType data_type = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_data_type(static_cast<::nvidia::inferenceserver::DataType>(val));
        } else
          goto handle_unusual;
        continue;
      // repeated int64 dims = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt64Parser(_internal_mutable_dims(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 24) {
          _internal_add_dims(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string label_filename = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          auto str = _internal_mutable_label_filename();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.ModelOutput.label_filename"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelOutput::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelOutput)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.ModelOutput.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // .nvidia.inferenceserver.DataType data_type = 2;
  if (this->_internal_data_type() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteEnumToArray(
      2, this->_internal_data_type(), target);
  }

  // repeated int64 dims = 3;
  {
    int byte_size = _dims_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt64Packed(
          3, _internal_dims(), byte_size, target);
    }
  }

  // string label_filename = 4;
  if (!this->_internal_label_filename().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_label_filename().data(), static_cast<int>(this->_internal_label_filename().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.ModelOutput.label_filename");
    target = stream->WriteStringMaybeAliased(
        4, this->_internal_label_filename(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelOutput)
  return target;
}

size_t ModelOutput::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelOutput)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int64 dims = 3;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int64Size(this->dims_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<int32_t>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _dims_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  // string label_filename = 4;
  if (!this->_internal_label_filename().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_label_filename());
  }

  // .nvidia.inferenceserver.DataType data_type = 2;
  if (this->_internal_data_type() != 0) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::EnumSize(this->_internal_data_type());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelOutput::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelOutput::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelOutput::GetClassData() const { return &_class_data_; }

void ModelOutput::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelOutput *>(to)->MergeFrom(
      static_cast<const ModelOutput &>(from));
}


void ModelOutput::MergeFrom(const ModelOutput& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelOutput)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  dims_.MergeFrom(from.dims_);
  if (!from._internal_name().empty()) {
    _internal_set_name(from._internal_name());
  }
  if (!from._internal_label_filename().empty()) {
    _internal_set_label_filename(from._internal_label_filename());
  }
  if (from._internal_data_type() != 0) {
    _internal_set_data_type(from._internal_data_type());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelOutput::CopyFrom(const ModelOutput& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelOutput)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelOutput::IsInitialized() const {
  return true;
}

void ModelOutput::InternalSwap(ModelOutput* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  dims_.InternalSwap(&other->dims_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &name_, lhs_arena,
      &other->name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &label_filename_, lhs_arena,
      &other->label_filename_, rhs_arena
  );
  swap(data_type_, other->data_type_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelOutput::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[2]);
}

// ===================================================================

class ModelVersionPolicy_Latest::_Internal {
 public:
};

ModelVersionPolicy_Latest::ModelVersionPolicy_Latest(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelVersionPolicy.Latest)
}
ModelVersionPolicy_Latest::ModelVersionPolicy_Latest(const ModelVersionPolicy_Latest& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  num_versions_ = from.num_versions_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelVersionPolicy.Latest)
}

inline void ModelVersionPolicy_Latest::SharedCtor() {
num_versions_ = 0u;
}

ModelVersionPolicy_Latest::~ModelVersionPolicy_Latest() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelVersionPolicy.Latest)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelVersionPolicy_Latest::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void ModelVersionPolicy_Latest::ArenaDtor(void* object) {
  ModelVersionPolicy_Latest* _this = reinterpret_cast< ModelVersionPolicy_Latest* >(object);
  (void)_this;
}
void ModelVersionPolicy_Latest::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelVersionPolicy_Latest::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelVersionPolicy_Latest::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelVersionPolicy.Latest)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  num_versions_ = 0u;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelVersionPolicy_Latest::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint32 num_versions = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          num_versions_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelVersionPolicy_Latest::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelVersionPolicy.Latest)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint32 num_versions = 1;
  if (this->_internal_num_versions() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteUInt32ToArray(1, this->_internal_num_versions(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelVersionPolicy.Latest)
  return target;
}

size_t ModelVersionPolicy_Latest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelVersionPolicy.Latest)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint32 num_versions = 1;
  if (this->_internal_num_versions() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::UInt32SizePlusOne(this->_internal_num_versions());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelVersionPolicy_Latest::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelVersionPolicy_Latest::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelVersionPolicy_Latest::GetClassData() const { return &_class_data_; }

void ModelVersionPolicy_Latest::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelVersionPolicy_Latest *>(to)->MergeFrom(
      static_cast<const ModelVersionPolicy_Latest &>(from));
}


void ModelVersionPolicy_Latest::MergeFrom(const ModelVersionPolicy_Latest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelVersionPolicy.Latest)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_num_versions() != 0) {
    _internal_set_num_versions(from._internal_num_versions());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelVersionPolicy_Latest::CopyFrom(const ModelVersionPolicy_Latest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelVersionPolicy.Latest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelVersionPolicy_Latest::IsInitialized() const {
  return true;
}

void ModelVersionPolicy_Latest::InternalSwap(ModelVersionPolicy_Latest* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(num_versions_, other->num_versions_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelVersionPolicy_Latest::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[3]);
}

// ===================================================================

class ModelVersionPolicy_All::_Internal {
 public:
};

ModelVersionPolicy_All::ModelVersionPolicy_All(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelVersionPolicy.All)
}
ModelVersionPolicy_All::ModelVersionPolicy_All(const ModelVersionPolicy_All& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelVersionPolicy.All)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelVersionPolicy_All::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelVersionPolicy_All::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata ModelVersionPolicy_All::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[4]);
}

// ===================================================================

class ModelVersionPolicy_Specific::_Internal {
 public:
};

ModelVersionPolicy_Specific::ModelVersionPolicy_Specific(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  versions_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelVersionPolicy.Specific)
}
ModelVersionPolicy_Specific::ModelVersionPolicy_Specific(const ModelVersionPolicy_Specific& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      versions_(from.versions_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelVersionPolicy.Specific)
}

inline void ModelVersionPolicy_Specific::SharedCtor() {
}

ModelVersionPolicy_Specific::~ModelVersionPolicy_Specific() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelVersionPolicy.Specific)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelVersionPolicy_Specific::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void ModelVersionPolicy_Specific::ArenaDtor(void* object) {
  ModelVersionPolicy_Specific* _this = reinterpret_cast< ModelVersionPolicy_Specific* >(object);
  (void)_this;
}
void ModelVersionPolicy_Specific::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelVersionPolicy_Specific::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelVersionPolicy_Specific::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelVersionPolicy.Specific)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  versions_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelVersionPolicy_Specific::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated int64 versions = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt64Parser(_internal_mutable_versions(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 8) {
          _internal_add_versions(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelVersionPolicy_Specific::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelVersionPolicy.Specific)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated int64 versions = 1;
  {
    int byte_size = _versions_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt64Packed(
          1, _internal_versions(), byte_size, target);
    }
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelVersionPolicy.Specific)
  return target;
}

size_t ModelVersionPolicy_Specific::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelVersionPolicy.Specific)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int64 versions = 1;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int64Size(this->versions_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<int32_t>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _versions_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelVersionPolicy_Specific::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelVersionPolicy_Specific::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelVersionPolicy_Specific::GetClassData() const { return &_class_data_; }

void ModelVersionPolicy_Specific::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelVersionPolicy_Specific *>(to)->MergeFrom(
      static_cast<const ModelVersionPolicy_Specific &>(from));
}


void ModelVersionPolicy_Specific::MergeFrom(const ModelVersionPolicy_Specific& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelVersionPolicy.Specific)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  versions_.MergeFrom(from.versions_);
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelVersionPolicy_Specific::CopyFrom(const ModelVersionPolicy_Specific& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelVersionPolicy.Specific)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelVersionPolicy_Specific::IsInitialized() const {
  return true;
}

void ModelVersionPolicy_Specific::InternalSwap(ModelVersionPolicy_Specific* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  versions_.InternalSwap(&other->versions_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelVersionPolicy_Specific::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[5]);
}

// ===================================================================

class ModelVersionPolicy::_Internal {
 public:
  static const ::nvidia::inferenceserver::ModelVersionPolicy_Latest& latest(const ModelVersionPolicy* msg);
  static const ::nvidia::inferenceserver::ModelVersionPolicy_All& all(const ModelVersionPolicy* msg);
  static const ::nvidia::inferenceserver::ModelVersionPolicy_Specific& specific(const ModelVersionPolicy* msg);
};

const ::nvidia::inferenceserver::ModelVersionPolicy_Latest&
ModelVersionPolicy::_Internal::latest(const ModelVersionPolicy* msg) {
  return *msg->policy_choice_.latest_;
}
const ::nvidia::inferenceserver::ModelVersionPolicy_All&
ModelVersionPolicy::_Internal::all(const ModelVersionPolicy* msg) {
  return *msg->policy_choice_.all_;
}
const ::nvidia::inferenceserver::ModelVersionPolicy_Specific&
ModelVersionPolicy::_Internal::specific(const ModelVersionPolicy* msg) {
  return *msg->policy_choice_.specific_;
}
void ModelVersionPolicy::set_allocated_latest(::nvidia::inferenceserver::ModelVersionPolicy_Latest* latest) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_policy_choice();
  if (latest) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::ModelVersionPolicy_Latest>::GetOwningArena(latest);
    if (message_arena != submessage_arena) {
      latest = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, latest, submessage_arena);
    }
    set_has_latest();
    policy_choice_.latest_ = latest;
  }
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ModelVersionPolicy.latest)
}
void ModelVersionPolicy::set_allocated_all(::nvidia::inferenceserver::ModelVersionPolicy_All* all) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_policy_choice();
  if (all) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::ModelVersionPolicy_All>::GetOwningArena(all);
    if (message_arena != submessage_arena) {
      all = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, all, submessage_arena);
    }
    set_has_all();
    policy_choice_.all_ = all;
  }
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ModelVersionPolicy.all)
}
void ModelVersionPolicy::set_allocated_specific(::nvidia::inferenceserver::ModelVersionPolicy_Specific* specific) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_policy_choice();
  if (specific) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::ModelVersionPolicy_Specific>::GetOwningArena(specific);
    if (message_arena != submessage_arena) {
      specific = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, specific, submessage_arena);
    }
    set_has_specific();
    policy_choice_.specific_ = specific;
  }
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ModelVersionPolicy.specific)
}
ModelVersionPolicy::ModelVersionPolicy(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelVersionPolicy)
}
ModelVersionPolicy::ModelVersionPolicy(const ModelVersionPolicy& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  clear_has_policy_choice();
  switch (from.policy_choice_case()) {
    case kLatest: {
      _internal_mutable_latest()->::nvidia::inferenceserver::ModelVersionPolicy_Latest::MergeFrom(from._internal_latest());
      break;
    }
    case kAll: {
      _internal_mutable_all()->::nvidia::inferenceserver::ModelVersionPolicy_All::MergeFrom(from._internal_all());
      break;
    }
    case kSpecific: {
      _internal_mutable_specific()->::nvidia::inferenceserver::ModelVersionPolicy_Specific::MergeFrom(from._internal_specific());
      break;
    }
    case POLICY_CHOICE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelVersionPolicy)
}

inline void ModelVersionPolicy::SharedCtor() {
clear_has_policy_choice();
}

ModelVersionPolicy::~ModelVersionPolicy() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelVersionPolicy)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelVersionPolicy::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (has_policy_choice()) {
    clear_policy_choice();
  }
}

void ModelVersionPolicy::ArenaDtor(void* object) {
  ModelVersionPolicy* _this = reinterpret_cast< ModelVersionPolicy* >(object);
  (void)_this;
}
void ModelVersionPolicy::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelVersionPolicy::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelVersionPolicy::clear_policy_choice() {
// @@protoc_insertion_point(one_of_clear_start:nvidia.inferenceserver.ModelVersionPolicy)
  switch (policy_choice_case()) {
    case kLatest: {
      if (GetArenaForAllocation() == nullptr) {
        delete policy_choice_.latest_;
      }
      break;
    }
    case kAll: {
      if (GetArenaForAllocation() == nullptr) {
        delete policy_choice_.all_;
      }
      break;
    }
    case kSpecific: {
      if (GetArenaForAllocation() == nullptr) {
        delete policy_choice_.specific_;
      }
      break;
    }
    case POLICY_CHOICE_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = POLICY_CHOICE_NOT_SET;
}


void ModelVersionPolicy::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelVersionPolicy)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_policy_choice();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelVersionPolicy::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .nvidia.inferenceserver.ModelVersionPolicy.Latest latest = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_latest(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelVersionPolicy.All all = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_all(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelVersionPolicy.Specific specific = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_specific(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelVersionPolicy::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelVersionPolicy)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .nvidia.inferenceserver.ModelVersionPolicy.Latest latest = 1;
  if (_internal_has_latest()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        1, _Internal::latest(this), target, stream);
  }

  // .nvidia.inferenceserver.ModelVersionPolicy.All all = 2;
  if (_internal_has_all()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        2, _Internal::all(this), target, stream);
  }

  // .nvidia.inferenceserver.ModelVersionPolicy.Specific specific = 3;
  if (_internal_has_specific()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        3, _Internal::specific(this), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelVersionPolicy)
  return target;
}

size_t ModelVersionPolicy::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelVersionPolicy)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  switch (policy_choice_case()) {
    // .nvidia.inferenceserver.ModelVersionPolicy.Latest latest = 1;
    case kLatest: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *policy_choice_.latest_);
      break;
    }
    // .nvidia.inferenceserver.ModelVersionPolicy.All all = 2;
    case kAll: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *policy_choice_.all_);
      break;
    }
    // .nvidia.inferenceserver.ModelVersionPolicy.Specific specific = 3;
    case kSpecific: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *policy_choice_.specific_);
      break;
    }
    case POLICY_CHOICE_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelVersionPolicy::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelVersionPolicy::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelVersionPolicy::GetClassData() const { return &_class_data_; }

void ModelVersionPolicy::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelVersionPolicy *>(to)->MergeFrom(
      static_cast<const ModelVersionPolicy &>(from));
}


void ModelVersionPolicy::MergeFrom(const ModelVersionPolicy& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelVersionPolicy)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  switch (from.policy_choice_case()) {
    case kLatest: {
      _internal_mutable_latest()->::nvidia::inferenceserver::ModelVersionPolicy_Latest::MergeFrom(from._internal_latest());
      break;
    }
    case kAll: {
      _internal_mutable_all()->::nvidia::inferenceserver::ModelVersionPolicy_All::MergeFrom(from._internal_all());
      break;
    }
    case kSpecific: {
      _internal_mutable_specific()->::nvidia::inferenceserver::ModelVersionPolicy_Specific::MergeFrom(from._internal_specific());
      break;
    }
    case POLICY_CHOICE_NOT_SET: {
      break;
    }
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelVersionPolicy::CopyFrom(const ModelVersionPolicy& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelVersionPolicy)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelVersionPolicy::IsInitialized() const {
  return true;
}

void ModelVersionPolicy::InternalSwap(ModelVersionPolicy* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(policy_choice_, other->policy_choice_);
  swap(_oneof_case_[0], other->_oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelVersionPolicy::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[6]);
}

// ===================================================================

class ModelOptimizationPolicy_Graph::_Internal {
 public:
};

ModelOptimizationPolicy_Graph::ModelOptimizationPolicy_Graph(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
}
ModelOptimizationPolicy_Graph::ModelOptimizationPolicy_Graph(const ModelOptimizationPolicy_Graph& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  level_ = from.level_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
}

inline void ModelOptimizationPolicy_Graph::SharedCtor() {
level_ = 0;
}

ModelOptimizationPolicy_Graph::~ModelOptimizationPolicy_Graph() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelOptimizationPolicy_Graph::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void ModelOptimizationPolicy_Graph::ArenaDtor(void* object) {
  ModelOptimizationPolicy_Graph* _this = reinterpret_cast< ModelOptimizationPolicy_Graph* >(object);
  (void)_this;
}
void ModelOptimizationPolicy_Graph::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelOptimizationPolicy_Graph::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelOptimizationPolicy_Graph::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  level_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelOptimizationPolicy_Graph::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 level = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          level_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelOptimizationPolicy_Graph::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 level = 1;
  if (this->_internal_level() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(1, this->_internal_level(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
  return target;
}

size_t ModelOptimizationPolicy_Graph::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // int32 level = 1;
  if (this->_internal_level() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_level());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelOptimizationPolicy_Graph::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelOptimizationPolicy_Graph::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelOptimizationPolicy_Graph::GetClassData() const { return &_class_data_; }

void ModelOptimizationPolicy_Graph::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelOptimizationPolicy_Graph *>(to)->MergeFrom(
      static_cast<const ModelOptimizationPolicy_Graph &>(from));
}


void ModelOptimizationPolicy_Graph::MergeFrom(const ModelOptimizationPolicy_Graph& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_level() != 0) {
    _internal_set_level(from._internal_level());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelOptimizationPolicy_Graph::CopyFrom(const ModelOptimizationPolicy_Graph& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelOptimizationPolicy.Graph)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelOptimizationPolicy_Graph::IsInitialized() const {
  return true;
}

void ModelOptimizationPolicy_Graph::InternalSwap(ModelOptimizationPolicy_Graph* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(level_, other->level_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelOptimizationPolicy_Graph::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[7]);
}

// ===================================================================

class ModelOptimizationPolicy::_Internal {
 public:
  static const ::nvidia::inferenceserver::ModelOptimizationPolicy_Graph& graph(const ModelOptimizationPolicy* msg);
};

const ::nvidia::inferenceserver::ModelOptimizationPolicy_Graph&
ModelOptimizationPolicy::_Internal::graph(const ModelOptimizationPolicy* msg) {
  return *msg->graph_;
}
ModelOptimizationPolicy::ModelOptimizationPolicy(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelOptimizationPolicy)
}
ModelOptimizationPolicy::ModelOptimizationPolicy(const ModelOptimizationPolicy& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  if (from._internal_has_graph()) {
    graph_ = new ::nvidia::inferenceserver::ModelOptimizationPolicy_Graph(*from.graph_);
  } else {
    graph_ = nullptr;
  }
  priority_ = from.priority_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelOptimizationPolicy)
}

inline void ModelOptimizationPolicy::SharedCtor() {
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&graph_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&priority_) -
    reinterpret_cast<char*>(&graph_)) + sizeof(priority_));
}

ModelOptimizationPolicy::~ModelOptimizationPolicy() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelOptimizationPolicy)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelOptimizationPolicy::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete graph_;
}

void ModelOptimizationPolicy::ArenaDtor(void* object) {
  ModelOptimizationPolicy* _this = reinterpret_cast< ModelOptimizationPolicy* >(object);
  (void)_this;
}
void ModelOptimizationPolicy::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelOptimizationPolicy::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelOptimizationPolicy::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelOptimizationPolicy)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  if (GetArenaForAllocation() == nullptr && graph_ != nullptr) {
    delete graph_;
  }
  graph_ = nullptr;
  priority_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelOptimizationPolicy::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .nvidia.inferenceserver.ModelOptimizationPolicy.Graph graph = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_graph(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelOptimizationPolicy.ModelPriority priority = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          _internal_set_priority(static_cast<::nvidia::inferenceserver::ModelOptimizationPolicy_ModelPriority>(val));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelOptimizationPolicy::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelOptimizationPolicy)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // .nvidia.inferenceserver.ModelOptimizationPolicy.Graph graph = 1;
  if (this->_internal_has_graph()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        1, _Internal::graph(this), target, stream);
  }

  // .nvidia.inferenceserver.ModelOptimizationPolicy.ModelPriority priority = 2;
  if (this->_internal_priority() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteEnumToArray(
      2, this->_internal_priority(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelOptimizationPolicy)
  return target;
}

size_t ModelOptimizationPolicy::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelOptimizationPolicy)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // .nvidia.inferenceserver.ModelOptimizationPolicy.Graph graph = 1;
  if (this->_internal_has_graph()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *graph_);
  }

  // .nvidia.inferenceserver.ModelOptimizationPolicy.ModelPriority priority = 2;
  if (this->_internal_priority() != 0) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::EnumSize(this->_internal_priority());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelOptimizationPolicy::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelOptimizationPolicy::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelOptimizationPolicy::GetClassData() const { return &_class_data_; }

void ModelOptimizationPolicy::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelOptimizationPolicy *>(to)->MergeFrom(
      static_cast<const ModelOptimizationPolicy &>(from));
}


void ModelOptimizationPolicy::MergeFrom(const ModelOptimizationPolicy& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelOptimizationPolicy)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_graph()) {
    _internal_mutable_graph()->::nvidia::inferenceserver::ModelOptimizationPolicy_Graph::MergeFrom(from._internal_graph());
  }
  if (from._internal_priority() != 0) {
    _internal_set_priority(from._internal_priority());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelOptimizationPolicy::CopyFrom(const ModelOptimizationPolicy& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelOptimizationPolicy)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelOptimizationPolicy::IsInitialized() const {
  return true;
}

void ModelOptimizationPolicy::InternalSwap(ModelOptimizationPolicy* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ModelOptimizationPolicy, priority_)
      + sizeof(ModelOptimizationPolicy::priority_)
      - PROTOBUF_FIELD_OFFSET(ModelOptimizationPolicy, graph_)>(
          reinterpret_cast<char*>(&graph_),
          reinterpret_cast<char*>(&other->graph_));
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelOptimizationPolicy::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[8]);
}

// ===================================================================

class ModelDynamicBatching::_Internal {
 public:
};

ModelDynamicBatching::ModelDynamicBatching(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  preferred_batch_size_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelDynamicBatching)
}
ModelDynamicBatching::ModelDynamicBatching(const ModelDynamicBatching& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      preferred_batch_size_(from.preferred_batch_size_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  max_queue_delay_microseconds_ = from.max_queue_delay_microseconds_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelDynamicBatching)
}

inline void ModelDynamicBatching::SharedCtor() {
max_queue_delay_microseconds_ = 0;
}

ModelDynamicBatching::~ModelDynamicBatching() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelDynamicBatching)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelDynamicBatching::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void ModelDynamicBatching::ArenaDtor(void* object) {
  ModelDynamicBatching* _this = reinterpret_cast< ModelDynamicBatching* >(object);
  (void)_this;
}
void ModelDynamicBatching::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelDynamicBatching::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelDynamicBatching::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelDynamicBatching)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  preferred_batch_size_.Clear();
  max_queue_delay_microseconds_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelDynamicBatching::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated int32 preferred_batch_size = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_preferred_batch_size(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 8) {
          _internal_add_preferred_batch_size(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 max_queue_delay_microseconds = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          max_queue_delay_microseconds_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelDynamicBatching::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelDynamicBatching)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated int32 preferred_batch_size = 1;
  {
    int byte_size = _preferred_batch_size_cached_byte_size_.load(std::memory_order_relaxed);
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          1, _internal_preferred_batch_size(), byte_size, target);
    }
  }

  // int32 max_queue_delay_microseconds = 2;
  if (this->_internal_max_queue_delay_microseconds() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(2, this->_internal_max_queue_delay_microseconds(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelDynamicBatching)
  return target;
}

size_t ModelDynamicBatching::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelDynamicBatching)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int32 preferred_batch_size = 1;
  {
    size_t data_size = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      Int32Size(this->preferred_batch_size_);
    if (data_size > 0) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32Size(
            static_cast<int32_t>(data_size));
    }
    int cached_size = ::PROTOBUF_NAMESPACE_ID::internal::ToCachedSize(data_size);
    _preferred_batch_size_cached_byte_size_.store(cached_size,
                                    std::memory_order_relaxed);
    total_size += data_size;
  }

  // int32 max_queue_delay_microseconds = 2;
  if (this->_internal_max_queue_delay_microseconds() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_max_queue_delay_microseconds());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelDynamicBatching::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelDynamicBatching::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelDynamicBatching::GetClassData() const { return &_class_data_; }

void ModelDynamicBatching::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelDynamicBatching *>(to)->MergeFrom(
      static_cast<const ModelDynamicBatching &>(from));
}


void ModelDynamicBatching::MergeFrom(const ModelDynamicBatching& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelDynamicBatching)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  preferred_batch_size_.MergeFrom(from.preferred_batch_size_);
  if (from._internal_max_queue_delay_microseconds() != 0) {
    _internal_set_max_queue_delay_microseconds(from._internal_max_queue_delay_microseconds());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelDynamicBatching::CopyFrom(const ModelDynamicBatching& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelDynamicBatching)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelDynamicBatching::IsInitialized() const {
  return true;
}

void ModelDynamicBatching::InternalSwap(ModelDynamicBatching* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  preferred_batch_size_.InternalSwap(&other->preferred_batch_size_);
  swap(max_queue_delay_microseconds_, other->max_queue_delay_microseconds_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelDynamicBatching::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[9]);
}

// ===================================================================

class ModelSequenceBatching::_Internal {
 public:
};

ModelSequenceBatching::ModelSequenceBatching(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelSequenceBatching)
}
ModelSequenceBatching::ModelSequenceBatching(const ModelSequenceBatching& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  max_queue_delay_microseconds_ = from.max_queue_delay_microseconds_;
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelSequenceBatching)
}

inline void ModelSequenceBatching::SharedCtor() {
max_queue_delay_microseconds_ = 0;
}

ModelSequenceBatching::~ModelSequenceBatching() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelSequenceBatching)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelSequenceBatching::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void ModelSequenceBatching::ArenaDtor(void* object) {
  ModelSequenceBatching* _this = reinterpret_cast< ModelSequenceBatching* >(object);
  (void)_this;
}
void ModelSequenceBatching::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void ModelSequenceBatching::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelSequenceBatching::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelSequenceBatching)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  max_queue_delay_microseconds_ = 0;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelSequenceBatching::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 max_queue_delay_microseconds = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          max_queue_delay_microseconds_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelSequenceBatching::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelSequenceBatching)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 max_queue_delay_microseconds = 1;
  if (this->_internal_max_queue_delay_microseconds() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(1, this->_internal_max_queue_delay_microseconds(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelSequenceBatching)
  return target;
}

size_t ModelSequenceBatching::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelSequenceBatching)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // int32 max_queue_delay_microseconds = 1;
  if (this->_internal_max_queue_delay_microseconds() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_max_queue_delay_microseconds());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelSequenceBatching::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelSequenceBatching::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelSequenceBatching::GetClassData() const { return &_class_data_; }

void ModelSequenceBatching::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelSequenceBatching *>(to)->MergeFrom(
      static_cast<const ModelSequenceBatching &>(from));
}


void ModelSequenceBatching::MergeFrom(const ModelSequenceBatching& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelSequenceBatching)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_max_queue_delay_microseconds() != 0) {
    _internal_set_max_queue_delay_microseconds(from._internal_max_queue_delay_microseconds());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelSequenceBatching::CopyFrom(const ModelSequenceBatching& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelSequenceBatching)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelSequenceBatching::IsInitialized() const {
  return true;
}

void ModelSequenceBatching::InternalSwap(ModelSequenceBatching* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(max_queue_delay_microseconds_, other->max_queue_delay_microseconds_);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelSequenceBatching::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[10]);
}

// ===================================================================

ModelConfig_CcModelFilenamesEntry_DoNotUse::ModelConfig_CcModelFilenamesEntry_DoNotUse() {}
ModelConfig_CcModelFilenamesEntry_DoNotUse::ModelConfig_CcModelFilenamesEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena)
    : SuperType(arena) {}
void ModelConfig_CcModelFilenamesEntry_DoNotUse::MergeFrom(const ModelConfig_CcModelFilenamesEntry_DoNotUse& other) {
  MergeFromInternal(other);
}
::PROTOBUF_NAMESPACE_ID::Metadata ModelConfig_CcModelFilenamesEntry_DoNotUse::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[11]);
}

// ===================================================================

ModelConfig_TagsEntry_DoNotUse::ModelConfig_TagsEntry_DoNotUse() {}
ModelConfig_TagsEntry_DoNotUse::ModelConfig_TagsEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena)
    : SuperType(arena) {}
void ModelConfig_TagsEntry_DoNotUse::MergeFrom(const ModelConfig_TagsEntry_DoNotUse& other) {
  MergeFromInternal(other);
}
::PROTOBUF_NAMESPACE_ID::Metadata ModelConfig_TagsEntry_DoNotUse::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[12]);
}

// ===================================================================

class ModelConfig::_Internal {
 public:
  static const ::nvidia::inferenceserver::ModelVersionPolicy& version_policy(const ModelConfig* msg);
  static const ::nvidia::inferenceserver::ModelOptimizationPolicy& optimization(const ModelConfig* msg);
  static const ::nvidia::inferenceserver::ModelDynamicBatching& dynamic_batching(const ModelConfig* msg);
  static const ::nvidia::inferenceserver::ModelSequenceBatching& sequence_batching(const ModelConfig* msg);
};

const ::nvidia::inferenceserver::ModelVersionPolicy&
ModelConfig::_Internal::version_policy(const ModelConfig* msg) {
  return *msg->version_policy_;
}
const ::nvidia::inferenceserver::ModelOptimizationPolicy&
ModelConfig::_Internal::optimization(const ModelConfig* msg) {
  return *msg->optimization_;
}
const ::nvidia::inferenceserver::ModelDynamicBatching&
ModelConfig::_Internal::dynamic_batching(const ModelConfig* msg) {
  return *msg->scheduling_choice_.dynamic_batching_;
}
const ::nvidia::inferenceserver::ModelSequenceBatching&
ModelConfig::_Internal::sequence_batching(const ModelConfig* msg) {
  return *msg->scheduling_choice_.sequence_batching_;
}
void ModelConfig::set_allocated_dynamic_batching(::nvidia::inferenceserver::ModelDynamicBatching* dynamic_batching) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_scheduling_choice();
  if (dynamic_batching) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::ModelDynamicBatching>::GetOwningArena(dynamic_batching);
    if (message_arena != submessage_arena) {
      dynamic_batching = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, dynamic_batching, submessage_arena);
    }
    set_has_dynamic_batching();
    scheduling_choice_.dynamic_batching_ = dynamic_batching;
  }
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ModelConfig.dynamic_batching)
}
void ModelConfig::set_allocated_sequence_batching(::nvidia::inferenceserver::ModelSequenceBatching* sequence_batching) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_scheduling_choice();
  if (sequence_batching) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::nvidia::inferenceserver::ModelSequenceBatching>::GetOwningArena(sequence_batching);
    if (message_arena != submessage_arena) {
      sequence_batching = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, sequence_batching, submessage_arena);
    }
    set_has_sequence_batching();
    scheduling_choice_.sequence_batching_ = sequence_batching;
  }
  // @@protoc_insertion_point(field_set_allocated:nvidia.inferenceserver.ModelConfig.sequence_batching)
}
ModelConfig::ModelConfig(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned),
  input_(arena),
  output_(arena),
  instance_group_(arena),
  cc_model_filenames_(arena),
  tags_(arena) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:nvidia.inferenceserver.ModelConfig)
}
ModelConfig::ModelConfig(const ModelConfig& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      input_(from.input_),
      output_(from.output_),
      instance_group_(from.instance_group_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  cc_model_filenames_.MergeFrom(from.cc_model_filenames_);
  tags_.MergeFrom(from.tags_);
  name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_name().empty()) {
    name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_name(), 
      GetArenaForAllocation());
  }
  platform_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    platform_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_platform().empty()) {
    platform_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_platform(), 
      GetArenaForAllocation());
  }
  default_model_filename_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    default_model_filename_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_default_model_filename().empty()) {
    default_model_filename_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_default_model_filename(), 
      GetArenaForAllocation());
  }
  if (from._internal_has_version_policy()) {
    version_policy_ = new ::nvidia::inferenceserver::ModelVersionPolicy(*from.version_policy_);
  } else {
    version_policy_ = nullptr;
  }
  if (from._internal_has_optimization()) {
    optimization_ = new ::nvidia::inferenceserver::ModelOptimizationPolicy(*from.optimization_);
  } else {
    optimization_ = nullptr;
  }
  max_batch_size_ = from.max_batch_size_;
  clear_has_scheduling_choice();
  switch (from.scheduling_choice_case()) {
    case kDynamicBatching: {
      _internal_mutable_dynamic_batching()->::nvidia::inferenceserver::ModelDynamicBatching::MergeFrom(from._internal_dynamic_batching());
      break;
    }
    case kSequenceBatching: {
      _internal_mutable_sequence_batching()->::nvidia::inferenceserver::ModelSequenceBatching::MergeFrom(from._internal_sequence_batching());
      break;
    }
    case SCHEDULING_CHOICE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:nvidia.inferenceserver.ModelConfig)
}

inline void ModelConfig::SharedCtor() {
name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
platform_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  platform_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
default_model_filename_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  default_model_filename_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&version_policy_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&max_batch_size_) -
    reinterpret_cast<char*>(&version_policy_)) + sizeof(max_batch_size_));
clear_has_scheduling_choice();
}

ModelConfig::~ModelConfig() {
  // @@protoc_insertion_point(destructor:nvidia.inferenceserver.ModelConfig)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void ModelConfig::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  platform_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  default_model_filename_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete version_policy_;
  if (this != internal_default_instance()) delete optimization_;
  if (has_scheduling_choice()) {
    clear_scheduling_choice();
  }
}

void ModelConfig::ArenaDtor(void* object) {
  ModelConfig* _this = reinterpret_cast< ModelConfig* >(object);
  (void)_this;
  _this->cc_model_filenames_. ~MapField();
  _this->tags_. ~MapField();
}
inline void ModelConfig::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena* arena) {
  if (arena != nullptr) {
    arena->OwnCustomDestructor(this, &ModelConfig::ArenaDtor);
  }
}
void ModelConfig::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void ModelConfig::clear_scheduling_choice() {
// @@protoc_insertion_point(one_of_clear_start:nvidia.inferenceserver.ModelConfig)
  switch (scheduling_choice_case()) {
    case kDynamicBatching: {
      if (GetArenaForAllocation() == nullptr) {
        delete scheduling_choice_.dynamic_batching_;
      }
      break;
    }
    case kSequenceBatching: {
      if (GetArenaForAllocation() == nullptr) {
        delete scheduling_choice_.sequence_batching_;
      }
      break;
    }
    case SCHEDULING_CHOICE_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = SCHEDULING_CHOICE_NOT_SET;
}


void ModelConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:nvidia.inferenceserver.ModelConfig)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  input_.Clear();
  output_.Clear();
  instance_group_.Clear();
  cc_model_filenames_.Clear();
  tags_.Clear();
  name_.ClearToEmpty();
  platform_.ClearToEmpty();
  default_model_filename_.ClearToEmpty();
  if (GetArenaForAllocation() == nullptr && version_policy_ != nullptr) {
    delete version_policy_;
  }
  version_policy_ = nullptr;
  if (GetArenaForAllocation() == nullptr && optimization_ != nullptr) {
    delete optimization_;
  }
  optimization_ = nullptr;
  max_batch_size_ = 0;
  clear_scheduling_choice();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* ModelConfig::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // string name = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.ModelConfig.name"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string platform = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_platform();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.ModelConfig.platform"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelVersionPolicy version_policy = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_version_policy(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 max_batch_size = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          max_batch_size_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .nvidia.inferenceserver.ModelInput input = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_input(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<42>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .nvidia.inferenceserver.ModelOutput output = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_output(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<50>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .nvidia.inferenceserver.ModelInstanceGroup instance_group = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_instance_group(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<58>(ptr));
        } else
          goto handle_unusual;
        continue;
      // string default_model_filename = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
          auto str = _internal_mutable_default_model_filename();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "nvidia.inferenceserver.ModelConfig.default_model_filename"));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // map<string, string> cc_model_filenames = 9;
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 74)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(&cc_model_filenames_, ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<74>(ptr));
        } else
          goto handle_unusual;
        continue;
      // map<string, string> tags = 10;
      case 10:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 82)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(&tags_, ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<82>(ptr));
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelDynamicBatching dynamic_batching = 11;
      case 11:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 90)) {
          ptr = ctx->ParseMessage(_internal_mutable_dynamic_batching(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelOptimizationPolicy optimization = 12;
      case 12:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 98)) {
          ptr = ctx->ParseMessage(_internal_mutable_optimization(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .nvidia.inferenceserver.ModelSequenceBatching sequence_batching = 13;
      case 13:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 106)) {
          ptr = ctx->ParseMessage(_internal_mutable_sequence_batching(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* ModelConfig::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:nvidia.inferenceserver.ModelConfig)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // string name = 1;
  if (!this->_internal_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_name().data(), static_cast<int>(this->_internal_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.ModelConfig.name");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_name(), target);
  }

  // string platform = 2;
  if (!this->_internal_platform().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_platform().data(), static_cast<int>(this->_internal_platform().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.ModelConfig.platform");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_platform(), target);
  }

  // .nvidia.inferenceserver.ModelVersionPolicy version_policy = 3;
  if (this->_internal_has_version_policy()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        3, _Internal::version_policy(this), target, stream);
  }

  // int32 max_batch_size = 4;
  if (this->_internal_max_batch_size() != 0) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(4, this->_internal_max_batch_size(), target);
  }

  // repeated .nvidia.inferenceserver.ModelInput input = 5;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_input_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(5, this->_internal_input(i), target, stream);
  }

  // repeated .nvidia.inferenceserver.ModelOutput output = 6;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_output_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(6, this->_internal_output(i), target, stream);
  }

  // repeated .nvidia.inferenceserver.ModelInstanceGroup instance_group = 7;
  for (unsigned int i = 0,
      n = static_cast<unsigned int>(this->_internal_instance_group_size()); i < n; i++) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(7, this->_internal_instance_group(i), target, stream);
  }

  // string default_model_filename = 8;
  if (!this->_internal_default_model_filename().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_default_model_filename().data(), static_cast<int>(this->_internal_default_model_filename().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "nvidia.inferenceserver.ModelConfig.default_model_filename");
    target = stream->WriteStringMaybeAliased(
        8, this->_internal_default_model_filename(), target);
  }

  // map<string, string> cc_model_filenames = 9;
  if (!this->_internal_cc_model_filenames().empty()) {
    typedef ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_pointer
        ConstPtr;
    typedef ConstPtr SortItem;
    typedef ::PROTOBUF_NAMESPACE_ID::internal::CompareByDerefFirst<SortItem> Less;
    struct Utf8Check {
      static void Check(ConstPtr p) {
        (void)p;
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
          p->first.data(), static_cast<int>(p->first.length()),
          ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
          "nvidia.inferenceserver.ModelConfig.CcModelFilenamesEntry.key");
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
          p->second.data(), static_cast<int>(p->second.length()),
          ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
          "nvidia.inferenceserver.ModelConfig.CcModelFilenamesEntry.value");
      }
    };

    if (stream->IsSerializationDeterministic() &&
        this->_internal_cc_model_filenames().size() > 1) {
      ::std::unique_ptr<SortItem[]> items(
          new SortItem[this->_internal_cc_model_filenames().size()]);
      typedef ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::size_type size_type;
      size_type n = 0;
      for (::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_iterator
          it = this->_internal_cc_model_filenames().begin();
          it != this->_internal_cc_model_filenames().end(); ++it, ++n) {
        items[static_cast<ptrdiff_t>(n)] = SortItem(&*it);
      }
      ::std::sort(&items[0], &items[static_cast<ptrdiff_t>(n)], Less());
      for (size_type i = 0; i < n; i++) {
        target = ModelConfig_CcModelFilenamesEntry_DoNotUse::Funcs::InternalSerialize(9, items[static_cast<ptrdiff_t>(i)]->first, items[static_cast<ptrdiff_t>(i)]->second, target, stream);
        Utf8Check::Check(&(*items[static_cast<ptrdiff_t>(i)]));
      }
    } else {
      for (::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_iterator
          it = this->_internal_cc_model_filenames().begin();
          it != this->_internal_cc_model_filenames().end(); ++it) {
        target = ModelConfig_CcModelFilenamesEntry_DoNotUse::Funcs::InternalSerialize(9, it->first, it->second, target, stream);
        Utf8Check::Check(&(*it));
      }
    }
  }

  // map<string, string> tags = 10;
  if (!this->_internal_tags().empty()) {
    typedef ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_pointer
        ConstPtr;
    typedef ConstPtr SortItem;
    typedef ::PROTOBUF_NAMESPACE_ID::internal::CompareByDerefFirst<SortItem> Less;
    struct Utf8Check {
      static void Check(ConstPtr p) {
        (void)p;
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
          p->first.data(), static_cast<int>(p->first.length()),
          ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
          "nvidia.inferenceserver.ModelConfig.TagsEntry.key");
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
          p->second.data(), static_cast<int>(p->second.length()),
          ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
          "nvidia.inferenceserver.ModelConfig.TagsEntry.value");
      }
    };

    if (stream->IsSerializationDeterministic() &&
        this->_internal_tags().size() > 1) {
      ::std::unique_ptr<SortItem[]> items(
          new SortItem[this->_internal_tags().size()]);
      typedef ::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::size_type size_type;
      size_type n = 0;
      for (::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_iterator
          it = this->_internal_tags().begin();
          it != this->_internal_tags().end(); ++it, ++n) {
        items[static_cast<ptrdiff_t>(n)] = SortItem(&*it);
      }
      ::std::sort(&items[0], &items[static_cast<ptrdiff_t>(n)], Less());
      for (size_type i = 0; i < n; i++) {
        target = ModelConfig_TagsEntry_DoNotUse::Funcs::InternalSerialize(10, items[static_cast<ptrdiff_t>(i)]->first, items[static_cast<ptrdiff_t>(i)]->second, target, stream);
        Utf8Check::Check(&(*items[static_cast<ptrdiff_t>(i)]));
      }
    } else {
      for (::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_iterator
          it = this->_internal_tags().begin();
          it != this->_internal_tags().end(); ++it) {
        target = ModelConfig_TagsEntry_DoNotUse::Funcs::InternalSerialize(10, it->first, it->second, target, stream);
        Utf8Check::Check(&(*it));
      }
    }
  }

  // .nvidia.inferenceserver.ModelDynamicBatching dynamic_batching = 11;
  if (_internal_has_dynamic_batching()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        11, _Internal::dynamic_batching(this), target, stream);
  }

  // .nvidia.inferenceserver.ModelOptimizationPolicy optimization = 12;
  if (this->_internal_has_optimization()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        12, _Internal::optimization(this), target, stream);
  }

  // .nvidia.inferenceserver.ModelSequenceBatching sequence_batching = 13;
  if (_internal_has_sequence_batching()) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        13, _Internal::sequence_batching(this), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:nvidia.inferenceserver.ModelConfig)
  return target;
}

size_t ModelConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:nvidia.inferenceserver.ModelConfig)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .nvidia.inferenceserver.ModelInput input = 5;
  total_size += 1UL * this->_internal_input_size();
  for (const auto& msg : this->input_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .nvidia.inferenceserver.ModelOutput output = 6;
  total_size += 1UL * this->_internal_output_size();
  for (const auto& msg : this->output_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .nvidia.inferenceserver.ModelInstanceGroup instance_group = 7;
  total_size += 1UL * this->_internal_instance_group_size();
  for (const auto& msg : this->instance_group_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // map<string, string> cc_model_filenames = 9;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(this->_internal_cc_model_filenames_size());
  for (::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_iterator
      it = this->_internal_cc_model_filenames().begin();
      it != this->_internal_cc_model_filenames().end(); ++it) {
    total_size += ModelConfig_CcModelFilenamesEntry_DoNotUse::Funcs::ByteSizeLong(it->first, it->second);
  }

  // map<string, string> tags = 10;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(this->_internal_tags_size());
  for (::PROTOBUF_NAMESPACE_ID::Map< std::string, std::string >::const_iterator
      it = this->_internal_tags().begin();
      it != this->_internal_tags().end(); ++it) {
    total_size += ModelConfig_TagsEntry_DoNotUse::Funcs::ByteSizeLong(it->first, it->second);
  }

  // string name = 1;
  if (!this->_internal_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_name());
  }

  // string platform = 2;
  if (!this->_internal_platform().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_platform());
  }

  // string default_model_filename = 8;
  if (!this->_internal_default_model_filename().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_default_model_filename());
  }

  // .nvidia.inferenceserver.ModelVersionPolicy version_policy = 3;
  if (this->_internal_has_version_policy()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *version_policy_);
  }

  // .nvidia.inferenceserver.ModelOptimizationPolicy optimization = 12;
  if (this->_internal_has_optimization()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
        *optimization_);
  }

  // int32 max_batch_size = 4;
  if (this->_internal_max_batch_size() != 0) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_max_batch_size());
  }

  switch (scheduling_choice_case()) {
    // .nvidia.inferenceserver.ModelDynamicBatching dynamic_batching = 11;
    case kDynamicBatching: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *scheduling_choice_.dynamic_batching_);
      break;
    }
    // .nvidia.inferenceserver.ModelSequenceBatching sequence_batching = 13;
    case kSequenceBatching: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *scheduling_choice_.sequence_batching_);
      break;
    }
    case SCHEDULING_CHOICE_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData ModelConfig::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    ModelConfig::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*ModelConfig::GetClassData() const { return &_class_data_; }

void ModelConfig::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<ModelConfig *>(to)->MergeFrom(
      static_cast<const ModelConfig &>(from));
}


void ModelConfig::MergeFrom(const ModelConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:nvidia.inferenceserver.ModelConfig)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  input_.MergeFrom(from.input_);
  output_.MergeFrom(from.output_);
  instance_group_.MergeFrom(from.instance_group_);
  cc_model_filenames_.MergeFrom(from.cc_model_filenames_);
  tags_.MergeFrom(from.tags_);
  if (!from._internal_name().empty()) {
    _internal_set_name(from._internal_name());
  }
  if (!from._internal_platform().empty()) {
    _internal_set_platform(from._internal_platform());
  }
  if (!from._internal_default_model_filename().empty()) {
    _internal_set_default_model_filename(from._internal_default_model_filename());
  }
  if (from._internal_has_version_policy()) {
    _internal_mutable_version_policy()->::nvidia::inferenceserver::ModelVersionPolicy::MergeFrom(from._internal_version_policy());
  }
  if (from._internal_has_optimization()) {
    _internal_mutable_optimization()->::nvidia::inferenceserver::ModelOptimizationPolicy::MergeFrom(from._internal_optimization());
  }
  if (from._internal_max_batch_size() != 0) {
    _internal_set_max_batch_size(from._internal_max_batch_size());
  }
  switch (from.scheduling_choice_case()) {
    case kDynamicBatching: {
      _internal_mutable_dynamic_batching()->::nvidia::inferenceserver::ModelDynamicBatching::MergeFrom(from._internal_dynamic_batching());
      break;
    }
    case kSequenceBatching: {
      _internal_mutable_sequence_batching()->::nvidia::inferenceserver::ModelSequenceBatching::MergeFrom(from._internal_sequence_batching());
      break;
    }
    case SCHEDULING_CHOICE_NOT_SET: {
      break;
    }
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void ModelConfig::CopyFrom(const ModelConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:nvidia.inferenceserver.ModelConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelConfig::IsInitialized() const {
  return true;
}

void ModelConfig::InternalSwap(ModelConfig* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  input_.InternalSwap(&other->input_);
  output_.InternalSwap(&other->output_);
  instance_group_.InternalSwap(&other->instance_group_);
  cc_model_filenames_.InternalSwap(&other->cc_model_filenames_);
  tags_.InternalSwap(&other->tags_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &name_, lhs_arena,
      &other->name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &platform_, lhs_arena,
      &other->platform_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &default_model_filename_, lhs_arena,
      &other->default_model_filename_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ModelConfig, max_batch_size_)
      + sizeof(ModelConfig::max_batch_size_)
      - PROTOBUF_FIELD_OFFSET(ModelConfig, version_policy_)>(
          reinterpret_cast<char*>(&version_policy_),
          reinterpret_cast<char*>(&other->version_policy_));
  swap(scheduling_choice_, other->scheduling_choice_);
  swap(_oneof_case_[0], other->_oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata ModelConfig::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_model_5fconfig_2eproto_getter, &descriptor_table_model_5fconfig_2eproto_once,
      file_level_metadata_model_5fconfig_2eproto[13]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace inferenceserver
}  // namespace nvidia
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelInstanceGroup* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelInstanceGroup >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelInstanceGroup >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelInput* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelInput >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelInput >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelOutput* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelOutput >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelOutput >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelVersionPolicy_Latest* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelVersionPolicy_Latest >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelVersionPolicy_Latest >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelVersionPolicy_All* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelVersionPolicy_All >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelVersionPolicy_All >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelVersionPolicy_Specific* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelVersionPolicy_Specific >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelVersionPolicy_Specific >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelVersionPolicy* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelVersionPolicy >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelVersionPolicy >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelOptimizationPolicy_Graph* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelOptimizationPolicy_Graph >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelOptimizationPolicy_Graph >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelOptimizationPolicy* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelOptimizationPolicy >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelOptimizationPolicy >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelDynamicBatching* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelDynamicBatching >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelDynamicBatching >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelSequenceBatching* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelSequenceBatching >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelSequenceBatching >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelConfig_CcModelFilenamesEntry_DoNotUse >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelConfig_TagsEntry_DoNotUse >(arena);
}
template<> PROTOBUF_NOINLINE ::nvidia::inferenceserver::ModelConfig* Arena::CreateMaybeMessage< ::nvidia::inferenceserver::ModelConfig >(Arena* arena) {
  return Arena::CreateMessageInternal< ::nvidia::inferenceserver::ModelConfig >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
